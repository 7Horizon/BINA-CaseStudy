{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyP6gga+oDjiBTBGH7qTyVgD",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Datenquellen und Datenbank\n",
    "In diesem Notebook werden die Datenquellen beschrieben sowie deren Herkunft. Aufgrund der grossen Datenmengen wird ein Data Warehouse angelegt. Dazu werden die Daten in eine SQLite Datenbank geladen. Dies erlaubt in der späteren Auswertungen vordefinierte Views zu erstellen und diese für die weitere Verwendung zu nutzen.\n",
    "\n",
    "> !! Dieses Notebook muss zuerst ausgeführt werden, damit die Datenbank erstellt wird. Sie ist zu gross um diese direkt in Github hochzuladen. !!\n",
    "\n",
    "## Eingesetzte Module\n",
    "Für dieses Notebook werden folgende Module eingesetzt:\n",
    "- __sqlite3__\n",
    "    Wird für die Datenbank verwendet\n",
    "- __pandas__ \n",
    "    Wird gebraucht um die CSV Dateien zu lesen und als Dataframe in die SQLite Datenbank zu laden\n",
    "- __numpy__\n",
    "    Wird benötigt um die NaN Werte in den Dataframes mit NULL zu ersetzen\n",
    "- __glob__\n",
    "    Wird eingesetzt um gesamte Folders in einem Loop in die SQLite Datenbank zu laden"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Import Modules\n",
    "import os, sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:07.859267Z",
     "start_time": "2024-05-25T19:29:07.857042Z"
    }
   },
   "outputs": [],
   "execution_count": 167
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Datenbank\n",
    "Zur Untersuchung, welche Einflussfaktoren den Stromverbrauch der Gemeinden im Kanton Luzern beeinflussen können, wird auf mehrere Datenquellen zurückgegriffen. Die Datenquellen sind nachfolgend aufgelistet und werden im weiteren Verlauf beschrieben:\n",
    "- Smartmeter Daten der CKW AG\n",
    "- Demografische Daten des Bundes\n",
    "- Solarkraftwerke Daten des Bundes\n",
    "- Historische Meteo Daten des Bundes\n",
    "- Gemeindenamen und BFS-ID von Swisstopo\n",
    "\n",
    "Die genannten Datenquellen werden mit folgendem ERD in die SQLite Datenbank geladen.\n",
    "\n",
    "> ![ERD-Diagramm](./DATA/ERD_BINA_V4.png)\n",
    "\n",
    "Die Erläuterungen, zu den einzelnen Tabellen, folgt bei den jeweiligen Datenimporten.\n",
    "\n",
    "### Eigenschaften der SQLite Datenbank\n",
    "Die SQLite Datenbank hat gewisse Einschränkungen und Eigenheiten die beachtet werden müssen. Dies weil SQLite nicht alle Formate oder Datentypen unterstützt. Die relevanten Aspekte werden in diesem Kapitel kurz erläutert.\n",
    "\n",
    "__Strings__\n",
    "Damit SQLite die Daten als String erkennt müssen diese in \"\" eingebettet werden. Ansonsten wird eine Fehlermeldung ausgegeben. Die Datentypen aus den Pandas Dataframes werden nicht in die SQLite Datenbank mitübergeben.\n",
    "\n",
    "__Datum__\n",
    "SQLite kennt keinen Datum-Datentyp. Dementsprechend müssen die Datum-/Zeitstempel in einem spezifischen String-Format gespeichert werden. Eine entsprechende Umformung muss daher bereits vor dem Import erfolgen, ansonsten funktionieren die SQLite Datum-/Zeitfunktionen nicht bei den abfragen. Die unterstützten Formate sind in dieser [Dokumentation](https://www.sqlite.org/lang_datefunc.html) gelistet. Für diese Arbeit sind folgende Formate relevant:\n",
    "- YYYY-MM-DDTHH:MM:SS.SSS \n",
    "- YYYY-MM-DD HH:MM\n",
    "\n",
    "So können Datumabfragen erstellt werden wie im nachfolgenden Beispiel\n",
    "> `SELECT MAX(strftime('%Y-%m-%d %H:%M', dataTime)) FROM meteoData;`\n",
    "\n",
    "__Automatische ID__\n",
    "Damit automatisch ein eindeutiger Primary Key generiert wird muss beim Import der Daten, der Platzhalter für das ID-Attribut leergelassen werden und mit NULL gefüllt werden. So wird automatisch ein Primary Key vergeben.\n",
    "\n",
    "__No Value Handling__\n",
    "Leere Werte in den Datenquellen welche mit nan, NaN, na, etc. gelistet sind, müssen mit NULL ersetzt werden. Sonst wird der Wert als String interpretiert und gibt einen Fehler aus, wenn es sich um numerische Werte handelt."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Erstellen des Datenbank Files\n",
    "Hier wird die Datenbank angelegt. Ist das File nicht vorhanden, wird dieses automatisch angelegt."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# creating file (path) name\n",
    "dbfile = './DATA/BINA_DATA.db' \n",
    "\n",
    "# Test if the database file is available in the colab workspace\n",
    "if os.path.exists(dbfile):\n",
    "    # Create database (file) and Open a (SQL) connection \n",
    "    connection = sqlite3.connect(dbfile)\n",
    "    # Create a data cursor to exchange information between Python and SQLite\n",
    "    cursor = connection.cursor()\n",
    "else:\n",
    "    print(\"Angegebene Database wurde nicht gefunden\")\n",
    "    # Create database (file) and Open a (SQL) connection \n",
    "    connection = sqlite3.connect(dbfile)\n",
    "    # Create a data cursor to exchange information between Python and SQLite\n",
    "    cursor = connection.cursor()\n",
    "    #sys.exit(0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:07.940055Z",
     "start_time": "2024-05-25T19:29:07.936923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angegebene Database wurde nicht gefunden\n"
     ]
    }
   ],
   "execution_count": 168
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tabellen erstellen\n",
    "Basierend auf dem ERD werden die Tabellen in der Datenbank angelegt. Entsprechend werden die Primary Keys definierte und die Abhängigkeiten referenziert."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Tabelle erstellen\n",
    "sql = [\"CREATE TABLE city (id INTEGER PRIMARY KEY, plz string, cityName string, bfsID string, lawCityName string, kantonkuerzel string)\",\n",
    "\"CREATE TABLE smartmeter (id INTEGER PRIMARY KEY, plz REFERENCES city(plz) ON UPDATE CASCADE, timestamp string, anzMeter int,valueKwh float)\",\n",
    "\"CREATE TABLE solarPlants (id INTEGER PRIMARY KEY, xtfID string, plz string, canton string, totalPower float, mainCategory string, subCategory string, plantCategory string,  _x int,  _y int, FOREIGN KEY (plz) REFERENCES city(plz) ON UPDATE CASCADE, FOREIGN KEY (subCategory) REFERENCES subCategory(id) ON UPDATE CASCADE, FOREIGN KEY (mainCategory) REFERENCES mainCategory(id) ON UPDATE CASCADE, FOREIGN KEY (plantCategory) REFERENCES plantCategory(id) ON UPDATE CASCADE)\",\n",
    "\"CREATE TABLE mainCategory (id string PRIMARY KEY, de string, fr string, it string, en string)\",\n",
    "\"CREATE TABLE plantCategory (id string PRIMARY KEY, de string, fr string, it string, en string)\",\n",
    "\"CREATE TABLE subCategory (id string PRIMARY KEY, de string, fr string, it string, en string)\",\n",
    "\"CREATE TABLE indicator (id string PRIMARY KEY, descr string)\",\n",
    "\"CREATE TABLE unit (id string,  mes string)\",\n",
    "\"CREATE TABLE demoValue (id INTEGER PRIMARY KEY, bfsID string, period string, indicator string, unit string, value float, FOREIGN KEY (bfsID) REFERENCES city(bfsID) ON UPDATE CASCADE, FOREIGN KEY (indicator) REFERENCES indicator (id) ON UPDATE CASCADE, FOREIGN KEY (unit) REFERENCES unit(id) ON UPDATE CASCADE)\",\n",
    "\"CREATE TABLE meteoParameter (parameterID string PRIMARY KEY , measure string, description string)\",\n",
    "\"CREATE TABLE meteoStations (stn string PRIMARY KEY, stnName string, lawCityName string,  datasource string, bfsID string, coEast string, coNorth string, coLength string, coWide string, FOREIGN KEY (lawCityName) REFERENCES city (lawCityName) ON UPDATE CASCADE, FOREIGN KEY (bfsID) REFERENCES city (bfsID) ON UPDATE CASCADE)\",\n",
    "\"CREATE TABLE meteoData (id INTEGER PRIMARY KEY, meteoStation string, meteoParameter string, dataTime string, value float, FOREIGN KEY (meteoStation) REFERENCES meteoStations (stn) ON UPDATE CASCADE, FOREIGN KEY (meteoParameter) REFERENCES meteoParameter (parameterID) ON UPDATE CASCADE)\",\n",
    "\"CREATE TABLE meteoParamBfs (id INTEGER PRIMARY KEY, bfsID string, meteoParameter string, meteoStation string, FOREIGN KEY (bfsID) REFERENCES city (bfsID) ON UPDATE CASCADE, FOREIGN KEY (meteoParameter) References meteoParameter (parameterID) ON UPDATE CASCADE, FOREIGN KEY (meteoStation) REFERENCES meteoStations (stn) ON UPDATE CASCADE)\",\n",
    "\"CREATE TABLE plzBfsMapping (id INTEGER PRIMARY KEY, plz string, bfsID string, cityName string, lawCityName string)\"]\n",
    "\n",
    "for code in sql:\n",
    "    cursor.execute(code)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:07.946826Z",
     "start_time": "2024-05-25T19:29:07.940965Z"
    }
   },
   "outputs": [],
   "execution_count": 169
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Views erstellen\n",
    "Diese Views helfen in der späteren Datenanalyse und können direkt in ein Dataframe geladen werden für die weitere Verwendung.\n",
    "\n",
    "Um einen einfacheren Zugang zu bestimmten Daten zu haben, wurden entsprechende Views generiert. Diese filtern im Beispiel der demografischen Daten die verschiedenen Indikatoren oder verbinden die Daten zwischen mehreren Datensätzen und summieren diese. So können für spätere Auswertungen bereits vorgefertigte Daten verwendet werden.\n",
    "\n",
    "Folgende Views wurden erstellt:\n",
    "- **population:** Gibt die Bevölkerung zur BFS-ID in einer bestimmten Periode an.\n",
    "- **populationDensity:** Gibt die Bevölkerungsdichte zur BFS-ID in einer bestimmten Periode an.\n",
    "- **areaTotal:** Gibt die Fläche zur BFS-ID in einer bestimmten Periode an.\n",
    "- **areaSettlement:** Gibt die besiedelte Fläche zur BFS-ID in einer bestimmten Periode an.\n",
    "- **areaAgricultural:** Gibt die Agrarfläche zur BFS-ID in einer bestimmten Periode an.\n",
    "- **areaUnproductive:** Gibt die unproduktive Fläche zur BFS-ID in einer bestimmten Periode an.\n",
    "- **keyFiguresPopulation:** Fasst die einzelnen Datensätze der Bevölkerung und der Bevölkerungsdichte pro BFS-ID und Periode zu einem Datensatz zusammen.\n",
    "- **keyFiguresArea:** Fasst die einzelnen Datensätze der Fläche pro BFS-ID zu einem Datensatz zusammen, weist aber pro Wert die Periode aus.\n",
    "- **sumSmartmeter:** Rechnet die KWh pro BFS-ID zusammen.\n",
    "- **meteoStationsParameter:** Reichert die Daten der Meteo Stationen mit deren Standort an.\n",
    "- **solarPlantsLU:** Gibt alle registrierten Solaranlagen im Kanton Luzern aus.\n",
    "- **solarPlantsLUbfsId:** Gibt alle registrierten Solaranlagen im Kanton Luzern aus, gruppiert nach der BFS-ID."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Views erstellen\n",
    "sql = [ \"CREATE VIEW population AS SELECT id, bfsID, period, value FROM demoValue WHERE demoValue.indicator == 'Ind_01_01';\",\n",
    "        \"CREATE VIEW populationDensity AS SELECT id, bfsID, period, value FROM demoValue WHERE demoValue.indicator == 'Ind_01_03';\",\n",
    "        \"CREATE VIEW areaTotal AS SELECT id, bfsID, period, value FROM demoValue WHERE demoValue.indicator == 'Ind_04_01';\",\n",
    "        \"CREATE VIEW areaSettlement AS SELECT id, bfsID, period, value FROM demoValue WHERE demoValue.indicator == 'Ind_04_02';\",\n",
    "        \"CREATE VIEW areaAgricultural AS SELECT id, bfsID, period, value FROM demoValue WHERE demoValue.indicator == 'Ind_04_04';\",\n",
    "        \"CREATE VIEW areaUnproductive AS SELECT id, bfsID, period, value FROM demoValue WHERE demoValue.indicator == 'Ind_04_07';\",\n",
    "        \"CREATE VIEW keyFiguresPopulation as SELECT p.bfsID, p.period, p.value as population, pd.value as populationDensity FROM population p LEFT JOIN population_density pd ON p.bfsID = pd.bfsID AND p.period = pd.period;\",\n",
    "        \"CREATE VIEW keyFiguresArea as SELECT a.bfsID, a.period as periodTotal, a.value as total,ase.period as periodSettlement, ase.value as settlement, aa.period as periodAgricultural, aa.value as agricultural, au.period as periodUnproductive, au.value as unproductive FROM areaTotal a LEFT JOIN areaSettlement ase ON a.bfsID = ase.bfsID LEFT JOIN areaAgricultural aa ON a.bfsID = aa.bfsID LEFT JOIN areaUnproductive au ON a.bfsID = au.bfsID;\",\n",
    "        \"CREATE VIEW sumSmartmeter as SELECT s.plz as plz, bfsID, SUM(valueKwh) as 'kWh' FROM smartmeter as s LEFT JOIN (SELECT plz, bfsID FROM city GROUP BY plz) as c ON s.plz = c.plz GROUP BY bfsID;\",\n",
    "        \"CREATE VIEW meteoStationsParameter as SELECT DISTINCT meteoStations.bfsID, meteoStation, meteoParameter FROM meteoData LEFT JOIN meteoStations on meteoStations.stn = meteoData.meteoStation;\",\n",
    "        \"CREATE VIEW solarPlantsLU as SELECT * FROM solarPlants WHERE solarPlants.Canton == 'LU' AND solarPlants.SubCategory == 'subcat_2';\",\n",
    "        \"CREATE VIEW solarPlantsLUbfsId as SELECT SUM(s.totalPower), s.canton, p.lawCityName, p.bfsID FROM solarPlants as s LEFT JOIN plzBfsMapping as p ON s.plz = p.plz WHERE s.canton == 'LU' AND s.subCategory == 'subcat_2' GROUP BY p.bfsID;\"\n",
    "       ]\n",
    "\n",
    "for code in sql:\n",
    "    cursor.execute(code)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:07.952971Z",
     "start_time": "2024-05-25T19:29:07.947714Z"
    }
   },
   "outputs": [],
   "execution_count": 170
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Datenquellen\n",
    "Nachfolgend werden die verwendeten Datenquellen beschrieben und ein erstes Mal analysiert."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BFS-ID Verzeichnis\n",
    "**Herausgeber:**\n",
    "Bundesamt für Landestopografie Swisstopo\n",
    "\n",
    "**Link:**\n",
    "https://www.swisstopo.admin.ch/de/amtliches-ortschaftenverzeichnis#Ortschaftenverzeichnis--Download\n",
    "\n",
    "**Beschreibung:**\n",
    "Dieses Dataset beinhaltet das amtliche Ortschaftenverzeichnis. Eine Ortschaft ist mit einer eindeutigen Postleitzahl (PLZ) und Ortschaftsnamen bezeichnet. Diese Bezeichnungen sind relevant für die Postadresse und werden durch die Swisstopo erstellt, verwaltet und veröffentlicht (Swisstopo, [Online-Quelle](https://www.swisstopo.admin.ch/de/amtliches-ortschaftenverzeichnis)). Die BFS-Nr. wird vom Bundesamt für Statistik (BFS) jeder Gemeinde vergeben. Diese Nummern werden vom BFS erstellt, verwaltet und veröffentlicht. Diese sind im amtlichen Gemeindeverzeichnis ersichtlich (BFS, [Online-Quelle](https://www.bfs.admin.ch/bfs/de/home/grundlagen/agvch.html)). Dieses Dataset erlaubt die Übersetzung zwischen BFS-Nr. <-> PLZ.\n",
    "\n",
    "**Zeitraum:**\n",
    "Das Dataset wurde am 25.3.2024 heruntergeladen. Dementsprechend ist das Dataset auf dem gültigen Stand vom 1.3.2024, da dieses Dataset von Swisstopo immer am ersten Tag im Monat aktualisiert wird (Swisstopo, [Online-Quelle](https://www.swisstopo.admin.ch/de/amtliches-ortschaftenverzeichnis)).\n",
    "\n",
    "**Zweckerfüllung:**\n",
    "Zur Beantwortung der Forschungsfrage werden diverse Datasets mit einander verbunden. Da die Datasets mit unterschiedlichen Gemeinde-Informationen bzw. Ortschaftsinformationen arbeiten wird eine Übersetzung zwischen der BFS-ID und der PLZ benötigt. Beispielsweise arbeitet das BFS ausschliesslich mit der BFS-ID, die Smartmeter Daten werden auf die PLZ geschlüsselt. Damit die Daten nun miteinander in Beziehung gesetzt werden können, wird dieses Dataset von Swisstopo benötigt. \n",
    "\n",
    "**Qualität (Glaubwürdigkeit, Nützlichkeit, Interpretierbarkeit, Schlüsselintegrität):**\n",
    "\n",
    "*Glaubwürdigkeit:* Da es sich beim Bund um eine Primäre Quelle handelt, ist die Glaubwürdigkeit gegeben.\n",
    "\n",
    "*Nützlichkeit:* Die Daten sind vollständig und erlauben die notwendige Übersetzung mit einer gewissen Limitierung welche noch genauer erläutert wird.\n",
    "\n",
    "*Interpretierbarkeit:* Das Dataset ist leicht verständlich und kann ohne weiteres Interpretiert werden.\n",
    "\n",
    "*Schlüsselintegrität:* Ein eindeutiger Schlüssel ist im Dataset nicht vorhanden.\n",
    "\n",
    "**Verfügbarkeit:** Das Dataset ist öffentlich verfügbar und kann durch jede Person heruntergeladen werden.\n",
    "\n",
    "**Preis:** Das Dataset wird kostenlos zu Verfügung gestellt.\n",
    "\n",
    "#### Inhaltliche Analyse und Schwierigkeiten \n",
    "Es sind zehn Spalten in dem CSV Dataset vorhanden mit Total 5733 Zeilen. Die Spalten sind selbstsprechend. Die Spalte \"Zusatzziffer\" ist eine Post interne Ziffer und ist für die weiterführende Analyse nicht relevant. Auffallend sind die 20 null Werte in der Spalte \"Kantonskürzel\".\n",
    "Ortschaft entspricht nicht der Gemeinde und umgekehrt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# City Daten einlesen als Dataframe und in DB sichern\n",
    "city_df = pd.read_csv(\"./DATA/city_directory/AMTOVZ_CSV_LV95.csv\", delimiter=\";\")\n",
    "city_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:07.963691Z",
     "start_time": "2024-05-25T19:29:07.953793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5733 entries, 0 to 5732\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Ortschaftsname  5733 non-null   object \n",
      " 1   PLZ             5733 non-null   int64  \n",
      " 2   Zusatzziffer    5733 non-null   int64  \n",
      " 3   Gemeindename    5733 non-null   object \n",
      " 4   BFS-Nr          5733 non-null   int64  \n",
      " 5   Kantonskürzel   5713 non-null   object \n",
      " 6   E               5733 non-null   float64\n",
      " 7   N               5733 non-null   float64\n",
      " 8   Sprache         5733 non-null   object \n",
      " 9   Validity        5733 non-null   object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 448.0+ KB\n"
     ]
    }
   ],
   "execution_count": 171
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wie nachfolgend ersichtlich ist, werden die Liechtensteiner Ortschaften ebenfalls in diesem Dataset geführt. Da diese keinem Kanton angehören, sind diese Werte entsprechend leer, daraus resultieren die null Werte."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Ortschaftsname   PLZ  Zusatzziffer  Gemeindename  BFS-Nr Kantonskürzel  \\\n",
      "5713  Gamprin-Bendern  9487             0         Vaduz    7001           NaN   \n",
      "5714            Vaduz  9490             0         Vaduz    7001           NaN   \n",
      "5715           Schaan  9494             0         Vaduz    7001           NaN   \n",
      "5716      Triesenberg  9497             0         Vaduz    7001           NaN   \n",
      "5717          Triesen  9495             0       Triesen    7002           NaN   \n",
      "5718          Balzers  9496             0       Balzers    7003           NaN   \n",
      "5719      Triesenberg  9497             0   Triesenberg    7004           NaN   \n",
      "5720           Schaan  9494             0        Schaan    7005           NaN   \n",
      "5721      Triesenberg  9497             0        Schaan    7005           NaN   \n",
      "5722          Planken  9498             0       Planken    7006           NaN   \n",
      "5723          Nendeln  9485             0        Eschen    7007           NaN   \n",
      "5724  Gamprin-Bendern  9487             0        Eschen    7007           NaN   \n",
      "5725           Eschen  9492             0        Eschen    7007           NaN   \n",
      "5726        Mauren FL  9493             0        Eschen    7007           NaN   \n",
      "5727       Schaanwald  9486             0        Mauren    7008           NaN   \n",
      "5728        Mauren FL  9493             0        Mauren    7008           NaN   \n",
      "5729          Nendeln  9485             0       Gamprin    7009           NaN   \n",
      "5730  Gamprin-Bendern  9487             0       Gamprin    7009           NaN   \n",
      "5731          Ruggell  9491             0       Ruggell    7010           NaN   \n",
      "5732     Schellenberg  9488             0  Schellenberg    7011           NaN   \n",
      "\n",
      "                E            N Sprache    Validity  \n",
      "5713  2756856.160  1228966.193      de  2008-07-01  \n",
      "5714  2758285.127  1223446.785      de  2008-07-01  \n",
      "5715  2758128.332  1226948.347      de  2008-07-01  \n",
      "5716  2763929.076  1218709.465      de  2008-07-01  \n",
      "5717  2760435.677  1216637.023      de  2008-07-01  \n",
      "5718  2757162.414  1214954.819      de  2008-07-01  \n",
      "5719  2762729.216  1220447.498      de  2008-07-01  \n",
      "5720  2756712.885  1226948.941      de  2008-07-01  \n",
      "5721  2763406.601  1221948.682      de  2008-07-01  \n",
      "5722  2760582.158  1227854.692      de  2008-07-01  \n",
      "5723  2759321.011  1229683.222      de  2008-07-01  \n",
      "5724  2756433.293  1229376.941      de  2008-07-01  \n",
      "5725  2757843.097  1230769.428      de  2008-07-01  \n",
      "5726  2759184.884  1232638.702      de  2008-07-01  \n",
      "5727  2760833.562  1231528.491      de  2008-07-01  \n",
      "5728  2759637.820  1231945.121      de  2008-07-01  \n",
      "5729  2759978.270  1229651.126      de  2008-07-01  \n",
      "5730  2757125.670  1232514.364      de  2008-07-01  \n",
      "5731  2758648.719  1235172.319      de  2008-07-01  \n",
      "5732  2759708.282  1233349.815      de  2008-07-01  \n"
     ]
    }
   ],
   "source": [
    "df = city_df[city_df['Kantonskürzel'].isnull()]\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:07.968489Z",
     "start_time": "2024-05-25T19:29:07.964727Z"
    }
   },
   "execution_count": 172
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wenn ein erster Blick auf die ersten Zeilen des Datasets geworfen wird, fällt gleich auf, dass eine PLZ mehrere Ortschaftsnamen haben kann. Umgekehrt kann eine BFS-Nr mehreren Ortschaften mit auch unterschiedlicher PLZ zugewiesen werden. Dies macht die gesamte Übersetzung nicht einfach. Ein weiterer Indikator für diese Schwierigkeit sind die Anzahl eindeutiger Werte bei der PLZ und der BFS-Nr."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anz. Eindeutige PLZ: 3194 \n",
      "Anz. Eindeutige BFS-Nr: 2143\n"
     ]
    },
    {
     "data": {
      "text/plain": "       Ortschaftsname   PLZ  Zusatzziffer        Gemeindename  BFS-Nr  \\\n0     Aeugst am Albis  8914             0     Aeugst am Albis       1   \n1         Aeugstertal  8914             2     Aeugst am Albis       1   \n2           Zwillikon  8909             0  Affoltern am Albis       2   \n3  Affoltern am Albis  8910             0  Affoltern am Albis       2   \n4          Bonstetten  8906             0          Bonstetten       3   \n5           Sihlbrugg  6340             4     Hausen am Albis       4   \n6    Langnau am Albis  8135             0     Hausen am Albis       4   \n7     Hausen am Albis  8915             0     Hausen am Albis       4   \n8           Ebertswil  8925             0     Hausen am Albis       4   \n9            Hedingen  8908             0            Hedingen       5   \n\n  Kantonskürzel            E            N Sprache    Validity  \n0            ZH  2679402.872  1235842.010      de  2008-07-01  \n1            ZH  2679815.372  1237404.310      de  2008-07-01  \n2            ZH  2675280.133  1238108.286      de  2008-07-01  \n3            ZH  2676852.012  1236929.718      de  2008-07-01  \n4            ZH  2677412.150  1241078.278      de  2008-07-01  \n5            ZH  2686082.431  1230649.176      de  2008-07-01  \n6            ZH  2682031.828  1235594.870      de  2008-07-01  \n7            ZH  2682851.794  1233662.737      de  2008-07-01  \n8            ZH  2684421.805  1231375.039      de  2008-07-01  \n9            ZH  2676516.423  1239543.573      de  2008-07-01  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ortschaftsname</th>\n      <th>PLZ</th>\n      <th>Zusatzziffer</th>\n      <th>Gemeindename</th>\n      <th>BFS-Nr</th>\n      <th>Kantonskürzel</th>\n      <th>E</th>\n      <th>N</th>\n      <th>Sprache</th>\n      <th>Validity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aeugst am Albis</td>\n      <td>8914</td>\n      <td>0</td>\n      <td>Aeugst am Albis</td>\n      <td>1</td>\n      <td>ZH</td>\n      <td>2679402.872</td>\n      <td>1235842.010</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Aeugstertal</td>\n      <td>8914</td>\n      <td>2</td>\n      <td>Aeugst am Albis</td>\n      <td>1</td>\n      <td>ZH</td>\n      <td>2679815.372</td>\n      <td>1237404.310</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Zwillikon</td>\n      <td>8909</td>\n      <td>0</td>\n      <td>Affoltern am Albis</td>\n      <td>2</td>\n      <td>ZH</td>\n      <td>2675280.133</td>\n      <td>1238108.286</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Affoltern am Albis</td>\n      <td>8910</td>\n      <td>0</td>\n      <td>Affoltern am Albis</td>\n      <td>2</td>\n      <td>ZH</td>\n      <td>2676852.012</td>\n      <td>1236929.718</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bonstetten</td>\n      <td>8906</td>\n      <td>0</td>\n      <td>Bonstetten</td>\n      <td>3</td>\n      <td>ZH</td>\n      <td>2677412.150</td>\n      <td>1241078.278</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Sihlbrugg</td>\n      <td>6340</td>\n      <td>4</td>\n      <td>Hausen am Albis</td>\n      <td>4</td>\n      <td>ZH</td>\n      <td>2686082.431</td>\n      <td>1230649.176</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Langnau am Albis</td>\n      <td>8135</td>\n      <td>0</td>\n      <td>Hausen am Albis</td>\n      <td>4</td>\n      <td>ZH</td>\n      <td>2682031.828</td>\n      <td>1235594.870</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Hausen am Albis</td>\n      <td>8915</td>\n      <td>0</td>\n      <td>Hausen am Albis</td>\n      <td>4</td>\n      <td>ZH</td>\n      <td>2682851.794</td>\n      <td>1233662.737</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Ebertswil</td>\n      <td>8925</td>\n      <td>0</td>\n      <td>Hausen am Albis</td>\n      <td>4</td>\n      <td>ZH</td>\n      <td>2684421.805</td>\n      <td>1231375.039</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Hedingen</td>\n      <td>8908</td>\n      <td>0</td>\n      <td>Hedingen</td>\n      <td>5</td>\n      <td>ZH</td>\n      <td>2676516.423</td>\n      <td>1239543.573</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Anz. Eindeutige PLZ:\",len(city_df['PLZ'].unique()), \"\\nAnz. Eindeutige BFS-Nr:\", len(city_df['BFS-Nr'].unique()))\n",
    "city_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:07.974400Z",
     "start_time": "2024-05-25T19:29:07.969072Z"
    }
   },
   "execution_count": 173
  },
  {
   "cell_type": "markdown",
   "source": [
    "Besonders gut ersichtlich ist dies mit der Ortschaft/Gemeinde Entlebuch. Diese wird als Ortschaft mit der PLZ 6162 geführt, gehört aber einmal zu der Gemeinde Hasle mit der BFS-Nr. 1005 und einmal zu der eigenständige Gemeinde Entlebuch mit der BFS-Nr. 1002. Aus diesem Grund muss manuell für den Kanton Luzern (auf diesen Kanton beschränken sich die Stromzähler-Daten) eine gültiges Mapping erstellt werden, damit die statistischen Daten korrekt miteinander verknüpft werden können."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                Ortschaftsname   PLZ  Zusatzziffer Gemeindename  BFS-Nr  \\\n1302               Schachen LU  6105             0    Entlebuch    1002   \n1303                  Wolhusen  6110             0    Entlebuch    1002   \n1304                 Entlebuch  6162             0    Entlebuch    1002   \n1305                     Rengg  6162             2    Entlebuch    1002   \n1306  Finsterwald b. Entlebuch  6162             3    Entlebuch    1002   \n1307                     Ebnet  6163             0    Entlebuch    1002   \n1308                  Hasle LU  6166             0    Entlebuch    1002   \n1309                Schüpfheim  6170             0    Entlebuch    1002   \n1315                 Entlebuch  6162             0   Hasle (LU)    1005   \n\n     Kantonskürzel            E            N Sprache    Validity  \n1302            LU  2651765.170  1206458.353      de  2008-07-01  \n1303            LU  2647835.016  1209085.303      de  2008-07-01  \n1304            LU  2648181.509  1204613.219      de  2008-07-01  \n1305            LU  2651085.330  1206090.284      de  2008-07-01  \n1306            LU  2651398.164  1196309.788      de  2008-07-01  \n1307            LU  2649189.420  1207868.916      de  2008-07-01  \n1308            LU  2643949.810  1203182.068      de  2008-07-01  \n1309            LU  2643913.598  1202607.042      de  2008-07-01  \n1315            LU  2647203.726  1204928.665      de  2008-07-01  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ortschaftsname</th>\n      <th>PLZ</th>\n      <th>Zusatzziffer</th>\n      <th>Gemeindename</th>\n      <th>BFS-Nr</th>\n      <th>Kantonskürzel</th>\n      <th>E</th>\n      <th>N</th>\n      <th>Sprache</th>\n      <th>Validity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1302</th>\n      <td>Schachen LU</td>\n      <td>6105</td>\n      <td>0</td>\n      <td>Entlebuch</td>\n      <td>1002</td>\n      <td>LU</td>\n      <td>2651765.170</td>\n      <td>1206458.353</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>1303</th>\n      <td>Wolhusen</td>\n      <td>6110</td>\n      <td>0</td>\n      <td>Entlebuch</td>\n      <td>1002</td>\n      <td>LU</td>\n      <td>2647835.016</td>\n      <td>1209085.303</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>1304</th>\n      <td>Entlebuch</td>\n      <td>6162</td>\n      <td>0</td>\n      <td>Entlebuch</td>\n      <td>1002</td>\n      <td>LU</td>\n      <td>2648181.509</td>\n      <td>1204613.219</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>1305</th>\n      <td>Rengg</td>\n      <td>6162</td>\n      <td>2</td>\n      <td>Entlebuch</td>\n      <td>1002</td>\n      <td>LU</td>\n      <td>2651085.330</td>\n      <td>1206090.284</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>1306</th>\n      <td>Finsterwald b. Entlebuch</td>\n      <td>6162</td>\n      <td>3</td>\n      <td>Entlebuch</td>\n      <td>1002</td>\n      <td>LU</td>\n      <td>2651398.164</td>\n      <td>1196309.788</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>1307</th>\n      <td>Ebnet</td>\n      <td>6163</td>\n      <td>0</td>\n      <td>Entlebuch</td>\n      <td>1002</td>\n      <td>LU</td>\n      <td>2649189.420</td>\n      <td>1207868.916</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>1308</th>\n      <td>Hasle LU</td>\n      <td>6166</td>\n      <td>0</td>\n      <td>Entlebuch</td>\n      <td>1002</td>\n      <td>LU</td>\n      <td>2643949.810</td>\n      <td>1203182.068</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>1309</th>\n      <td>Schüpfheim</td>\n      <td>6170</td>\n      <td>0</td>\n      <td>Entlebuch</td>\n      <td>1002</td>\n      <td>LU</td>\n      <td>2643913.598</td>\n      <td>1202607.042</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n    <tr>\n      <th>1315</th>\n      <td>Entlebuch</td>\n      <td>6162</td>\n      <td>0</td>\n      <td>Hasle (LU)</td>\n      <td>1005</td>\n      <td>LU</td>\n      <td>2647203.726</td>\n      <td>1204928.665</td>\n      <td>de</td>\n      <td>2008-07-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = city_df.query('Ortschaftsname == \"Entlebuch\" or Gemeindename == \"Entlebuch\"')\n",
    "df.head(100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:07.999841Z",
     "start_time": "2024-05-25T19:29:07.993152Z"
    }
   },
   "execution_count": 174
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mit den nachfolgenden Codezeilen werden die Daten in die city-Tabelle eingelesen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for index, row in city_df.iterrows():\n",
    "    ort = '\"' + row[\"Ortschaftsname\"] + '\"'\n",
    "    lawCityName = '\"' + row[\"Gemeindename\"] + '\"'\n",
    "    if isinstance(row[\"Kantonskürzel\"], str):\n",
    "        kantonkuerzel = '\"' + row[\"Kantonskürzel\"] + '\"'\n",
    "    else:\n",
    "        kantonkuerzel = \"NULL\"\n",
    "    sql = \"INSERT INTO city VALUES(NULL,{},{},{},{},{})\".format(row[\"PLZ\"], ort, row[\"BFS-Nr\"], lawCityName, kantonkuerzel)\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:08.304553Z",
     "start_time": "2024-05-25T19:29:08.002917Z"
    }
   },
   "execution_count": 175
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Mapping BFS-Nr. <-> PLZ\n",
    "<font color=red>Beschreibung, ergänzend zu der vorherigen Erläuterungen</font>\n",
    "Um eine eindeutige Zuordnung zwischen PLZ und BFS-Nr zu haben, wurde die Liste der Luzerner Gemeinden händisch bearbeitet. Das Ziel war es jede PLZ eindeutig einer BFS-ID zuzuordnen, wobei aber mehrere verschiedene PLZ auf dieselbe BFS-ID verweisen können. Dazu wurden zuerst sämtliche Gemeinden vom Kanton Luzern aus dem City Directory exportiert. In diesem Datensatz wurden sämtliche, doppelt vorhandenen PLZ identifiziert und geprüft, welches die \"Hauptgemeinde\" hinder der PLZ darstellt und welche Ortschaften auch bereits mit einer anderen BFS-ID verknüpft sind. Solche Einträge wurden entfernt. Ausser bei einer Ausnahme konnten so sämtliche, doppelten PLZ entfernt werden, wobei darauf geachtet werden musste, dass nicht keine BFS-ID komplett entfernt wird und so keine zugewiesene PLZ mehr hat.\n",
    "\n",
    "Die Ausnahme bilden Gisikon und Honau, welche zwar identische PLZ (6038) aufweisen, jedoch unterschiedliche BFS-IDs haben. Die BFS-IDs sind einmalig, bedeutet beim Entfernen einer der beiden Datensätze verschwindet eine Markierung auf der Karte. Da anhand der PLZ keine Unterscheidung vorgenommen werden kann, wurde die Entscheidung getroffen, den Datensatz von Honau zu entfernen und nur mit Gisikon zu arbeiten.\n",
    "\n",
    "Verweisen mehrere PLZ auf dieselbe BFS-ID müssen bei den Auswertungen für die MAP am Ende die Werte zusammengerechnet werden für akkurate Darstellungen.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mapping = pd.read_csv(\"./DATA/city_directory/mapping_plz_bfsid_lu.csv\", delimiter=\",\")\n",
    "\n",
    "for index, row in mapping.iterrows():\n",
    "    cityName = '\"' + row[\"cityName\"] + '\"'\n",
    "    lawCityName = '\"' + row[\"lawCityName\"] + '\"'\n",
    "\n",
    "    sql = \"INSERT INTO plzBfsMapping VALUES(NULL,{},{},{},{})\".format(row[\"plz\"], row[\"bfsId\"], cityName, lawCityName)\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:08.312332Z",
     "start_time": "2024-05-25T19:29:08.305504Z"
    }
   },
   "execution_count": 176
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Verbaute Solaranlagen\n",
    "**Herausgeber:**\n",
    "Bundesamt für Energie (BFE)\n",
    "\n",
    "**Link:**\n",
    "https://opendata.swiss/de/dataset/elektrizitatsproduktionsanlagen\n",
    "\n",
    "**Beschreibung:**\n",
    "In diesem Dataset sind sämtliche registrierte Elektrizität Produktionsanlagen hinterlegt. Diese Daten basieren auf dem Herkunftsnachweissystem (HKN). In diesem System sind sämtliche Anlagen registriert welche über 30 Kilovoltampere (kVA) bzw. 30 Kilowatt (KW). Zudem sind Kleinanlagen welche über 2 KW produzieren registriert, den Beitreibern steht es aber frei, ob sie sich registrieren möchten. Die Registrierung ist notwendig für einen Herkunftsnachweis. Dieser ist Voraussetzung, wenn Strom in das Netz eingespiesen werden möchte. Es sind nur Anlagen gelistet, welche aktuell in Betrieb sind. Es wird monatlich aktualisiert (BFE, [Online-Quelle](https://www.uvek-gis.admin.ch/BFE/storymaps/EE_Elektrizitaetsproduktionsanlagen/)).\n",
    "\n",
    "**Zeitraum:**\n",
    "Das Dataset wurde am 24.3.2024 heruntergeladen. Dementsprechend ist das Dataset auf dem gültigen Stand vom Monat März, da dieses Dataset vom BFE monatlich aktualisiert wird. Es sind nur aktive Anlagen gelistet (OpenData, [Online-Quelle](https://opendata.swiss/de/dataset/elektrizitatsproduktionsanlagen)).\n",
    "\n",
    "**Zweckerfüllung:**\n",
    "In diesem Dataset befinden sich diverse Kraftwerks-Kategorien. Für diese Arbeit sind besonders die Photovoltaik-Anlagen von Privaten interessant. Dies erschliesst sich daraus, dass mit der Sonne und einer Photovoltaik-Anlage der Strom selbst verbraucht werden kann. Aus Sicht des Energieversorgers sinkt dadurch der Strombedarf und müsste in den Smartmeter-Daten ersichtlich sein. Daher erfüllt dieses Dataset seinen Zweck, in dem des vorhandene Anlagen inkl. verbaute Leistung liefert. Nähere Infos folgen in der tieferen Analyse.\n",
    "\n",
    "**Qualität (Glaubwürdigkeit, Nützlichkeit, Interpretierbarkeit, Schlüsselintegrität):**\n",
    "\n",
    "*Glaubwürdigkeit:* Es handelt sich im primäre Daten welche durch das BFE veröffentlicht werden. Dementsprechend ist die Glaubwürdigkeit gegeben. Wie in der Analyse festgestellt wurde, ist die Qualität der Adressen wohl nicht geprüft worden durch eine amtliche Stelle. Wie später beschrieben wird, wurden diverse Schreibfehler und Zahlendreher festgestellt.\n",
    "\n",
    "*Nützlichkeit:* Die Daten können für den vorgesehenen Zweck verwendet werden. Sie basieren auf aktuellen Daten aus dem HKN. Weiter wird ein Datum des Produktionsbetriebes angegeben, was eine zeitliche Schlussfolgerung zusammen mit den Smartmeter Daten und weiteren Daten zulässt.\n",
    "\n",
    "*Interpretierbarkeit:* Das Dataset besteht aus sechs CSV-Dateien welche zusammen eine Datenbank in Normalform darstellen. Die Spalten sind klingend benannt. Was nicht intuitiv verständlich ist, sind die drei verschiedenen Kategorie-Katalogen (MainCategoryCatalogue, PlantCategoryCatalogue, SubCategoryCatalogue). Am Aussagekräftigsten ist die SubCategoryCatalogue Datei. Sie gibt direkt an, um welchen erneuerbaren Kraftwerktyp es sich handelt. Die Datei PlantDetail ist nicht relevant, da sie im Dataset nicht referenziert wird. Mit diesem Wissen ist die Interpretierbarkeit gegeben. Nähere Details folgen in der Analyse.\n",
    "\n",
    "*Schlüsselintegrität:* Die Hauptdatei ist die ElectricityProductionPlant. In dieser ist jedes Kraftwerk mit der xtf_id eindeutig identifizierbar. Jedes Kraftwerk verfügt über mehrere ForeignKey's welche auf die entsprechenden Kategorien geschlüsselt sind. \n",
    "\n",
    "**Verfügbarkeit:** Das Dataset ist öffentlich verfügbar und kann durch jede Person heruntergeladen werden.\n",
    "\n",
    "**Preis:** Das Dataset wird kostenlos zu Verfügung gestellt.\n",
    "\n",
    "#### Inhaltliche Analyse und Schwierigkeiten \n",
    "Die drei relevanten CSV-Dateien MainCategoryCatalogue, PlantCategoryCatalogue und SubCategoryCatalogue sind ausgelagerte Kategorien Definitionen. Diese Dateien sind immer gleich aufgebaut. Zuerst wird die ID angegeben und anschliessend die jeweilige Textbeschreibung in verschiedenen Sprachen (de, fr, it und en). In der PlantCategoryCatalogue Datei werden die detaillierten Kraftwerkstypen angegeben."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plantCategory = pd.read_csv(\"./DATA/solar_powerplants/PlantCategoryCatalogue.csv\", delimiter=\",\")\n",
    "plantCategory.head(100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:08.317904Z",
     "start_time": "2024-05-25T19:29:08.312939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Catalogue_id                     de                                  fr  \\\n0    plantcat_1      Abwasserkraftwerk         Centrale sur les eaux usées   \n1    plantcat_2       Ausleitkraftwerk              Centrale de dérivation   \n2    plantcat_3  Dotierwasserkraftwerk                Centrale de dotation   \n3    plantcat_4     Durchlaufkraftwerk            Centrale au fil de l’eau   \n4    plantcat_5   Trinkwasserkraftwerk          Centrale sur l’eau potable   \n5    plantcat_6  Pumpspeicherkraftwerk       Centrale de pompage-turbinage   \n6    plantcat_7      Speicherkraftwerk             Centrale à accumulation   \n7    plantcat_8               Angebaut                             Ajoutée   \n8    plantcat_9             Integriert                            Intégrée   \n9   plantcat_10            Freistehend                              Isolée   \n10  plantcat_11        Biomassenutzung             Utilisation de biomasse   \n11  plantcat_12    Kehrichtverbrennung  Incinération des ordures ménagères   \n12  plantcat_13      Abwasserreinigung                  Épuration des eaux   \n\n                                    it                          en  \n0         Centrale ad acqua di scarico      Wastewater power plant  \n1               Centrale a derivazione       Diversion power plant  \n2       Centrale ad acqua di dotazione                  Weir plant  \n3        Centrale ad acque di deflusso      Continuous power plant  \n4           Centrale ad acqua potabile  Drinking water power plant  \n5    Centrale di pompaggio-turbinaggio  Pumped storage power plant  \n6            Centrale ad accumulazione         Storage power plant  \n7                              Annesso                    Attached  \n8                            Integrato                  Integrated  \n9                              Isolato                Freestanding  \n10             Utilisation de biomasse               Biomass usage  \n11           Incenerimento dei rifiuti          Waste incineration  \n12  Depurazione delle acque di scarico        Wastewater treatment  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Catalogue_id</th>\n      <th>de</th>\n      <th>fr</th>\n      <th>it</th>\n      <th>en</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>plantcat_1</td>\n      <td>Abwasserkraftwerk</td>\n      <td>Centrale sur les eaux usées</td>\n      <td>Centrale ad acqua di scarico</td>\n      <td>Wastewater power plant</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>plantcat_2</td>\n      <td>Ausleitkraftwerk</td>\n      <td>Centrale de dérivation</td>\n      <td>Centrale a derivazione</td>\n      <td>Diversion power plant</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>plantcat_3</td>\n      <td>Dotierwasserkraftwerk</td>\n      <td>Centrale de dotation</td>\n      <td>Centrale ad acqua di dotazione</td>\n      <td>Weir plant</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>plantcat_4</td>\n      <td>Durchlaufkraftwerk</td>\n      <td>Centrale au fil de l’eau</td>\n      <td>Centrale ad acque di deflusso</td>\n      <td>Continuous power plant</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>plantcat_5</td>\n      <td>Trinkwasserkraftwerk</td>\n      <td>Centrale sur l’eau potable</td>\n      <td>Centrale ad acqua potabile</td>\n      <td>Drinking water power plant</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>plantcat_6</td>\n      <td>Pumpspeicherkraftwerk</td>\n      <td>Centrale de pompage-turbinage</td>\n      <td>Centrale di pompaggio-turbinaggio</td>\n      <td>Pumped storage power plant</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>plantcat_7</td>\n      <td>Speicherkraftwerk</td>\n      <td>Centrale à accumulation</td>\n      <td>Centrale ad accumulazione</td>\n      <td>Storage power plant</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>plantcat_8</td>\n      <td>Angebaut</td>\n      <td>Ajoutée</td>\n      <td>Annesso</td>\n      <td>Attached</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>plantcat_9</td>\n      <td>Integriert</td>\n      <td>Intégrée</td>\n      <td>Integrato</td>\n      <td>Integrated</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>plantcat_10</td>\n      <td>Freistehend</td>\n      <td>Isolée</td>\n      <td>Isolato</td>\n      <td>Freestanding</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>plantcat_11</td>\n      <td>Biomassenutzung</td>\n      <td>Utilisation de biomasse</td>\n      <td>Utilisation de biomasse</td>\n      <td>Biomass usage</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>plantcat_12</td>\n      <td>Kehrichtverbrennung</td>\n      <td>Incinération des ordures ménagères</td>\n      <td>Incenerimento dei rifiuti</td>\n      <td>Waste incineration</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>plantcat_13</td>\n      <td>Abwasserreinigung</td>\n      <td>Épuration des eaux</td>\n      <td>Depurazione delle acque di scarico</td>\n      <td>Wastewater treatment</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 177
  },
  {
   "cell_type": "markdown",
   "source": [
    "Laden der CSV Datei in die SQLite Datenbank."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for index, row in plantCategory.iterrows():\n",
    "    catalogueId = '\"' + row[\"Catalogue_id\"] + '\"'\n",
    "    de = '\"' + row[\"de\"] + '\"'\n",
    "    fr = '\"' + row[\"fr\"] + '\"'\n",
    "    it = '\"' + row[\"it\"] + '\"'\n",
    "    en = '\"' + row[\"en\"] + '\"'\n",
    "    sql = \"INSERT INTO plantCategory VALUES({},{},{},{},{})\".format(catalogueId, de, fr, it, en)\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:08.322159Z",
     "start_time": "2024-05-25T19:29:08.319077Z"
    }
   },
   "execution_count": 178
  },
  {
   "cell_type": "markdown",
   "source": [
    "Die MainCategoryCatalogue Datei liefert die Haupt-Kraftwerkskategorien. Hier wird unterschieden aus welchem Energieträger Strom produziert wird. Für die vorliegende Arbeit ist die maincat_2 \"Übrige erneuerbaren Energien\" relevant."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "mainCategory = pd.read_csv(\"./DATA/solar_powerplants/MainCategoryCatalogue.csv\", delimiter=\",\")\n",
    "mainCategory.info()\n",
    "mainCategory.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:08.328179Z",
     "start_time": "2024-05-25T19:29:08.322768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Catalogue_id  4 non-null      object\n",
      " 1   de            4 non-null      object\n",
      " 2   fr            4 non-null      object\n",
      " 3   it            4 non-null      object\n",
      " 4   en            4 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 288.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": "  Catalogue_id                           de                             fr  \\\n0    maincat_1                  Wasserkraft            Énergie hydraulique   \n1    maincat_2  Übrige erneuerbare Energien  Autres énergies renouvelables   \n2    maincat_3                  Kernenergie              Énergie nucléaire   \n3    maincat_4        Fossile Energieträger   Agents énergétiques fossiles   \n\n                           it                        en  \n0                Forza idrica       Hydroelectric power  \n1   Altre energie rinnovabili  Other renewable energies  \n2            Energia nucleare            Nuclear energy  \n3  Vettori energetici fossili               Fossil fuel  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Catalogue_id</th>\n      <th>de</th>\n      <th>fr</th>\n      <th>it</th>\n      <th>en</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>maincat_1</td>\n      <td>Wasserkraft</td>\n      <td>Énergie hydraulique</td>\n      <td>Forza idrica</td>\n      <td>Hydroelectric power</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>maincat_2</td>\n      <td>Übrige erneuerbare Energien</td>\n      <td>Autres énergies renouvelables</td>\n      <td>Altre energie rinnovabili</td>\n      <td>Other renewable energies</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>maincat_3</td>\n      <td>Kernenergie</td>\n      <td>Énergie nucléaire</td>\n      <td>Energia nucleare</td>\n      <td>Nuclear energy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>maincat_4</td>\n      <td>Fossile Energieträger</td>\n      <td>Agents énergétiques fossiles</td>\n      <td>Vettori energetici fossili</td>\n      <td>Fossil fuel</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 179
  },
  {
   "cell_type": "markdown",
   "source": [
    "Laden der CSV Datei in die SQLite Datenbank."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for index, row in mainCategory.iterrows():\n",
    "    catalogueId = '\"' + row[\"Catalogue_id\"] + '\"'\n",
    "    de = '\"' + row[\"de\"] + '\"'\n",
    "    fr = '\"' + row[\"fr\"] + '\"'\n",
    "    it = '\"' + row[\"it\"] + '\"'\n",
    "    en = '\"' + row[\"en\"] + '\"'\n",
    "    sql = \"INSERT INTO mainCategory VALUES({},{},{},{},{})\".format(catalogueId, de, fr, it, en)\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:08.336361Z",
     "start_time": "2024-05-25T19:29:08.328864Z"
    }
   },
   "execution_count": 180
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wie in der Interpretierbarkeit erläutert ist die SubCategoryCatalogue Datei die aussagekräftigste für diese Arbeit. Mit der subcat_2 ID werden alle Photovoltaik Produktionsanlagen beschrieben."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Importieren der Unterkategorien\n",
    "subCategory = pd.read_csv(\"./DATA/solar_powerplants/SubCategoryCatalogue.csv\", delimiter=\",\")\n",
    "subCategory.info()\n",
    "subCategory.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:08.342789Z",
     "start_time": "2024-05-25T19:29:08.336932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Catalogue_id  10 non-null     object\n",
      " 1   de            10 non-null     object\n",
      " 2   fr            10 non-null     object\n",
      " 3   it            10 non-null     object\n",
      " 4   en            10 non-null     object\n",
      "dtypes: object(5)\n",
      "memory usage: 528.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": "  Catalogue_id            de                   fr                     it  \\\n0     subcat_1   Wasserkraft  Énergie hydraulique           Forza idrica   \n1     subcat_2  Photovoltaik      Photovoltaïque   Energia fotovoltaica    \n2     subcat_3   Windenergie     Énergie éolienne         Energia eolica   \n3     subcat_4     Biomasse              Biomasse              Biomassa    \n4     subcat_5    Geothermie           Géothermie              Geotermia   \n5     subcat_6   Kernenergie    Énergie nucléaire       Energia nucleare   \n6     subcat_7         Erdöl              Pétrole               Petrolio   \n7     subcat_8        Erdgas          Gaz naturel           Gas naturale   \n8     subcat_9         Kohle              Charbon                Carbone   \n9    subcat_10      Abfälle              Déchets                Rifiuti    \n\n                    en  \n0  Hydroelectric power  \n1         Photovoltaic  \n2          Wind energy  \n3             Biomass   \n4    Geothermal energy  \n5       Nuclear energy  \n6            Crude oil  \n7          Natural gas  \n8                Coal   \n9               Waste   ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Catalogue_id</th>\n      <th>de</th>\n      <th>fr</th>\n      <th>it</th>\n      <th>en</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>subcat_1</td>\n      <td>Wasserkraft</td>\n      <td>Énergie hydraulique</td>\n      <td>Forza idrica</td>\n      <td>Hydroelectric power</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>subcat_2</td>\n      <td>Photovoltaik</td>\n      <td>Photovoltaïque</td>\n      <td>Energia fotovoltaica</td>\n      <td>Photovoltaic</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>subcat_3</td>\n      <td>Windenergie</td>\n      <td>Énergie éolienne</td>\n      <td>Energia eolica</td>\n      <td>Wind energy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>subcat_4</td>\n      <td>Biomasse</td>\n      <td>Biomasse</td>\n      <td>Biomassa</td>\n      <td>Biomass</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>subcat_5</td>\n      <td>Geothermie</td>\n      <td>Géothermie</td>\n      <td>Geotermia</td>\n      <td>Geothermal energy</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>subcat_6</td>\n      <td>Kernenergie</td>\n      <td>Énergie nucléaire</td>\n      <td>Energia nucleare</td>\n      <td>Nuclear energy</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>subcat_7</td>\n      <td>Erdöl</td>\n      <td>Pétrole</td>\n      <td>Petrolio</td>\n      <td>Crude oil</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>subcat_8</td>\n      <td>Erdgas</td>\n      <td>Gaz naturel</td>\n      <td>Gas naturale</td>\n      <td>Natural gas</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>subcat_9</td>\n      <td>Kohle</td>\n      <td>Charbon</td>\n      <td>Carbone</td>\n      <td>Coal</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>subcat_10</td>\n      <td>Abfälle</td>\n      <td>Déchets</td>\n      <td>Rifiuti</td>\n      <td>Waste</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 181
  },
  {
   "cell_type": "markdown",
   "source": [
    "Laden der CSV Datei in die SQLite Datenbank."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for index, row in subCategory.iterrows():\n",
    "    catalogueId = '\"' + row[\"Catalogue_id\"] + '\"'\n",
    "    de = '\"' + row[\"de\"] + '\"'\n",
    "    fr = '\"' + row[\"fr\"] + '\"'\n",
    "    it = '\"' + row[\"it\"] + '\"'\n",
    "    en = '\"' + row[\"en\"] + '\"'\n",
    "    sql = \"INSERT INTO subCategory VALUES({},{},{},{},{})\".format(catalogueId, de, fr, it, en)\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:08.347299Z",
     "start_time": "2024-05-25T19:29:08.343422Z"
    }
   },
   "execution_count": 182
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Die Hauptdatei ElectricityProductionPlant beinhaltet 203473 Anlagen. Die Datei ist nicht komplett. Die PlantCategory sowie die Koordinaten sind nicht für sämtliche Anlagen gepflegt. Dies stellt für die weitere Analyse kein Problem dar da für jede Anlage eine Adresse mit PLZ und Ortsname verfügbar. Dadurch können diese Kraftwerke direkt einer Smartmeter Gemeinde zugewiesen werden. Die PlantCategory ist sekundär, da die SubCategory relevant ist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Importieren der Solar Kraftanlagen\n",
    "electricityProductionPlant = pd.read_csv(\"./DATA/solar_powerplants/ElectricityProductionPlant.csv\", delimiter=\",\")\n",
    "electricityProductionPlant.info()\n",
    "electricityProductionPlant.head(10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T20:41:04.068814Z",
     "start_time": "2024-05-25T20:41:03.853931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 203474 entries, 0 to 203473\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   xtf_id                203474 non-null  int64  \n",
      " 1   Address               203474 non-null  object \n",
      " 2   PostCode              203474 non-null  int64  \n",
      " 3   Municipality          203474 non-null  object \n",
      " 4   Canton                203474 non-null  object \n",
      " 5   BeginningOfOperation  203474 non-null  object \n",
      " 6   InitialPower          203474 non-null  float64\n",
      " 7   TotalPower            203474 non-null  float64\n",
      " 8   MainCategory          203474 non-null  object \n",
      " 9   SubCategory           203474 non-null  object \n",
      " 10  PlantCategory         198553 non-null  object \n",
      " 11  _x                    196057 non-null  float64\n",
      " 12  _y                    196057 non-null  float64\n",
      "dtypes: float64(4), int64(2), object(7)\n",
      "memory usage: 20.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": "   xtf_id                 Address  PostCode Municipality Canton  \\\n0   14727       Schlossstrasse 15      4147     Aesch BL     BL   \n1   14728          Ob der Steig 1      5082      Kaisten     AG   \n2   10164                Gässli 4      3114    Wichtrach     BE   \n3   10794    Diemtigtalstrasse 46      3753          Oey     BE   \n4    9476       Holzweidstrasse 8      8340       Hinwil     ZH   \n5   14729  Lärchentobelstrasse 33      8700     Küsnacht     ZH   \n6   14730      Schulhaustrasse 24      9470        Buchs     SG   \n7    9365       Renggerstrasse 58      5000        Aarau     AG   \n8   14742             Gartenweg 8      5018   Erlinsbach     AG   \n9   14747       Hofbergstrasse 21      9500          Wil     SG   \n\n  BeginningOfOperation  InitialPower  TotalPower MainCategory SubCategory  \\\n0           2009-05-05         14.65       18.81    maincat_2    subcat_2   \n1           2011-10-28          5.80        5.80    maincat_2    subcat_2   \n2           2008-10-07          3.00        3.00    maincat_2    subcat_2   \n3           2008-06-27          8.40        8.40    maincat_2    subcat_2   \n4           2006-04-21          4.80        4.80    maincat_2    subcat_2   \n5           2010-11-04         21.80       21.80    maincat_2    subcat_2   \n6           2008-09-24          3.60        3.60    maincat_2    subcat_2   \n7           2006-09-14          1.60        1.60    maincat_2    subcat_2   \n8           2011-09-19          7.70        7.70    maincat_2    subcat_2   \n9           2011-12-16         50.90       50.90    maincat_2    subcat_2   \n\n  PlantCategory         _x         _y  \n0    plantcat_9  2611936.0  1257011.0  \n1    plantcat_8  2645758.0  1265094.0  \n2    plantcat_8  2610547.0  1188979.0  \n3    plantcat_8  2610529.0  1167346.0  \n4    plantcat_8  2705863.0  1240553.0  \n5    plantcat_9  2687331.0  1241205.0  \n6    plantcat_8  2754146.0  1225474.0  \n7    plantcat_8  2645858.0  1248560.0  \n8    plantcat_9  2643326.0  1250567.0  \n9    plantcat_9  2721432.0  1258999.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>xtf_id</th>\n      <th>Address</th>\n      <th>PostCode</th>\n      <th>Municipality</th>\n      <th>Canton</th>\n      <th>BeginningOfOperation</th>\n      <th>InitialPower</th>\n      <th>TotalPower</th>\n      <th>MainCategory</th>\n      <th>SubCategory</th>\n      <th>PlantCategory</th>\n      <th>_x</th>\n      <th>_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14727</td>\n      <td>Schlossstrasse 15</td>\n      <td>4147</td>\n      <td>Aesch BL</td>\n      <td>BL</td>\n      <td>2009-05-05</td>\n      <td>14.65</td>\n      <td>18.81</td>\n      <td>maincat_2</td>\n      <td>subcat_2</td>\n      <td>plantcat_9</td>\n      <td>2611936.0</td>\n      <td>1257011.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14728</td>\n      <td>Ob der Steig 1</td>\n      <td>5082</td>\n      <td>Kaisten</td>\n      <td>AG</td>\n      <td>2011-10-28</td>\n      <td>5.80</td>\n      <td>5.80</td>\n      <td>maincat_2</td>\n      <td>subcat_2</td>\n      <td>plantcat_8</td>\n      <td>2645758.0</td>\n      <td>1265094.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10164</td>\n      <td>Gässli 4</td>\n      <td>3114</td>\n      <td>Wichtrach</td>\n      <td>BE</td>\n      <td>2008-10-07</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>maincat_2</td>\n      <td>subcat_2</td>\n      <td>plantcat_8</td>\n      <td>2610547.0</td>\n      <td>1188979.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10794</td>\n      <td>Diemtigtalstrasse 46</td>\n      <td>3753</td>\n      <td>Oey</td>\n      <td>BE</td>\n      <td>2008-06-27</td>\n      <td>8.40</td>\n      <td>8.40</td>\n      <td>maincat_2</td>\n      <td>subcat_2</td>\n      <td>plantcat_8</td>\n      <td>2610529.0</td>\n      <td>1167346.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9476</td>\n      <td>Holzweidstrasse 8</td>\n      <td>8340</td>\n      <td>Hinwil</td>\n      <td>ZH</td>\n      <td>2006-04-21</td>\n      <td>4.80</td>\n      <td>4.80</td>\n      <td>maincat_2</td>\n      <td>subcat_2</td>\n      <td>plantcat_8</td>\n      <td>2705863.0</td>\n      <td>1240553.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>14729</td>\n      <td>Lärchentobelstrasse 33</td>\n      <td>8700</td>\n      <td>Küsnacht</td>\n      <td>ZH</td>\n      <td>2010-11-04</td>\n      <td>21.80</td>\n      <td>21.80</td>\n      <td>maincat_2</td>\n      <td>subcat_2</td>\n      <td>plantcat_9</td>\n      <td>2687331.0</td>\n      <td>1241205.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>14730</td>\n      <td>Schulhaustrasse 24</td>\n      <td>9470</td>\n      <td>Buchs</td>\n      <td>SG</td>\n      <td>2008-09-24</td>\n      <td>3.60</td>\n      <td>3.60</td>\n      <td>maincat_2</td>\n      <td>subcat_2</td>\n      <td>plantcat_8</td>\n      <td>2754146.0</td>\n      <td>1225474.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>9365</td>\n      <td>Renggerstrasse 58</td>\n      <td>5000</td>\n      <td>Aarau</td>\n      <td>AG</td>\n      <td>2006-09-14</td>\n      <td>1.60</td>\n      <td>1.60</td>\n      <td>maincat_2</td>\n      <td>subcat_2</td>\n      <td>plantcat_8</td>\n      <td>2645858.0</td>\n      <td>1248560.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>14742</td>\n      <td>Gartenweg 8</td>\n      <td>5018</td>\n      <td>Erlinsbach</td>\n      <td>AG</td>\n      <td>2011-09-19</td>\n      <td>7.70</td>\n      <td>7.70</td>\n      <td>maincat_2</td>\n      <td>subcat_2</td>\n      <td>plantcat_9</td>\n      <td>2643326.0</td>\n      <td>1250567.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>14747</td>\n      <td>Hofbergstrasse 21</td>\n      <td>9500</td>\n      <td>Wil</td>\n      <td>SG</td>\n      <td>2011-12-16</td>\n      <td>50.90</td>\n      <td>50.90</td>\n      <td>maincat_2</td>\n      <td>subcat_2</td>\n      <td>plantcat_9</td>\n      <td>2721432.0</td>\n      <td>1258999.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 237
  },
  {
   "cell_type": "markdown",
   "source": [
    "Im Kanton Luzern sind 10238 Anlagen registriert. In diesem Subset gibt es ebenfalls Lücken im Bereich der Koordinaten und PlantCategory. Die unten dargestellte Tabelle zeigt die totale Produktionsleistung gruppiert nach den Gemeinden. In dieser Tabelle wird ersichtlich, dass einige Schreibfehler vorhanden sind und dadurch die Gruppierung verfälschen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anzahl Solaranlagen im Kanton Luzern:  10238 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10238 entries, 32 to 203462\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   xtf_id                10238 non-null  int64  \n",
      " 1   Address               10238 non-null  object \n",
      " 2   PostCode              10238 non-null  int64  \n",
      " 3   Municipality          10238 non-null  object \n",
      " 4   Canton                10238 non-null  object \n",
      " 5   BeginningOfOperation  10238 non-null  object \n",
      " 6   InitialPower          10238 non-null  float64\n",
      " 7   TotalPower            10238 non-null  float64\n",
      " 8   MainCategory          10238 non-null  object \n",
      " 9   SubCategory           10238 non-null  object \n",
      " 10  PlantCategory         10073 non-null  object \n",
      " 11  _x                    9932 non-null   float64\n",
      " 12  _y                    9932 non-null   float64\n",
      "dtypes: float64(4), int64(2), object(7)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": "              TotalPower\nMunicipality            \nAdligenswil      2225.49\nAdlingenswil       23.02\nAdsligenswil       13.53\nAesch            1566.78\nAesch              10.26\n...                  ...\nWohlhusen          16.64\nWolhsuen            9.00\nWolhusen         5403.48\nZell             2089.21\nZell LU           308.22\n\n[224 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TotalPower</th>\n    </tr>\n    <tr>\n      <th>Municipality</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Adligenswil</th>\n      <td>2225.49</td>\n    </tr>\n    <tr>\n      <th>Adlingenswil</th>\n      <td>23.02</td>\n    </tr>\n    <tr>\n      <th>Adsligenswil</th>\n      <td>13.53</td>\n    </tr>\n    <tr>\n      <th>Aesch</th>\n      <td>1566.78</td>\n    </tr>\n    <tr>\n      <th>Aesch</th>\n      <td>10.26</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Wohlhusen</th>\n      <td>16.64</td>\n    </tr>\n    <tr>\n      <th>Wolhsuen</th>\n      <td>9.00</td>\n    </tr>\n    <tr>\n      <th>Wolhusen</th>\n      <td>5403.48</td>\n    </tr>\n    <tr>\n      <th>Zell</th>\n      <td>2089.21</td>\n    </tr>\n    <tr>\n      <th>Zell LU</th>\n      <td>308.22</td>\n    </tr>\n  </tbody>\n</table>\n<p>224 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electricityProductionPlantLU = electricityProductionPlant.query('Canton == \"LU\" and SubCategory == \"subcat_2\"')\n",
    "print(\"\\nAnzahl Solaranlagen im Kanton Luzern: \", len(electricityProductionPlantLU), \"\\n\")\n",
    "electricityProductionPlantLU.info()\n",
    "electricityProductionPlantLU[[\"Municipality\", \"TotalPower\"]].groupby('Municipality').sum()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T20:41:06.979487Z",
     "start_time": "2024-05-25T20:41:06.956336Z"
    }
   },
   "execution_count": 238
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aufgrund der Schreibfehler wird nach der PLZ gruppiert und in einer eigenen Datenbank View \"solarPlantsLUbfsId\" die Gemeindenamen sowie die BFS-ID hinzugefügt. Dadurch lassen sich die weiteren Daten miteinander verbinden. Während der Analyse im Zusammenhang mit dem verbinden der PLZ auf die BFS-ID wurde festgestellt, dass die PLZ 6000, 6002, 6011, 6021, 6161 und 6281 in der erstellten Tabelle gefehlt haben. Diese wurden entsprechend manuell nachgepflegt."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          TotalPower\nPostCode            \n4806         1238.15\n4915          541.97\n5735          612.36\n6000          464.68\n6002         1330.12\n...              ...\n6353         2156.50\n6354          829.58\n6356          113.86\n6403            7.48\n6404          409.72\n\n[137 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TotalPower</th>\n    </tr>\n    <tr>\n      <th>PostCode</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4806</th>\n      <td>1238.15</td>\n    </tr>\n    <tr>\n      <th>4915</th>\n      <td>541.97</td>\n    </tr>\n    <tr>\n      <th>5735</th>\n      <td>612.36</td>\n    </tr>\n    <tr>\n      <th>6000</th>\n      <td>464.68</td>\n    </tr>\n    <tr>\n      <th>6002</th>\n      <td>1330.12</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6353</th>\n      <td>2156.50</td>\n    </tr>\n    <tr>\n      <th>6354</th>\n      <td>829.58</td>\n    </tr>\n    <tr>\n      <th>6356</th>\n      <td>113.86</td>\n    </tr>\n    <tr>\n      <th>6403</th>\n      <td>7.48</td>\n    </tr>\n    <tr>\n      <th>6404</th>\n      <td>409.72</td>\n    </tr>\n  </tbody>\n</table>\n<p>137 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electricityProductionPlantLU[[\"PostCode\", \"TotalPower\"]].groupby('PostCode').sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T20:41:10.966538Z",
     "start_time": "2024-05-25T20:41:10.958897Z"
    }
   },
   "execution_count": 239
  },
  {
   "cell_type": "markdown",
   "source": [
    "Während dem weiteren Mapping wurde festgestellt, dass die PLZ 6403 und 6312 nicht zum Kanton Luzern gehören. Wenn diese Einträge genau betrachtet werden, liegt der Verdacht nahe, dass diese Einträge nicht korrekt sind. Die PLZ 6312 wurde wohl falsch eingetippt und könnte 6212 St. Erhard LU sein, da auch die Adresse an diesen Ort verweist. Bei der PLZ 6403 wurde wohl der Kanton falsch angegeben. Diese Werte werden korrigiert aber auf eine weitere Validierung der Adressen wird aus zeitgründen verzichtet. Die Qualität der Daten wird durch die festgestellten Mängel gemindert."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "electricityProductionPlantLU.query('PostCode == 6403 or PostCode == 6312')\n",
    "electricityProductionPlant.at[101656, 'PostCode'] = 6212\n",
    "electricityProductionPlant.at[138741, 'Canton'] = 'SZ'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T20:42:35.663821Z",
     "start_time": "2024-05-25T20:42:35.660466Z"
    }
   },
   "execution_count": 242
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "        xtf_id         Address  PostCode       Municipality Canton  \\\n101656  168209    Im Wiberg 48      6212         St. Erhard     LU   \n138741  218255  Talstrasse 31A      6403  Küssnacht am rigi     SZ   \n\n       BeginningOfOperation  InitialPower  TotalPower MainCategory  \\\n101656           2020-07-14         13.60       13.60    maincat_2   \n138741           2022-03-11          7.48        7.48    maincat_2   \n\n       SubCategory PlantCategory         _x         _y  \n101656    subcat_2    plantcat_8  2679696.0  1227599.0  \n138741    subcat_2    plantcat_8  2675871.0  1215913.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>xtf_id</th>\n      <th>Address</th>\n      <th>PostCode</th>\n      <th>Municipality</th>\n      <th>Canton</th>\n      <th>BeginningOfOperation</th>\n      <th>InitialPower</th>\n      <th>TotalPower</th>\n      <th>MainCategory</th>\n      <th>SubCategory</th>\n      <th>PlantCategory</th>\n      <th>_x</th>\n      <th>_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>101656</th>\n      <td>168209</td>\n      <td>Im Wiberg 48</td>\n      <td>6212</td>\n      <td>St. Erhard</td>\n      <td>LU</td>\n      <td>2020-07-14</td>\n      <td>13.60</td>\n      <td>13.60</td>\n      <td>maincat_2</td>\n      <td>subcat_2</td>\n      <td>plantcat_8</td>\n      <td>2679696.0</td>\n      <td>1227599.0</td>\n    </tr>\n    <tr>\n      <th>138741</th>\n      <td>218255</td>\n      <td>Talstrasse 31A</td>\n      <td>6403</td>\n      <td>Küssnacht am rigi</td>\n      <td>SZ</td>\n      <td>2022-03-11</td>\n      <td>7.48</td>\n      <td>7.48</td>\n      <td>maincat_2</td>\n      <td>subcat_2</td>\n      <td>plantcat_8</td>\n      <td>2675871.0</td>\n      <td>1215913.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electricityProductionPlant.query('xtf_id == 168209 or xtf_id == 218255')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T20:43:36.138381Z",
     "start_time": "2024-05-25T20:43:36.128811Z"
    }
   },
   "execution_count": 245
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mit diesen Anpassungen und Erkenntnissen können die Daten in die Datenbank geladen werden. Weiter und tiefere Analyse folgen in den weiteren Schritten.\n",
    "Vor dem Import werden die na Werte noch mit NULL überschrieben, damit die SQLite Datenbank diese als solche versteht."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "electricityProductionPlant.replace(np.nan, \"NULL\", inplace=True)\n",
    "for index, row in electricityProductionPlant.iterrows():\n",
    "    mainCategoryId = '\"' + row[\"MainCategory\"] + '\"'\n",
    "    subCategoryId = '\"' + row[\"SubCategory\"] + '\"'\n",
    "    canton = '\"' + row[\"Canton\"] + '\"'\n",
    "    xCor = row[\"_x\"]\n",
    "    yCor = row[\"_y\"]\n",
    "    \n",
    "    if isinstance(row[\"PlantCategory\"], str):\n",
    "        plantCategoryId = '\"' + row[\"PlantCategory\"] + '\"'\n",
    "    else:\n",
    "        plantCategoryId = \"NULL\"\n",
    "        \n",
    "    sql = \"INSERT INTO solarPlants VALUES(NULL,{},{},{},{},{},{},{},{},{})\".format(row[\"xtf_id\"], row[\"PostCode\"], canton, row[\"TotalPower\"], mainCategoryId, subCategoryId, plantCategoryId, xCor, yCor)\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:14.453768Z",
     "start_time": "2024-05-25T19:29:08.581348Z"
    }
   },
   "execution_count": 186
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Importieren Demografie Daten Indikator\n",
    "demoIndicator = pd.read_csv(\"./DATA/key_figures_communities/Indicator_DemoData.csv\", delimiter=\";\")\n",
    "\n",
    "for index, row in demoIndicator.iterrows():\n",
    "    indicatorId = '\"' + row[\"INDICATORS\"] + '\"'\n",
    "    de = '\"' + row[\"DE\"] + '\"'\n",
    "    \n",
    "    sql = \"INSERT INTO indicator VALUES({},{})\".format(indicatorId, de)\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:14.465330Z",
     "start_time": "2024-05-25T19:29:14.454453Z"
    }
   },
   "outputs": [],
   "execution_count": 187
  },
  {
   "cell_type": "code",
   "source": [
    "#Importieren Unit Messeinheit\n",
    "unitMeas = pd.read_csv(\"./DATA/key_figures_communities/unit_mes_DemoData.csv\", delimiter=\";\")\n",
    "\n",
    "for index, row in unitMeas.iterrows():\n",
    "    unitMeasId = '\"' + row[\"UNIT_MES\"] + '\"'\n",
    "    unit = '\"' + row[\"Einheit\"] + '\"'\n",
    "    \n",
    "    sql = \"INSERT INTO unit VALUES({}, {})\".format(unitMeasId, unit)\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:14.469359Z",
     "start_time": "2024-05-25T19:29:14.465994Z"
    }
   },
   "outputs": [],
   "execution_count": 188
  },
  {
   "cell_type": "code",
   "source": [
    "#Importieren demoValue\n",
    "demoValue = pd.read_csv(\"./DATA/key_figures_communities/ts-x-21.03.01.csv\", delimiter=\";\", dtype={'PERIOD_REF': str, 'PERIOD_COMP': str, 'REGION': str})\n",
    "demoValue.replace(\"CH\", 0, inplace=True)\n",
    "demoValue.replace(np.nan, \"NULL\", inplace=True)\n",
    "\n",
    "for index, row in demoValue.iterrows():\n",
    "    period = row[\"PERIOD_REF\"]\n",
    "    if isinstance(period, str):\n",
    "        period = '\"' + period + '\"'\n",
    "    else:\n",
    "        period = str(period)\n",
    "        period = '\"' + period + '\"'\n",
    "        \n",
    "    indicator = '\"' + row[\"INDICATORS\"] + '\"'\n",
    "    unit = '\"' + row[\"UNIT_MES\"] + '\"'\n",
    "    \n",
    "    sql = \"INSERT INTO demoValue VALUES(NULL,{},{},{},{},{})\".format(row[\"CODE_REGION\"], period, indicator, unit, row[\"VALUE\"])\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:29:16.527894Z",
     "start_time": "2024-05-25T19:29:14.469981Z"
    }
   },
   "outputs": [],
   "execution_count": 189
  },
  {
   "cell_type": "markdown",
   "source": [
    "--> Darstellen wann der Messbeginn ist und bis Wann. So kann ich bei den MeteoDaten darauf referenzieren und den Zeitraum begründen. Sollte 2020-12-30 00:00 - 2024-03-06 23:00 sein."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Importieren SmartMeter DATA\n",
    "path = './DATA/smartmeter'\n",
    "csv_files = glob.glob(path + '/*.csv.gz')\n",
    "df_list = (pd.read_csv(file) for file in csv_files)\n",
    "\n",
    "smartmeter_df = pd.concat(df_list, ignore_index=True)\n",
    "smartmeter_df[\"timestamp\"] = '\"' + smartmeter_df[\"timestamp\"] + '\"'\n",
    "\n",
    "for index, row in smartmeter_df.iterrows():\n",
    "    sql = \"INSERT INTO smartmeter VALUES(NULL,{},{},{},{})\".format(row[\"area_code\"], row[\"timestamp\"], row[\"num_meter\"], row[\"value_kwh\"])\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "connection.commit()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:33:45.381695Z",
     "start_time": "2024-05-25T19:29:16.528616Z"
    }
   },
   "outputs": [],
   "execution_count": 190
  },
  {
   "cell_type": "code",
   "source": [
    "#Test Date Time and manipulation\n",
    "\n",
    "#input = '202001240000'\n",
    "#output = '%Y%m%d%H%M'\n",
    "\n",
    "#date = input.strftime('%Y-%m-%d %H:%M')\n",
    "#date = datetime.datetime.strptime('202001240000', '%Y%m%d%H%M').strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "#df = pd.DataFrame({'date':['2020012400', '2020012400']})\n",
    "\n",
    "#print(df)\n",
    "\n",
    "#df['date'] += '00'\n",
    "\n",
    "#print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:33:45.383912Z",
     "start_time": "2024-05-25T19:33:45.382403Z"
    }
   },
   "outputs": [],
   "execution_count": 191
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Historische Meteo Daten\n",
    "**Herausgeber:**\n",
    "Eidgenössisches Departement des Innern (EDI)\n",
    "Bundesamt für Meteorologie und Klimatologie MeteoSchweiz\n",
    "Wird zitiert als MeteoSchweiz [Zitierwunsch](https://gate.meteoswiss.ch/idaweb/more.do)\n",
    "\n",
    "**Link:**\n",
    "https://gate.meteoswiss.ch/idaweb/more.do\n",
    "\n",
    "**Beschreibung:**\n",
    "Die historischen Meteodaten bestehen aus Archivdaten des Bodenmessnetzes von MeteoSchweiz. MeteoSchweiz liefert Messgrössen wie z.B. Niederschlag, Temperatur oder Sonnenstunden. Diese Informationen können Interessant sein, um festzustellen ob diese einen Effekt auf den Stromverbrauch haben. Die Daten können in Zehnminutenwerte, Stundenwerte, Tageswerte, Monatswerte oder Jahreswerte geladen werden. Die Daten können über das Web-Portal IDAWEB zusammengestellt und heruntergeladen werden. (MeteoSchweiz, [Online-Quelle](https://gate.meteoswiss.ch/idaweb/more.do)).\n",
    "\n",
    "**Zeitraum:**\n",
    "Es stehen alle Meteodaten seit Messbeginn zu Verfügung. Die Smartmeterdaten stehen für den Zeitraum vom 2020-12-30 00:00 - 2024-03-06 23:00 zu Verfügung. Aus diesem Grund wird für die Meteodaten derselbe Zeitraum gewählt.\n",
    "\n",
    "**Zweckerfüllung:**\n",
    "Mit den Meteodaten sollen gewisse Abhängigkeiten festgestellt werden. So wird z.B. erwartet, dass mit zunehmenden Sonnenstunden, der Strombedarf sinkt aufgrund der zahlreichen privaten Solaranlagen. Durch den Niederschlag soll festgestellt werden, ob dieser den Strombedarf positiv oder negativ beeinflusst auch in Kombination mit der Temperatur. Hat der Niederschlag einen merkbaren Einfluss, wenn in einem vergleichbaren Zeitraum die Temperatur gleich bleibt.\n",
    "Diese drei Parameter werden auf stündlicher Basis für den gewählten Zeitraum geladen.  Folgende Parameter werden erhoben:\n",
    "- Niederschlag, Stundensumme in Millimeter\n",
    "- Lufttemperatur 2m über Boden, Stundenmittel in Grad Celsius\n",
    "- Sonnenscheindauer, Stundensumme in Minuten\n",
    "\n",
    "Im Grundsatz werden die Anforderungen damit erfüllt.\n",
    "\n",
    "**Qualität (Glaubwürdigkeit, Nützlichkeit, Interpretierbarkeit, Schlüsselintegrität):**\n",
    "\n",
    "*Glaubwürdigkeit:* Die Glaubwürdigkeit ist gegeben, da es sich um die offizielle Meteo Stationen des Bundes handelt. Neben den Daten des Bundes stand die Quelle [Open-Meteo.com](https://open-meteo.com/en/docs/historical-weather-api) als API zur Auswahl. Auf diese wurde verzichtet. Dies aus den Gründen, dass die historischen Daten basierend auf Wetterstationen, Flugzeugen, Boyen, Radar und Satelliten Beobachtungen berechnet werden und nicht klar ist, wie genau diese Daten sind. Eine weitere Unsicherheit ist, dass die verwendeten Datasets auf Mittel- bis Langvorhersagen ausgerichtet sind sowie einen globalen Fokus haben [Open-Meteo.com](https://open-meteo.com/en/docs/historical-weather-api). Da im Projektteam die meteorologische Expertise fehlt zur Verifizierung wie gut diese Daten sind, werden die Daten von MeteoSchweiz verwendet.\n",
    "\n",
    "*Nützlichkeit:* Das IDAWEB Portal von MeteoSchweiz stellt die Messdaten der Messstationen zu Verfügung. Damit entsteht die Schwierigkeit, dass nicht pro BFS-ID oder PLZ direkt die gewünschten Messdaten zu Verfügung stehen. Während des Abfrageprozesses, müssen zuerst die potenziellen Messstationen ausgewählt werden. Danach folgen die gewünschten Messparameter sowie der Zeitraum. Daraus ergibt sich ein Set an Messdaten welches zu Verfügung steht. Beim Niederschlag steht eine gute Menge an Messtationen zu Verfügung, welche den Kanton Luzern gut abdecken. Im Bereich der Sonnenstunden und Temperatur ist dies jedoch nicht der Fall. Bei den Sonnenstunden gibt es generell kaum Messstationen. Bei der Temperatur gibt es verschiedene Messhöhen z.B. direkt am Boden, 5cm ab Boden oder 2m ab Boden. Teilweise wird auch keine Höhe angegeben. Die Messtationen mit einer Messhöhe von 2m erfüllen den internationalen Standard und sind dabei nicht der Witterung oder Sonnenstrahlung ausgesetzt, welche die Messwerte verfälschen würden (MeteoSchweiz, [Online-Quelle](https://www.meteoschweiz.admin.ch/wetter/wetter-und-klima-von-a-bis-z/temperatur.html)). \n",
    "Die geografische Abdeckung der Temperatur Messtationen mit 2m Höhe ist nicht flächendeckend. Bei den Temperatur Messstationen ohne Höhen Angabe, gibt es eine breitere Abdeckung jedoch mit der Ungewissheit, wie die Temperaturen gemessen werden. Je nach Position können grössere Schwankungen auftreten. Aus diesem Grund werden die Meteostationen gewählt, welche die Temperatur 2 Meter über dem Boden messen. Damit ist eine einheitliche Messmethodik gewährleistet und die Vergleichbarkeit gegeben. Damit die Daten nutzbar eingesetzt werden können, wird aufgrund der geografischen Position der Messstation die BFS-ID zugeordnet. Dies erfolgt manuell in einer gesonderten CSV-Datei. Die geografische Verteilung und Zuordnung folgt in der Analyse.\n",
    "\n",
    "*Interpretierbarkeit:* Nachdem die gewünschten Parameter gewählt wurden, werden die Messdaten exportiert. Es wird pro Messstation und Parameter eine TXT-Datei mit einer Legende erstellt und eine mit den Messdaten. Insgesamt sind dies 370 TXT-Dateien. In der Legende werden jeweils die Meteostation beschrieben mit der Bezeichnung, Parameter, Koordinate und ID. Zusätzlich gibt es ein Beschreibung zum Parameter. Aufgrund des TXT-Formats und keinen Trennzeichen wurden die Meteostationen manuell in der Datei meteoStation.csv erfasst. Dasselbe gilt für die drei Parameter. Die wurden manuell in die Datei parameter.csv geschrieben. Die Messstationen verfügen über keine PLZ oder BFS-ID, daher werden diese Informationen manuell in der CSV-Datei ergänzt.\n",
    "Die Messdaten TXT-Datei beinhaltet die Station-ID, Zeitstempel sowie den Wert, des Parameters. Die Bezeichnung des Parameters steht in der Spaltenbezeichnung. Es besteht viel manueller Aufwand und die Maschinen lesbarkeit ist nur bei den Messdaten TXT-Dateien gegeben. Daher ist die Interpretierbarkeit für den hier benötigten Kontext nur mit manuellem Aufwand gegeben. Zur Sicherung in der Datenbank, müssen die Daten angereichert werden damit die Daten später wieder korrekt zusammengesetzt werden können.\n",
    "\n",
    "*Schlüsselintegrität:* Die Messdaten TXT-Dateien haben aber keinen Primary Key, besitzen aber die Foreign-Key's der Messstationen-ID sowie der Parameter-ID. Damit lassen sich die Messdaten wieder zusammensetzen. Damit pro BFS-ID alle drei Parameter geladen werden können, wird eine Mapping-Tabelle benötigt welche jeweils die BFS-ID jeweils mit dem gewünschten Parameter der geografisch nächsten Meteostation verbindet.\n",
    "\n",
    "**Verfügbarkeit:** Die Daten stehen für Forschungs- und Lehrzwecke allen zu Verfügung. Es ist ein Registrierungsprozess notwendig, um Zugriff auf die Daten zu erhalten.\n",
    "\n",
    "**Preis:** Im Kontext von Forschungs- und Lehrzwecken können die Daten kostenlos genutzt werden. Eine kommerzielle Nutzung ist untersagt. Die Verwendung der Daten für Grafiken, Text oder Vorträge ist erlaubt mit entsprechender Kennzeichnung der Quelle mit MeteoSchweiz. (MeteoSchweiz, [Online-Quelle](https://gate.meteoswiss.ch/idaweb/more.do))\n",
    "\n",
    "#### Inhaltliche Analyse und Schwierigkeiten \n",
    "Die drei relevanten CSV-Dateien MainCategoryCatalogue, PlantCategoryCatalogue und SubCategoryCatalogue sind ausgelagerte Kategorien Definitionen. Diese Dateien sind immer gleich aufgebaut. Zuerst wird die ID angegeben und anschliessend die jeweilige Textbeschreibung in verschiedenen Sprachen (de, fr, it und en). In der PlantCategoryCatalogue Datei werden die detaillierten Kraftwerkstypen angegeben."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Import Meteo Parameter\n",
    "meteoParameter = pd.read_csv(\"./DATA/meteo/parameter.csv\", delimiter=\";\")\n",
    "\n",
    "meteoParameter.head()\n",
    "meteoParameter[\"parameterID\"] = '\"' + meteoParameter[\"parameterID\"] + '\"'\n",
    "meteoParameter[\"measure\"] = '\"' + meteoParameter[\"measure\"] + '\"'\n",
    "meteoParameter[\"description\"] = '\"' + meteoParameter[\"description\"] + '\"'\n",
    "\n",
    "for index, row in meteoParameter.iterrows():\n",
    "    sql = \"INSERT INTO meteoParameter VALUES({}, {}, {})\".format(row[\"parameterID\"], row[\"measure\"], row[\"description\"])\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:33:45.593447Z",
     "start_time": "2024-05-25T19:33:45.384590Z"
    }
   },
   "outputs": [],
   "execution_count": 192
  },
  {
   "cell_type": "code",
   "source": [
    "#Import Meteo Stations\n",
    "meteoStations = pd.read_csv(\"./DATA/meteo/meteoStation.csv\", delimiter=\";\")\n",
    "\n",
    "meteoStations[\"stn\"] = '\"' + meteoStations[\"stn\"] + '\"'\n",
    "meteoStations[\"stnName\"] = '\"' + meteoStations[\"stnName\"] + '\"'\n",
    "meteoStations[\"lawCityName\"] = '\"' + meteoStations[\"lawCityName\"] + '\"'\n",
    "meteoStations[\"datasource\"] = '\"' + meteoStations[\"datasource\"] + '\"'\n",
    "meteoStations[\"coLength\"] = '\"' + meteoStations[\"coLength\"] + '\"'\n",
    "meteoStations[\"coWide\"] = '\"' + meteoStations[\"coWide\"] + '\"'\n",
    "\n",
    "for index, row in meteoStations.iterrows():\n",
    "    sql = \"INSERT INTO meteoStations VALUES({}, {}, {}, {}, {}, {}, {}, {}, {})\".format(row[\"stn\"], row[\"stnName\"], row[\"lawCityName\"], row[\"datasource\"], row[\"bfsId\"], row[\"coEast\"], row[\"coNorth\"], row[\"coLength\"], row[\"coWide\"])\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:33:45.602056Z",
     "start_time": "2024-05-25T19:33:45.594226Z"
    }
   },
   "outputs": [],
   "execution_count": 193
  },
  {
   "cell_type": "code",
   "source": [
    "#Import MeteoData of parameter rre150h0\n",
    "#Files bereinigen mit den ersten zwei Zeilen jeder Datei überspringen\n",
    "#Datum umformatieren damit SQLite dies interpretieren kann\n",
    "path = './DATA/meteo/data'\n",
    "csv_files = glob.glob(path + '/*rre150h0*data.txt')\n",
    "df_list = (pd.read_csv(file, delimiter=';', na_values= '-') for file in csv_files)\n",
    "\n",
    "meteo_df = pd.concat(df_list, ignore_index=True)\n",
    "meteo_df.replace(np.nan, \"NULL\", inplace=True)\n",
    "meteo_df = meteo_df.astype({'time': str})\n",
    "meteo_df['time'] = meteo_df['time'] + '00'\n",
    "meteo_df['time'] = pd.to_datetime(meteo_df.time)\n",
    "meteo_df['time'] = meteo_df['time'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "meteo_df['time'] = '\"' + meteo_df['time'] + '\"'\n",
    "meteo_df['stn'] = '\"' + meteo_df['stn'] + '\"'\n",
    "\n",
    "\n",
    "for index, row in meteo_df.iterrows():\n",
    "    sql = \"INSERT INTO meteoData VALUES(NULL,{},{},{},{})\".format(row[\"stn\"], '\"rre150h0\"', row[\"time\"], row[\"rre150h0\"])\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:34:30.996063Z",
     "start_time": "2024-05-25T19:33:45.602701Z"
    }
   },
   "outputs": [],
   "execution_count": 194
  },
  {
   "cell_type": "code",
   "source": [
    "#Import MeteoData of parameter tre200h0\n",
    "path = './DATA/meteo/data'\n",
    "csv_files = glob.glob(path + '/*tre200h0*data.txt')\n",
    "df_list = (pd.read_csv(file, delimiter=';', na_values= '-') for file in csv_files)\n",
    "\n",
    "meteo_df = pd.concat(df_list, ignore_index=True)\n",
    "meteo_df.replace(np.nan, \"NULL\", inplace=True)\n",
    "meteo_df = meteo_df.astype({'time': str})\n",
    "meteo_df['time'] = meteo_df['time'] + '00'\n",
    "meteo_df = meteo_df.astype({'time': str})\n",
    "meteo_df['time'] = meteo_df['time'] + '00'\n",
    "meteo_df['time'] = pd.to_datetime(meteo_df.time)\n",
    "meteo_df['time'] = meteo_df['time'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "meteo_df['time'] = '\"' + meteo_df['time'] + '\"'\n",
    "meteo_df['stn'] = '\"' + meteo_df['stn'] + '\"'\n",
    "\n",
    "for index, row in meteo_df.iterrows():\n",
    "    sql = \"INSERT INTO meteoData VALUES(NULL,{},{},{},{})\".format(row[\"stn\"], '\"tre200h0\"', row[\"time\"], row[\"tre200h0\"])\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:34:38.866011Z",
     "start_time": "2024-05-25T19:34:30.996858Z"
    }
   },
   "outputs": [],
   "execution_count": 195
  },
  {
   "cell_type": "code",
   "source": [
    "#Import MeteoData of parameter sre000h0\n",
    "path = './DATA/meteo/data'\n",
    "csv_files = glob.glob(path + '/*sre000h0*data.txt')\n",
    "df_list = (pd.read_csv(file, delimiter=';', na_values= '-') for file in csv_files)\n",
    "\n",
    "meteo_df = pd.concat(df_list, ignore_index=True)\n",
    "meteo_df.replace(np.nan, \"NULL\", inplace=True)\n",
    "meteo_df = meteo_df.astype({'time': str})\n",
    "meteo_df['time'] = meteo_df['time'] + '00'\n",
    "meteo_df = meteo_df.astype({'time': str})\n",
    "meteo_df['time'] = meteo_df['time'] + '00'\n",
    "meteo_df['time'] = pd.to_datetime(meteo_df.time)\n",
    "meteo_df['time'] = meteo_df['time'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "meteo_df['time'] = '\"' + meteo_df['time'] + '\"'\n",
    "meteo_df['stn'] = '\"' + meteo_df['stn'] + '\"'\n",
    "\n",
    "for index, row in meteo_df.iterrows():\n",
    "    sql = \"INSERT INTO meteoData VALUES(NULL,{},{},{},{})\".format(row[\"stn\"], '\"sre000h0\"', row[\"time\"], row[\"sre000h0\"])\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:34:41.223710Z",
     "start_time": "2024-05-25T19:34:38.866674Z"
    }
   },
   "outputs": [],
   "execution_count": 196
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Import MeteoParamBFS\n",
    "meteoParams = pd.read_csv(\"./DATA/meteo/meteoStationBfsParameter.csv\", delimiter=\";\")\n",
    "\n",
    "meteoParams[\"meteoParameter\"] = '\"' + meteoParams[\"meteoParameter\"] + '\"'\n",
    "meteoParams[\"meteoStation\"] = '\"' + meteoParams[\"meteoStation\"] + '\"'\n",
    "\n",
    "for index, row in meteoParams.iterrows():\n",
    "    sql = \"INSERT INTO meteoParamBfs VALUES(NULL, {}, {}, {})\".format(row[\"bfsID\"], row[\"meteoParameter\"], row[\"meteoStation\"])\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T19:34:41.234848Z",
     "start_time": "2024-05-25T19:34:41.224289Z"
    }
   },
   "execution_count": 197
  }
 ]
}
