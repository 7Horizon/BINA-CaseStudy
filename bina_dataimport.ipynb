{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyP6gga+oDjiBTBGH7qTyVgD",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import Modules\n",
    "Sqlite verlangt für Strings \"\"\n",
    "Sqlite Date Time formate https://www.sqlite.org/lang_datefunc.html\n",
    "SQlite NULL für ID\n",
    "SQLite nan to NULL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Import Modules\n",
    "import os, sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import datetime\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:50:06.666480Z",
     "start_time": "2024-04-22T22:50:06.429685Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angegebene Database wurde nicht gefunden\n"
     ]
    }
   ],
   "source": [
    "# creating file (path) name\n",
    "dbfile = './DATA/BINA_DATA.db' \n",
    "\n",
    "# Test if the database file is available in the colab workspace\n",
    "if os.path.exists(dbfile):\n",
    "    # Create database (file) and Open a (SQL) connection \n",
    "    connection = sqlite3.connect(dbfile)\n",
    "    # Create a data cursor to exchange information between Python and SQLite\n",
    "    cursor = connection.cursor()\n",
    "else:\n",
    "    print(\"Angegebene Database wurde nicht gefunden\")\n",
    "    # Create database (file) and Open a (SQL) connection \n",
    "    connection = sqlite3.connect(dbfile)\n",
    "    # Create a data cursor to exchange information between Python and SQLite\n",
    "    cursor = connection.cursor()\n",
    "    #sys.exit(0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:50:06.673746Z",
     "start_time": "2024-04-22T22:50:06.669394Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Tabelle erstellen\n",
    "sql = [\"CREATE TABLE city (id INTEGER PRIMARY KEY, plz string, cityName string, bfsID string, lawCityName string, kantonkuerzel string)\",\n",
    "\"CREATE TABLE smartmeter (id INTEGER PRIMARY KEY, plz REFERENCES city(plz) ON UPDATE CASCADE, timestamp string, anzMeter int,valueKwh float)\",\n",
    "\"CREATE TABLE solarPlants (id INTEGER PRIMARY KEY, xtfID string, plz string, totalPower float, mainCategory string, subCategory string, plantCategory string,  _x int,  _y int, FOREIGN KEY (plz) REFERENCES city(plz) ON UPDATE CASCADE, FOREIGN KEY (subCategory) REFERENCES subCategory(id) ON UPDATE CASCADE, FOREIGN KEY (mainCategory) REFERENCES mainCategory(id) ON UPDATE CASCADE, FOREIGN KEY (plantCategory) REFERENCES plantCategory(id) ON UPDATE CASCADE)\",\n",
    "\"CREATE TABLE mainCategory (id string PRIMARY KEY, de string, fr string, it string, en string)\",\n",
    "\"CREATE TABLE plantCategory (id string PRIMARY KEY, de string, fr string, it string, en string)\",\n",
    "\"CREATE TABLE subCategory (id string PRIMARY KEY, de string, fr string, it string, en string)\",\n",
    "\"CREATE TABLE indicator (id string PRIMARY KEY, descr string)\",\n",
    "\"CREATE TABLE unit (id string,  mes string)\",\n",
    "\"CREATE TABLE demoValue (id INTEGER PRIMARY KEY, bfsID string, period string, indicator string, unit string, value float, FOREIGN KEY (bfsID) REFERENCES city(bfsID) ON UPDATE CASCADE, FOREIGN KEY (indicator) REFERENCES indicator (id) ON UPDATE CASCADE, FOREIGN KEY (unit) REFERENCES unit(id) ON UPDATE CASCADE)\",\n",
    "\"CREATE TABLE meteoParameter (parameterID string PRIMARY KEY , measure string, description string)\",\n",
    "\"CREATE TABLE meteoStations (stn string PRIMARY KEY, stnName string, lawCityName string,  datasource string, bfsID string, coEast string, coNorth string, coLength string, coWide string, FOREIGN KEY (lawCityName) REFERENCES city (lawCityName) ON UPDATE CASCADE, FOREIGN KEY (bfsID) REFERENCES city (bfsID) ON UPDATE CASCADE)\",\n",
    "\"CREATE TABLE meteoData (id INTEGER PRIMARY KEY, meteoStation string, meteoParameter string, dataTime string, value float, FOREIGN KEY (meteoStation) REFERENCES meteoStations (stn) ON UPDATE CASCADE, FOREIGN KEY (meteoParameter) REFERENCES meteoParameter (parameterID) ON UPDATE CASCADE)\",\n",
    "\"CREATE TABLE meteoParamBfs (id INTEGER PRIMARY KEY, bfsID string, meteoParameter string, meteoStation string, FOREIGN KEY (bfsID) REFERENCES city (bfsID) ON UPDATE CASCADE, FOREIGN KEY (meteoParameter) References meteoParameter (parameterID) ON UPDATE CASCADE, FOREIGN KEY (meteoStation) REFERENCES meteoStations (stn) ON UPDATE CASCADE)\"]\n",
    "\n",
    "for code in sql:\n",
    "    cursor.execute(code)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:50:06.685582Z",
     "start_time": "2024-04-22T22:50:06.675204Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Views erstellen\n",
    "sql = [ \"CREATE VIEW population AS SELECT id, bfsID, period, value FROM demoValue WHERE demoValue.indicator == 'Ind_01_01';\",\n",
    "        \"CREATE VIEW population_density AS SELECT id, bfsID, period, value FROM demoValue WHERE demoValue.indicator == 'Ind_01_03';\",\n",
    "        \"CREATE VIEW areaTotal AS SELECT id, bfsID, period, value FROM demoValue WHERE demoValue.indicator == 'Ind_04_01';\",\n",
    "        \"CREATE VIEW areaSettlement AS SELECT id, bfsID, period, value FROM demoValue WHERE demoValue.indicator == 'Ind_04_02';\",\n",
    "        \"CREATE VIEW areaAgricultural AS SELECT id, bfsID, period, value FROM demoValue WHERE demoValue.indicator == 'Ind_04_04';\",\n",
    "        \"CREATE VIEW areaUnproductive AS SELECT id, bfsID, period, value FROM demoValue WHERE demoValue.indicator == 'Ind_04_07';\",\n",
    "        \"CREATE VIEW keyFiguresPopulation as SELECT p.bfsID, p.period, p.value as population, pd.value as populationDensity FROM population p LEFT JOIN population_density pd ON p.bfsID = pd.bfsID AND p.period = pd.period;\",\n",
    "        \"CREATE VIEW keyFiguresArea as SELECT a.bfsID, a.period as periodTotal, a.value as total,ase.period as periodSettlement, ase.value as settlement, aa.period as periodAgricultural, aa.value as agricultural, au.period as periodUnproductive, au.value as unproductive FROM areaTotal a LEFT JOIN areaSettlement ase ON a.bfsID = ase.bfsID LEFT JOIN areaAgricultural aa ON a.bfsID = aa.bfsID LEFT JOIN areaUnproductive au ON a.bfsID = au.bfsID;\",\n",
    "        \"CREATE VIEW sumSmartmeter as SELECT s.plz as plz, bfsID, SUM(valueKwh) as 'kWh' FROM smartmeter as s LEFT JOIN (SELECT plz, bfsID FROM city GROUP BY plz) as c ON s.plz = c.plz GROUP BY bfsID;\"\n",
    "       ]\n",
    "\n",
    "for code in sql:\n",
    "    cursor.execute(code)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:50:06.698404Z",
     "start_time": "2024-04-22T22:50:06.690386Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# City Daten einlesen als Dataframe und in DB sichern\n",
    "city = pd.read_csv(\"./DATA/city_directory/AMTOVZ_CSV_LV95.csv\", delimiter=\";\")\n",
    "\n",
    "for index, row in city.iterrows():\n",
    "    ort = '\"' + row[\"Ortschaftsname\"] + '\"'\n",
    "    lawCityName = '\"' + row[\"Gemeindename\"] + '\"'\n",
    "    if isinstance(row[\"Kantonskürzel\"], str):\n",
    "        kantonkuerzel = '\"' + row[\"Kantonskürzel\"] + '\"'\n",
    "    else:\n",
    "        kantonkuerzel = \"NULL\"\n",
    "    sql = \"INSERT INTO city VALUES(NULL,{},{},{},{},{})\".format(row[\"PLZ\"], ort, row[\"BFS-Nr\"], lawCityName, kantonkuerzel)\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:50:06.847393Z",
     "start_time": "2024-04-22T22:50:06.700076Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Solar Anlagen Daten einlesen als Dataframe und in DB sichern\n",
    "plantCategory = pd.read_csv(\"./DATA/solar_powerplants/PlantCategoryCatalogue.csv\", delimiter=\",\")\n",
    "plantCategory.head()\n",
    "\n",
    "for index, row in plantCategory.iterrows():\n",
    "    catalogueId = '\"' + row[\"Catalogue_id\"] + '\"'\n",
    "    de = '\"' + row[\"de\"] + '\"'\n",
    "    fr = '\"' + row[\"fr\"] + '\"'\n",
    "    it = '\"' + row[\"it\"] + '\"'\n",
    "    en = '\"' + row[\"en\"] + '\"'\n",
    "    sql = \"INSERT INTO plantCategory VALUES({},{},{},{},{})\".format(catalogueId, de, fr, it, en)\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:50:06.852391Z",
     "start_time": "2024-04-22T22:50:06.848094Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Importieren der Hauptkategorien\n",
    "mainCategory = pd.read_csv(\"./DATA/solar_powerplants/MainCategoryCatalogue.csv\", delimiter=\",\")\n",
    "mainCategory.head()\n",
    "\n",
    "for index, row in mainCategory.iterrows():\n",
    "    catalogueId = '\"' + row[\"Catalogue_id\"] + '\"'\n",
    "    de = '\"' + row[\"de\"] + '\"'\n",
    "    fr = '\"' + row[\"fr\"] + '\"'\n",
    "    it = '\"' + row[\"it\"] + '\"'\n",
    "    en = '\"' + row[\"en\"] + '\"'\n",
    "    sql = \"INSERT INTO mainCategory VALUES({},{},{},{},{})\".format(catalogueId, de, fr, it, en)\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:50:06.856764Z",
     "start_time": "2024-04-22T22:50:06.853097Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Importieren der Unterkategorien\n",
    "subCategory = pd.read_csv(\"./DATA/solar_powerplants/SubCategoryCatalogue.csv\", delimiter=\",\")\n",
    "subCategory.head()\n",
    "\n",
    "for index, row in subCategory.iterrows():\n",
    "    catalogueId = '\"' + row[\"Catalogue_id\"] + '\"'\n",
    "    de = '\"' + row[\"de\"] + '\"'\n",
    "    fr = '\"' + row[\"fr\"] + '\"'\n",
    "    it = '\"' + row[\"it\"] + '\"'\n",
    "    en = '\"' + row[\"en\"] + '\"'\n",
    "    sql = \"INSERT INTO subCategory VALUES({},{},{},{},{})\".format(catalogueId, de, fr, it, en)\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:50:06.861424Z",
     "start_time": "2024-04-22T22:50:06.857579Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Importieren der Solar Kraftanlagen\n",
    "electricityProductionPlant = pd.read_csv(\"./DATA/solar_powerplants/ElectricityProductionPlant.csv\", delimiter=\",\")\n",
    "electricityProductionPlant.head()\n",
    "electricityProductionPlant.replace(np.nan, \"NULL\", inplace=True)\n",
    "\n",
    "for index, row in electricityProductionPlant.iterrows():\n",
    "    mainCategoryId = '\"' + row[\"MainCategory\"] + '\"'\n",
    "    subCategoryId = '\"' + row[\"SubCategory\"] + '\"'\n",
    "    xCor = row[\"_x\"]\n",
    "    yCor = row[\"_y\"]\n",
    "    \n",
    "    if isinstance(row[\"PlantCategory\"], str):\n",
    "        plantCategoryId = '\"' + row[\"PlantCategory\"] + '\"'\n",
    "    else:\n",
    "        plantCategoryId = \"NULL\"\n",
    "        \n",
    "    sql = \"INSERT INTO solarPlants VALUES(NULL,{},{},{},{},{},{},{},{})\".format(row[\"xtf_id\"], row[\"PostCode\"], row[\"TotalPower\"], mainCategoryId, subCategoryId, plantCategoryId, xCor, yCor)\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:50:12.541010Z",
     "start_time": "2024-04-22T22:50:06.862202Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Importieren Demografie Daten Indikator\n",
    "demoIndicator = pd.read_csv(\"./DATA/key_figures_communities/Indicator_DemoData.csv\", delimiter=\";\")\n",
    "\n",
    "for index, row in demoIndicator.iterrows():\n",
    "    indicatorId = '\"' + row[\"INDICATORS\"] + '\"'\n",
    "    de = '\"' + row[\"DE\"] + '\"'\n",
    "    \n",
    "    sql = \"INSERT INTO indicator VALUES({},{})\".format(indicatorId, de)\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:50:12.553363Z",
     "start_time": "2024-04-22T22:50:12.542848Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Importieren Unit Messeinheit\n",
    "unitMeas = pd.read_csv(\"./DATA/key_figures_communities/unit_mes_DemoData.csv\", delimiter=\";\")\n",
    "\n",
    "for index, row in unitMeas.iterrows():\n",
    "    unitMeasId = '\"' + row[\"UNIT_MES\"] + '\"'\n",
    "    unit = '\"' + row[\"Einheit\"] + '\"'\n",
    "    \n",
    "    sql = \"INSERT INTO unit VALUES({}, {})\".format(unitMeasId, unit)\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:50:12.557929Z",
     "start_time": "2024-04-22T22:50:12.554070Z"
    }
   },
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Importieren demoValue\n",
    "demoValue = pd.read_csv(\"./DATA/key_figures_communities/ts-x-21.03.01.csv\", delimiter=\";\", dtype={'PERIOD_REF': str, 'PERIOD_COMP': str, 'REGION': str})\n",
    "demoValue.replace(\"CH\", 0, inplace=True)\n",
    "demoValue.replace(np.nan, \"NULL\", inplace=True)\n",
    "\n",
    "for index, row in demoValue.iterrows():\n",
    "    period = row[\"PERIOD_REF\"]\n",
    "    if isinstance(period, str):\n",
    "        period = '\"' + period + '\"'\n",
    "    else:\n",
    "        period = str(period)\n",
    "        period = '\"' + period + '\"'\n",
    "        \n",
    "    indicator = '\"' + row[\"INDICATORS\"] + '\"'\n",
    "    unit = '\"' + row[\"UNIT_MES\"] + '\"'\n",
    "    \n",
    "    sql = \"INSERT INTO demoValue VALUES(NULL,{},{},{},{},{})\".format(row[\"CODE_REGION\"], period, indicator, unit, row[\"VALUE\"])\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:50:14.630320Z",
     "start_time": "2024-04-22T22:50:12.558649Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Importieren SmartMeter DATA\n",
    "path = './DATA/smartmeter'\n",
    "csv_files = glob.glob(path + '/*.csv.gz')\n",
    "df_list = (pd.read_csv(file) for file in csv_files)\n",
    "\n",
    "smartmeter_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "for index, row in smartmeter_df.iterrows():\n",
    "    datetime = '\"' + row[\"timestamp\"] + '\"'\n",
    "    sql = \"INSERT INTO smartmeter VALUES(NULL,{},{},{},{})\".format(row[\"area_code\"], datetime, row[\"num_meter\"], row[\"value_kwh\"])\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "connection.commit()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:54:45.547084Z",
     "start_time": "2024-04-22T22:50:14.631108Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Test Date Time and manipulation\n",
    "\n",
    "#input = '2020012400' + '00'\n",
    "#output = '%Y%m%d%H%M'\n",
    "\n",
    "#date = datetime.datetime.strptime(input, output).strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "#df = pd.DataFrame({'date':['2020012400', '2020012400']})\n",
    "\n",
    "#print(df)\n",
    "\n",
    "#df['date'] += '00'\n",
    "\n",
    "#print(df)\n",
    "\n",
    "#print(date)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:54:45.549196Z",
     "start_time": "2024-04-22T22:54:45.547741Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Import Meteo Parameter\n",
    "meteoParameter = pd.read_csv(\"./DATA/meteo/parameter.csv\", delimiter=\";\")\n",
    "\n",
    "meteoParameter.head()\n",
    "meteoParameter[\"parameterID\"] = '\"' + meteoParameter[\"parameterID\"] + '\"'\n",
    "meteoParameter[\"measure\"] = '\"' + meteoParameter[\"measure\"] + '\"'\n",
    "meteoParameter[\"description\"] = '\"' + meteoParameter[\"description\"] + '\"'\n",
    "\n",
    "for index, row in meteoParameter.iterrows():\n",
    "    sql = \"INSERT INTO meteoParameter VALUES({}, {}, {})\".format(row[\"parameterID\"], row[\"measure\"], row[\"description\"])\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:54:45.691954Z",
     "start_time": "2024-04-22T22:54:45.549817Z"
    }
   },
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO meteoStations VALUES(\"ZGGRE\", \"Greppen\", \"Greppen\", \"Gewässerschutzverband der Region Zugersee-Küssnachtersee-Ägerisee\", 1056, 675282, 212747, \"8°26'\", \"47°04'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUZI\", \"Zinggen\", \"greppen\", \"Kanton Luzern; zentras\", 1056, 645418, 202081, \"8°02'\", \"46°58'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUWK\", \"Wikon\", \"Wikon\", \"Kanton Luzern; zentras\", 1147, 639947, 234508, \"7°58'\", \"47°16'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUWI\", \"Wikon\", \"Escholzmatt-Marbach\", \"Kanton Luzern; zentras\", 1010, 636014, 193238, \"7°55'\", \"46°53'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUWE\", \"Weggis\", \"Weggis\", \"Kanton Luzern; zentras\", 1069, 674923, 210861, \"8°25'\", \"47°03'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUVI\", \"Vitznau\", \"Vitznau\", \"Kanton Luzern; zentras\", 1068, 679542, 206692, \"8°29'\", \"47°00'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUUM\", \"Umfahrung Malters\", \"Malters\", \"Kanton Luzern; zentras\", 1062, 651827, 210776, \"8°07'\", \"47°03'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUUF\", \"Ufhusen\", \"Ufhusen\", \"Kanton Luzern; zentras\", 1145, 633452, 219521, \"7°53'\", \"47°08'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUTR\", \"Triengen\", \"Triengen\", \"Kanton Luzern; zentras\", 1104, 647678, 233270, \"8°04'\", \"47°15'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUTG\", \"Trutigen\", \"Neuenkirch\", \"Bundesamt für Strassen\", 1093, 659320, 219681, \"8°13'\", \"47°08'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUTB\", \"Triechterbrücke\", \"Schenkon\", \"Bundesamt für Strassen\", 1099, 652325, 225021, \"8°08'\", \"47°10'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUST\", \"Stänglematten\", \"Dagmersellen\", \"Bundesamt für Strassen\", 1125, 640780, 229151, \"7°59'\", \"47°13'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUSO\", \"Sörenberg\", \"Flühli\", \"Kanton Luzern; zentras\", 1004, 644745, 186215, \"8°02'\", \"46°50'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUSM\", \"Schüpfheim\", \"Schüpfheim\", \"Kanton Luzern; zentras\", 1008, 643956, 197614, \"8°01'\", \"46°56'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUSH\", \"Schwanderholz\", \"Werthenstein\", \"Kanton Luzern; zentras\", 1009, 648438, 208988, \"8°05'\", \"47°02'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUSG\", \"Schongau\", \"Schongau\", \"Kanton Luzern; zentras\", 1041, 661591, 235470, \"8°15'\", \"47°16'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUSC\", \"Schlund\", \"Kriens\", \"Bundesamt für Strassen\", 1059, 665329, 207833, \"8°18'\", \"47°01'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUSB\", \"Schwarzenberg\", \"Schwarzenberg\", \"Kanton Luzern; zentras\", 1066, 655587, 208155, \"8°10'\", \"47°01'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELURW\", \"Roggliswil\", \"Roggliswil\", \"Kanton Luzern; zentras\", 1142, 633462, 230139, \"7°53'\", \"47°13'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELURU\", \"Ruswil\", \"Ruswil\", \"Kanton Luzern; zentras\", 1098, 654513, 213594, \"8°09'\", \"47°04'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELURS\", \"Rüeggisingerbrücke\", \"Emmen\", \"Bundesamt für Strassen\", 1024, 664082, 214922, \"8°17'\", \"47°05'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELURO\", \"Rothenburg\", \"Rothenburg\", \"Kanton Luzern; zentras\", 1040, 662314, 217586, \"8°16'\", \"47°06'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELURN\", \"Rotbach Nationalstrasse\", \"Emmen\", \"Bundesamt für Strassen\", 1024, 662434, 214974, \"8°16'\", \"47°05'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELURK\", \"Rotback Kantonsstrasse\", \"Emmen\", \"Kanton Luzern; zentras\", 1024, 662226, 215127, \"8°15'\", \"47°05'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELURI\", \"Rickenbach\", \"Rickenbach (LU)\", \"Kanton Luzern; zentras\", 1097, 654622, 229752, \"8°10'\", \"47°13'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELURB\", \"Reussbrücke\", \"Buchrain\", \"Bundesamt für Strassen\", 1052, 668541, 216929, \"8°20'\", \"47°06'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUOK\", \"Oberkirch\", \"Oberkirch\", \"Kanton Luzern; zentras\", 1095, 650497, 223510, \"8°06'\", \"47°10'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUNK\", \"Neuenkirch\", \"Neuenkirch\", \"Kanton Luzern; zentras\", 1093, 656583, 218604, \"8°11'\", \"47°07'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUMK\", \"Meierskappel\", \"Meierskappel\", \"Kanton Luzern; zentras\", 1064, 674737, 217873, \"8°25'\", \"47°06'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUME\", \"Menznau\", \"Menznau\", \"Kanton Luzern; zentras\", 1136, 644904, 215445, \"8°02'\", \"47°05'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUMB\", \"Menzberg\", \"Menznau\", \"Kanton Luzern; zentras\", 1136, 642483, 211214, \"7°60'\", \"47°03'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELULI\", \"Littau\", \"Luzern\", \"Kanton Luzern; zentras\", 1061, 661816, 210772, \"8°15'\", \"47°03'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELULE\", \"Lehn\", \"Escholzmatt-Marbach\", \"Kanton Luzern; zentras\", 1010, 641325, 198075, \"7°59'\", \"46°56'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELULB\", \"Littauerboden\", \"Malters\", \"Kanton Luzern; zentras\", 1062, 661458, 211526, \"8°15'\", \"47°03'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUKW\", \"Kottwil\", \"Ettiswil\", \"Kanton Luzern; zentras\", 1128, 646556, 224189, \"8°03'\", \"47°10'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUKH\", \"Knutwilerhöhe\", \"Knutwil\", \"Bundesamt für Strassen\", 1089, 648422, 226640, \"8°05'\", \"47°11'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUHW\", \"Hergiswil\", \"Hergiswil bei Willisau\", \"Kanton Luzern; zentras\", 1132, 639708, 215653, \"7°58'\", \"47°05'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUHR\", \"Hildisrieden\", \"Hildisrieden\", \"Kanton Luzern; zentras\", 1088, 659434, 223061, \"8°13'\", \"47°09'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUHE\", \"Herlisberg\", \"Beromünster\", \"Kanton Luzern; zentras\", 1081, 659609, 228186, \"8°14'\", \"47°12'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUHB\", \"Hämikon Berg\", \"Hitzkirch\", \"Kanton Luzern; zentras\", 1030, 665229, 232749, \"8°18'\", \"47°15'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUHA\", \"Haltiwald N2\", \"Horw\", \"Bundesamt für Strassen\", 1058, 666360, 205789, \"8°19'\", \"46°60'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUGI\", \"Gisikon\", \"Gisikon\", \"Kanton Luzern; zentras\", 1055, 672600, 220341, \"8°24'\", \"47°08'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUGE\", \"Gettnau\", \"Willisau\", \"Kanton Luzern; zentras\", 1151, 639385, 220778, \"7°57'\", \"47°08'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUGB\", \"Grosshofbrücke\", \"Kriens\", \"Bundesamt für Strassen\", 1059, 665110, 209975, \"8°18'\", \"47°02'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUFT\", \"Fontannen / Romoos\", \"Doppleschwand\", \"Kanton Luzern; zentras\", 1001, 645527, 207445, \"8°02'\", \"47°01'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUEB\", \"Eschenbach\", \"Eschenbach (LU)\", \"Kanton Luzern; zentras\", 1026, 666845, 221568, \"8°19'\", \"47°09'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUBU\", \"Buchs\", \"Dagmersellen\", \"Kanton Luzern; zentras\", 1125, 645598, 228503, \"8°02'\", \"47°12'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUBR\", \"Buchrain\", \"Buchrain\", \"Kanton Luzern; zentras\", 1052, 669187, 217068, \"8°21'\", \"47°06'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUBH\", \"Buttisholz\", \"Buttisholz\", \"Kanton Luzern; zentras\", 1083, 650676, 219221, \"8°06'\", \"47°07'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUBD\", \"Bermudadreieck\", \"Ebikon\", \"Bundesamt für Strassen\", 1054, 665175, 213685, \"8°18'\", \"47°04'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUAW\", \"Alberswil\", \"Alberswil\", \"Kanton Luzern; zentras\", 1121, 642580, 223048, \"8°00'\", \"47°09'\")\n",
      "INSERT INTO meteoStations VALUES(\"ZELUAE\", \"Aesch\", \"Aesch (LU)\", \"Kanton Luzern; zentras\", 1021, 660531, 235073, \"8°14'\", \"47°16'\")\n",
      "INSERT INTO meteoStations VALUES(\"SPF\", \"Schüpfheim\", \"Schüpfheim\", \"MeteoSchweiz\", 1008, 643683, 199710, \"8°01'\", \"46°57'\")\n",
      "INSERT INTO meteoStations VALUES(\"NABBRM\", \"Bermünster\", \"Beromünster\", \"Bundesamt für Umwelt\", 1081, 655842, 226777, \"8°11'\", \"47°11'\")\n",
      "INSERT INTO meteoStations VALUES(\"MOA\", \"Mosen\", \"Hitzkirch\", \"MeteoSchweiz\", 1030, 660128, 232852, \"8°14'\", \"47°15'\")\n",
      "INSERT INTO meteoStations VALUES(\"MMTRG\", \"Triengen\", \"Triengen\", \"DTN Schweiz AG\", 1104, 648430, 230884, \"8°05'\", \"47°14'\")\n",
      "INSERT INTO meteoStations VALUES(\"LUZ\", \"Luzern\", \"Luzern\", \"Kanton Luzern\", 1061, 665543, 209849, \"8°18'\", \"47°02'\")\n",
      "INSERT INTO meteoStations VALUES(\"LUWOL\", \"Wolhusen\", \"Wolhusen\", \"Kanton Luzern\", 1107, 648090, 212490, \"8°04'\", \"47°04'\")\n",
      "INSERT INTO meteoStations VALUES(\"LUWIL\", \"Willisau\", \"Willisau\", \"Kanton Luzern\", 1151, 642650, 220780, \"8°00'\", \"47°08'\")\n",
      "INSERT INTO meteoStations VALUES(\"LUSUR\", \"Sursee\", \"Sursee\", \"Kanton Luzern\", 1103, 649930, 225040, \"8°06'\", \"47°10'\")\n",
      "INSERT INTO meteoStations VALUES(\"LUSEM\", \"Sempach\", \"Sempach\", \"Kanton Luzern\", 1102, 656880, 219360, \"8°11'\", \"47°07'\")\n",
      "INSERT INTO meteoStations VALUES(\"LUSCH\", \"Schüpfheim\", \"Schüpfheim\", \"Kanton Luzern\", 1008, 644500, 200940, \"8°01'\", \"46°57'\")\n",
      "INSERT INTO meteoStations VALUES(\"LUROO\", \"Root\", \"Root\", \"Kanton Luzern\", 1065, 672060, 218910, \"8°23'\", \"47°07'\")\n",
      "INSERT INTO meteoStations VALUES(\"LUMAL\", \"Malters\", \"Malters\", \"Kanton Luzern\", 1062, 656760, 210150, \"8°11'\", \"47°02'\")\n",
      "INSERT INTO meteoStations VALUES(\"LULAN\", \"Langnau\", \"Reiden\", \"Kanton Luzern\", 1140, 640360, 231200, \"7°58'\", \"47°14'\")\n",
      "INSERT INTO meteoStations VALUES(\"LUHOC\", \"Hochdorf\", \"Hochdorf\", \"Kanton Luzern\", 1031, 663850, 225520, \"8°17'\", \"47°11'\")\n",
      "INSERT INTO meteoStations VALUES(\"LUEMM\", \"Emmen\", \"Emmen\", \"Kanton Luzern\", 1024, 666800, 215725, \"8°19'\", \"47°05'\")\n",
      "INSERT INTO meteoStations VALUES(\"INNRED\", \"Reiden\", \"Reiden\", \"inNET Monitoring AG \", 1140, 639560, 232110, \"7°58'\", \"47°14'\")\n",
      "INSERT INTO meteoStations VALUES(\"INNLUZ\", \"Luzern\", \"Luzern\", \"inNET Monitoring AG \", 1061, 665789, 210898, \"8°18'\", \"47°03'\")\n",
      "INSERT INTO meteoStations VALUES(\"INNEBI\", \"Ebikon\", \"Ebikon\", \"inNET Monitoring AG \", 1054, 665478, 213381, \"8°18'\", \"47°04'\")\n",
      "INSERT INTO meteoStations VALUES(\"FLU\", \"Flühli\", \"Flühli\", \"MeteoSchweiz\", 1004, 644332, 193311, \"8°01'\", \"46°53'\")\n",
      "INSERT INTO meteoStations VALUES(\"ENT\", \"Entlebuch\", \"Entlebuch\", \"MeteoSchweiz\", 1002, 647935, 204165, \"8°04'\", \"46°59'\")\n",
      "INSERT INTO meteoStations VALUES(\"EMM\", \"Emmen\", \"Emmen\", \"Schweizer Armee - Luftwaffe\", 1024, 665102, 215165, \"8°18'\", \"47°05'\")\n",
      "INSERT INTO meteoStations VALUES(\"EGO\", \"Egolzwil\", \"Egolzwil\", \"MeteoSchweiz\", 1127, 642912, 225540, \"8°00'\", \"47°11'\")\n",
      "INSERT INTO meteoStations VALUES(\"BEMBE\", \"Marbachegg\", \"Escholzmatt-Marbach\", \"Kanton Bern\", 1010, 635550, 186385, \"7°54'\", \"46°50'\")\n"
     ]
    }
   ],
   "source": [
    "#Import Meteo Stations\n",
    "meteoStations = pd.read_csv(\"./DATA/meteo/meteoStation.csv\", delimiter=\";\")\n",
    "\n",
    "meteoStations[\"stn\"] = '\"' + meteoStations[\"stn\"] + '\"'\n",
    "meteoStations[\"stnName\"] = '\"' + meteoStations[\"stnName\"] + '\"'\n",
    "meteoStations[\"lawCityName\"] = '\"' + meteoStations[\"lawCityName\"] + '\"'\n",
    "meteoStations[\"datasource\"] = '\"' + meteoStations[\"datasource\"] + '\"'\n",
    "meteoStations[\"coLength\"] = '\"' + meteoStations[\"coLength\"] + '\"'\n",
    "meteoStations[\"coWide\"] = '\"' + meteoStations[\"coWide\"] + '\"'\n",
    "\n",
    "for index, row in meteoStations.iterrows():\n",
    "    sql = \"INSERT INTO meteoStations VALUES({}, {}, {}, {}, {}, {}, {}, {}, {})\".format(row[\"stn\"], row[\"stnName\"], row[\"lawCityName\"], row[\"datasource\"], row[\"bfsId\"], row[\"coEast\"], row[\"coNorth\"], row[\"coLength\"], row[\"coWide\"])\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T19:45:16.691786Z",
     "start_time": "2024-04-23T19:45:16.675390Z"
    }
   },
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Import MeteoData of parameter rre150h0\n",
    "#Files bereinigen mit den ersten zwei Zeilen jeder Datei überspringen\n",
    "path = './DATA/meteo/data'\n",
    "csv_files = glob.glob(path + '/*rre150h0*data.txt')\n",
    "df_list = (pd.read_csv(file, delimiter=';', na_values= '-') for file in csv_files)\n",
    "\n",
    "meteo_df = pd.concat(df_list, ignore_index=True)\n",
    "meteo_df.replace(np.nan, \"NULL\", inplace=True)\n",
    "meteo_df = meteo_df.astype({'time': str})\n",
    "meteo_df['time'] = meteo_df['time'] + '00' \n",
    "\n",
    "meteo_df['time'] = '\"' + meteo_df['time'] + '\"'\n",
    "meteo_df['stn'] = '\"' + meteo_df['stn'] + '\"'\n",
    "\n",
    "\n",
    "for index, row in meteo_df.iterrows():\n",
    "    sql = \"INSERT INTO meteoData VALUES(NULL,{},{},{},{})\".format(row[\"stn\"], '\"rre150h0\"', row[\"time\"], row[\"rre150h0\"])\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T20:02:37.506002Z",
     "start_time": "2024-04-23T20:01:56.788304Z"
    }
   },
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Import MeteoData of parameter tre200h0\n",
    "path = './DATA/meteo/data'\n",
    "csv_files = glob.glob(path + '/*tre200h0*data.txt')\n",
    "df_list = (pd.read_csv(file, delimiter=';', na_values= '-') for file in csv_files)\n",
    "\n",
    "meteo_df = pd.concat(df_list, ignore_index=True)\n",
    "meteo_df.replace(np.nan, \"NULL\", inplace=True)\n",
    "meteo_df = meteo_df.astype({'time': str})\n",
    "meteo_df['time'] = meteo_df['time'] + '00'\n",
    "\n",
    "meteo_df['time'] = '\"' + meteo_df['time'] + '\"'\n",
    "meteo_df['stn'] = '\"' + meteo_df['stn'] + '\"'\n",
    "\n",
    "for index, row in meteo_df.iterrows():\n",
    "    sql = \"INSERT INTO meteoData VALUES(NULL,{},{},{},{})\".format(row[\"stn\"], '\"tre200h0\"', row[\"time\"], row[\"tre200h0\"])\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T20:03:57.042453Z",
     "start_time": "2024-04-23T20:03:49.990739Z"
    }
   },
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Import MeteoData of parameter sre000h0\n",
    "path = './DATA/meteo/data'\n",
    "csv_files = glob.glob(path + '/*sre000h0*data.txt')\n",
    "df_list = (pd.read_csv(file, delimiter=';', na_values= '-') for file in csv_files)\n",
    "\n",
    "meteo_df = pd.concat(df_list, ignore_index=True)\n",
    "meteo_df.replace(np.nan, \"NULL\", inplace=True)\n",
    "meteo_df = meteo_df.astype({'time': str})\n",
    "meteo_df['time'] = meteo_df['time'] + '00'\n",
    "\n",
    "meteo_df['time'] = '\"' + meteo_df['time'] + '\"'\n",
    "meteo_df['stn'] = '\"' + meteo_df['stn'] + '\"'\n",
    "\n",
    "for index, row in meteo_df.iterrows():\n",
    "    sql = \"INSERT INTO meteoData VALUES(NULL,{},{},{},{})\".format(row[\"stn\"], '\"sre000h0\"', row[\"time\"], row[\"sre000h0\"])\n",
    "    cursor.execute(sql)\n",
    "\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T20:04:29.998596Z",
     "start_time": "2024-04-23T20:04:27.858111Z"
    }
   },
   "execution_count": 50
  }
 ]
}
