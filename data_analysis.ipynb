{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "850efa91fe8a341f",
   "metadata": {},
   "source": [
    "# Analyse über Einflussfaktoren zum Stromverbrauch im Versorgungsgebiet der CKW AG auf Ebene der Gemeinde\n",
    "*Business Intelligence and Analytics, MScWI FS24 Hochschule Luzern*\n",
    "- **Noemi Rohner**\n",
    "- **Mizgin Turunc**\n",
    "- **Jan Leuenberger**\n",
    "- **Lukas Bucheli**\n",
    "\n",
    "\n",
    "Die CKW AG ist ein zentralschweizer Energieunternehmen, welches sich aufgrund der Energiestrategie 2050 verpflichten musste bis 2027 sämtliche traditionellen Zähler durch Smartmeter zu ersetzen. Sie sollen Teil des Smart Grid werden. Mit einem Smart Grid erhofft man sich eine effizientere Energieversorgung. Die Smartmeter sind ein integrierter Bestandteil des Smart Grid und ermöglichen dadurch neue Funktionen wie intelligente Steuerungen. Besonders durch die aufkommende dezentralisierte Energieerzeugung mit erneuerbaren Energien bei privaten Haushalten, müssen intelligent gesteuert werden, damit das Stromnetz ausbalanciert bleibt. Mit diesen Smartmeter wird auch der Echtzeit-Zugriff auf die Zählerdaten für den Endkunden ermöglicht. Dadurch erhofft sich das Bundesamt für Energie (BFE) einen bewussteren Umgang mit dem Strom und dadurch auch diesen zu sparen (BFE, 2021 [Online-Quelle](https://www.bfe.admin.ch/bfe/de/home/versorgung/stromversorgung/stromnetze/smart-grids.html)).\n",
    "\n",
    "## Fragestellung\n",
    "In dieser Arbeit wird folgende Fragestellung versucht zu beantworten:\n",
    "> Was sind relevante Einflussfaktoren auf Gemeindeebene in Bezug auf den Stromverbrauch im Einzugsgebiet der CKW?\n",
    "\n",
    "## Aufbau der Jupyter Notebooks\n",
    "Aufgrund der umfassenden Datenmenge und dem Einsatz einer SQLite Datenbank wurde entschieden, die Arbeit in mehrere Jupyter Notebooks aufzuteilen:\n",
    "- **bina_dataimport.ipynb**, In diesem Notebook werden die einzelnen verwendeten Datasets analysiert und in die Datenbank geladen.\n",
    "- **data_analysis.ipynb**, In diesem Notebook folgt die vernetzte Analyse der Daten.\n",
    "\n",
    "# Datenquellen und Datenbank\n",
    "In diesem Notebook werden die Daten aus der im Import Notebook erstellten Datenbank geladen. Dazu muss die Datenbank zuvor mit dem Notebook erstellt worden sein.\n",
    "\n",
    "\n",
    "## Eingesetzte Module\n",
    "Für dieses Notebook werden folgende Module eingesetzt:\n",
    "- __sqlite3__\n",
    "    Wird für die Datenbank verwendet\n",
    "- __warnings__\n",
    "    Um FutureWarnings zu unterdrücken, welche in der aktuellen Pandas Version nicht relevant sind\n",
    "- __pandas__\n",
    "    Wird gebraucht um die CSV Dateien zu lesen und als Dataframe in die SQLite Datenbank zu laden\n",
    "- __geopandas__\n",
    "    Wird gebraucht um Geografische Karten darzustellen\n",
    "- __math__\n",
    "    Wird verwendet für mathematische Funktionen\n",
    "- __seaborn__\n",
    "    Wird für Daten-Visualisierungen verwendet. Basiert auf matplotlib\n",
    "- __matplotlib__\n",
    "    Wird verwendet für statistische Berechnungen sowie Darstellungen\n",
    "- __plotly__\n",
    "    Wird verwendet für statistische Berechnungen sowie Darstellungen\n",
    "- __numpy__\n",
    "    Wird benötigt um die NaN Werte in den Dataframes mit NULL zu ersetzen\n",
    "- __statsmodels__\n",
    "    Wird eingesetzt \n",
    "- __pmdarima__\n",
    "    Wird eingesetzt um leere Datensätze in Timeseries aufzufüllen\n",
    "- __tbats__\n",
    "    Wird für das Forecasting von Timeseries verwendet \n",
    "- __sklearn__\n",
    "    Wird für das Machine Learning eingesetzt "
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "# Load GEOPANDAS library\n",
    "import os, sqlite3\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stl.mstl import MSTL\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "import pmdarima as pm\n",
    "from tbats import TBATS, BATS\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Settings for clean html export\n",
    "pio.renderers.default = \"plotly_mimetype+notebook\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1650c10a650252ea",
   "metadata": {},
   "source": [
    "## Funktionen\n",
    "Nachfolgend werden mehrere Funktionen und Klassen definiert, welche eine Übersetzung des Schweizer Koordinatensystems in das globale Koordinatensystem ermöglichen\n",
    "Quelle: Swisstopo, https://github.com/ValentinMinder/Swisstopo-WGS84-LV03/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "id": "abae89e8a7d83c5e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "class GPSConverter(object):\n",
    "    '''\n",
    "    GPS Converter class which is able to perform convertions between the \n",
    "    CH1903 and WGS84 system.\n",
    "    '''\n",
    "    # Convert CH y/x/h to WGS height\n",
    "    def CHtoWGSheight(self, y, x, h):\n",
    "        # Axiliary values (% Bern)\n",
    "        y_aux = (y - 600000) / 1000000\n",
    "        x_aux = (x - 200000) / 1000000\n",
    "        h = (h + 49.55) - (12.60 * y_aux) - (22.64 * x_aux)\n",
    "        return h\n",
    "\n",
    "    # Convert CH y/x to WGS lat\n",
    "    def CHtoWGSlat(self, y, x):\n",
    "        # Axiliary values (% Bern)\n",
    "        y_aux = (y - 600000) / 1000000\n",
    "        x_aux = (x - 200000) / 1000000\n",
    "        lat = (16.9023892 + (3.238272 * x_aux)) + \\\n",
    "              - (0.270978 * pow(y_aux, 2)) + \\\n",
    "              - (0.002528 * pow(x_aux, 2)) + \\\n",
    "              - (0.0447 * pow(y_aux, 2) * x_aux) + \\\n",
    "              - (0.0140 * pow(x_aux, 3))\n",
    "        # Unit 10000\" to 1\" and convert seconds to degrees (dec)\n",
    "        lat = (lat * 100) / 36\n",
    "        return lat\n",
    "\n",
    "    # Convert CH y/x to WGS long\n",
    "    def CHtoWGSlng(self, y, x):\n",
    "        # Axiliary values (% Bern)\n",
    "        y_aux = (y - 600000) / 1000000\n",
    "        x_aux = (x - 200000) / 1000000\n",
    "        lng = (2.6779094 + (4.728982 * y_aux) + \\\n",
    "               + (0.791484 * y_aux * x_aux) + \\\n",
    "               + (0.1306 * y_aux * pow(x_aux, 2))) + \\\n",
    "              - (0.0436 * pow(y_aux, 3))\n",
    "        # Unit 10000\" to 1\" and convert seconds to degrees (dec)\n",
    "        lng = (lng * 100) / 36\n",
    "        return lng\n",
    "\n",
    "    # Convert decimal angle (° dec) to sexagesimal angle (dd.mmss,ss)\n",
    "    def DecToSexAngle(self, dec):\n",
    "        degree = int(math.floor(dec))\n",
    "        minute = int(math.floor((dec - degree) * 60))\n",
    "        second = (((dec - degree) * 60) - minute) * 60\n",
    "        return degree + (float(minute) / 100) + (second / 10000)\n",
    "\n",
    "    # Convert sexagesimal angle (dd.mmss,ss) to seconds\n",
    "    def SexAngleToSeconds(self, dms):\n",
    "        degree = 0\n",
    "        minute = 0\n",
    "        second = 0\n",
    "        degree = math.floor(dms)\n",
    "        minute = math.floor((dms - degree) * 100)\n",
    "        second = (((dms - degree) * 100) - minute) * 100\n",
    "        return second + (minute * 60) + (degree * 3600)\n",
    "\n",
    "    # Convert sexagesimal angle (dd.mmss) to decimal angle (degrees)\n",
    "    def SexToDecAngle(self, dms):\n",
    "        degree = 0\n",
    "        minute = 0\n",
    "        second = 0\n",
    "        degree = math.floor(dms)\n",
    "        minute = math.floor((dms - degree) * 100)\n",
    "        second = (((dms - degree) * 100) - minute) * 100\n",
    "        return degree + (minute / 60) + (second / 3600)\n",
    "\n",
    "    # Convert WGS lat/long (° dec) and height to CH h\n",
    "    def WGStoCHh(self, lat, lng, h):\n",
    "        lat = self.DecToSexAngle(lat)\n",
    "        lng = self.DecToSexAngle(lng)\n",
    "        lat = self.SexAngleToSeconds(lat)\n",
    "        lng = self.SexAngleToSeconds(lng)\n",
    "        # Axiliary values (% Bern)\n",
    "        lat_aux = (lat - 169028.66) / 10000\n",
    "        lng_aux = (lng - 26782.5) / 10000\n",
    "        h = (h - 49.55) + (2.73 * lng_aux) + (6.94 * lat_aux)\n",
    "        return h\n",
    "\n",
    "    # Convert WGS lat/long (° dec) to CH x\n",
    "    def WGStoCHx(self, lat, lng):\n",
    "        lat = self.DecToSexAngle(lat)\n",
    "        lng = self.DecToSexAngle(lng)\n",
    "        lat = self.SexAngleToSeconds(lat)\n",
    "        lng = self.SexAngleToSeconds(lng)\n",
    "        # Axiliary values (% Bern)\n",
    "        lat_aux = (lat - 169028.66) / 10000\n",
    "        lng_aux = (lng - 26782.5) / 10000\n",
    "        x = ((200147.07 + (308807.95 * lat_aux) + \\\n",
    "              + (3745.25 * pow(lng_aux, 2)) + \\\n",
    "              + (76.63 * pow(lat_aux,2))) + \\\n",
    "             - (194.56 * pow(lng_aux, 2) * lat_aux)) + \\\n",
    "            + (119.79 * pow(lat_aux, 3))\n",
    "        return x\n",
    "\n",
    "    # Convert WGS lat/long (° dec) to CH y\n",
    "    def WGStoCHy(self, lat, lng):\n",
    "        lat = self.DecToSexAngle(lat)\n",
    "        lng = self.DecToSexAngle(lng)\n",
    "        lat = self.SexAngleToSeconds(lat)\n",
    "        lng = self.SexAngleToSeconds(lng)\n",
    "        # Axiliary values (% Bern)\n",
    "        lat_aux = (lat - 169028.66) / 10000\n",
    "        lng_aux = (lng - 26782.5) / 10000\n",
    "        y = (600072.37 + (211455.93 * lng_aux)) + \\\n",
    "            - (10938.51 * lng_aux * lat_aux) + \\\n",
    "            - (0.36 * lng_aux * pow(lat_aux, 2)) + \\\n",
    "            - (44.54 * pow(lng_aux, 3))\n",
    "        return y\n",
    "\n",
    "    def LV03toWGS84(self, east, north, height):\n",
    "        '''\n",
    "        Convert LV03 to WGS84 Return a array of double that contain lat, long,\n",
    "        and height\n",
    "        '''\n",
    "        d = []\n",
    "        d.append(self.CHtoWGSlat(east, north))\n",
    "        d.append(self.CHtoWGSlng(east, north))\n",
    "        d.append(self.CHtoWGSheight(east, north, height))\n",
    "        return d\n",
    "\n",
    "    def WGS84toLV03(self, latitude, longitude, ellHeight):\n",
    "        '''\n",
    "        Convert WGS84 to LV03 Return an array of double that contaign east,\n",
    "        north, and height\n",
    "        '''\n",
    "        d = []\n",
    "        d.append(self.WGStoCHy(latitude, longitude))\n",
    "        d.append(self.WGStoCHx(latitude, longitude))\n",
    "        d.append(self.WGStoCHh(latitude, longitude, ellHeight))\n",
    "        return d"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7d07164156097904",
   "metadata": {},
   "source": [
    "## Daten vorbereiten\n",
    "### Geodaten\n",
    "Für die grafische Darstellung verschiedener Auswertungen auf der Schweizer Karte werden entsprechende Geodaten benötigt, welche anschliessend mit der BFS-ID mit Auswertungen verknüpft und so dargestellt werden."
   ]
  },
  {
   "cell_type": "code",
   "id": "cf43520b2d0b8660",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# read Swiss Cantons Geometry Data (as GeoFrame)\n",
    "geofilePATH = 'https://raw.githubusercontent.com/sawubona-repo/BINA-FS24-WORK/master/zDiversExamples/Notebook-GeoMapping/DATA/'\n",
    "geofileNAME = 'ch-municipalities.geojson'\n",
    "\n",
    "# Read GeoJSON geometry data into geopandas GeoDataFrame\n",
    "raw_geodf = gpd.read_file(geofilePATH+geofileNAME)\n",
    "\n",
    "raw_geodf.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4e615bcb8757155d",
   "metadata": {},
   "source": [
    "### Datenbank\n",
    "Um die im anderen Notebook erstellte Datenbank auszulesen, wird diese nachfolgend hinzugefügt."
   ]
  },
  {
   "cell_type": "code",
   "id": "9dfd2816c5897963",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "dbfile = './DATA/BINA_DATA.db'\n",
    "\n",
    "# Test if the database file is available in the colab workspace\n",
    "if os.path.exists(dbfile):\n",
    "    # Create database (file) and Open a (SQL) connection \n",
    "    connection = sqlite3.connect(dbfile)\n",
    "    # Create a data cursor to exchange information between Python and SQLite\n",
    "    cursor = connection.cursor()\n",
    "else:\n",
    "    print(\"Angegebene Database wurde nicht gefunden\")\n",
    "    # Create database (file) and Open a (SQL) connection \n",
    "    connection = sqlite3.connect(dbfile)\n",
    "    # Create a data cursor to exchange information between Python and SQLite\n",
    "    cursor = connection.cursor()\n",
    "    #sys.exit(0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2453afb070d90140",
   "metadata": {},
   "source": [
    "# Smartmeter\n",
    "Eine einfache Auswertung der maximalen Anzahl Smartmeter pro Gemeinde in den Daten soll aufzeigen, wie viele Smartmeter bereits zum Einsatz kommen. Dabei zeigt sich, dass diese Zahlen sehr unterschiedlich sind."
   ]
  },
  {
   "cell_type": "code",
   "id": "434c68a3698bc2bd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "anzSmartmeter = pd.read_sql_query(\"SELECT MAX(anzMeter) anz, bfsID FROM smartmeter s JOIN plzBfsMapping p ON s.plz = p.plz GROUP BY bfsID;\", connection)\n",
    "joined_anzSmartmeter = pd.merge(raw_geodf, anzSmartmeter, left_on=\"gemeinde.BFS_NUMMER\", right_on=\"bfsID\")\n",
    "anzSmartmeter = joined_anzSmartmeter\n",
    "\n",
    "# Create Choropleth GeoMap with Population Data (Feature \"zAnteil_Schweizer\")\n",
    "fig = px.choropleth_mapbox(\n",
    "    anzSmartmeter,\n",
    "    geojson=anzSmartmeter.geometry,\n",
    "    locations=anzSmartmeter.index,\n",
    "    color='anz',                                   # define feature variable\n",
    "    color_continuous_scale=px.colors.diverging.Geyser,           # define color palette\n",
    "    labels={'anz':'Anzahl Smartmeter', 'gemeinde.NAME':'Gemeinde'},\n",
    "\n",
    "    hover_name='gemeinde.NAME',                                       # define mouse over infos\n",
    "    hover_data={'gemeinde.NAME':True, 'anz':True},\n",
    "    opacity=0.5,\n",
    "    center=dict(lat=47.05048, lon=8.30635),                      # set lucerne as map center\n",
    "    zoom=8,\n",
    "    mapbox_style=\"carto-positron\"                                # other option \"open-street-map\"\n",
    ")\n",
    "\n",
    "fig.update_layout(margin=dict(l=0, r=0, t=0, b=0))\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ed67f7e3e84739df",
   "metadata": {},
   "source": [
    "Um herauszufinden, wie weit der Ausbau mit Smartmetern bereits fortgeschritten ist, kann die Anzahl Smartmeter mit der Anzahl Haushalten pro Gemeinde in Verbindung gebracht werden. Hier zeigt sich jedoch, dass bei einigen Gemeinden ein Wert von >1 erreicht wird. Dies deutet darauf hin, dass nebst privaten Haushalten auch Betriebe bereits damit ausgestattet wurden, welche nicht in die Kategorie \"Grossverbraucher\" fallen."
   ]
  },
  {
   "cell_type": "code",
   "id": "e32fd67bb23f2161",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "smartmeterPerHousehold = pd.read_sql_query(\"SELECT ROUND(MAX(s.anzMeter) / d.value, 2) AS anz, d.bfsID FROM smartmeter s JOIN plzBfsMapping p ON s.plz = p.plz JOIN demoValue d ON p.bfsID = d.bfsID WHERE d.indicator = 'Ind_01_13' GROUP BY d.bfsID, d.value;\", connection)\n",
    "joined_smartmeterPerHousehold = pd.merge(raw_geodf, smartmeterPerHousehold, left_on=\"gemeinde.BFS_NUMMER\", right_on=\"bfsID\")\n",
    "smartmeterPerHousehold = joined_smartmeterPerHousehold\n",
    "\n",
    "# Create Choropleth GeoMap with Population Data (Feature \"zAnteil_Schweizer\")\n",
    "fig = px.choropleth_mapbox(\n",
    "    smartmeterPerHousehold,\n",
    "    geojson=smartmeterPerHousehold.geometry,\n",
    "    locations=smartmeterPerHousehold.index,\n",
    "    color='anz',                                   # define feature variable\n",
    "    color_continuous_scale=px.colors.sequential.Greens,           # define color palette\n",
    "    labels={'anz':'Anzahl Smartmeter pro Haushalt', 'gemeinde.NAME':'Gemeinde'},\n",
    "\n",
    "    hover_name='gemeinde.NAME',                                       # define mouse over infos\n",
    "    hover_data={'gemeinde.NAME':True, 'anz':True},\n",
    "    opacity=0.5,\n",
    "    center=dict(lat=47.05048, lon=8.30635),                      # set lucerne as map center\n",
    "    zoom=8,\n",
    "    mapbox_style=\"carto-positron\"                                # other option \"open-street-map\"\n",
    ")\n",
    "\n",
    "fig.update_layout(margin=dict(l=0, r=0, t=0, b=0))\n",
    "fig.update_layout(title_text='Smartmeter pro Haushalt')\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6c777a2bfc410bc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "df = pd.read_sql_query(\"SELECT s.plz, SUM(valueKwh / anzMeter) as sumValuePerPlz, p.bfsID FROM smartmeter s JOIN plzBfsMapping p ON s.plz = p.plz GROUP BY s.plz ORDER BY sumValuePerPlz DESC;\", connection)\n",
    "geodf = pd.merge(raw_geodf, df, left_on=\"gemeinde.BFS_NUMMER\", right_on=\"bfsID\")\n",
    "\n",
    "# Create Choropleth GeoMap\n",
    "fig = px.choropleth_mapbox(\n",
    "    geodf,\n",
    "    geojson=geodf.geometry,\n",
    "    locations=geodf.index,\n",
    "    color='sumValuePerPlz',                                   # define feature variable\n",
    "    color_continuous_scale=px.colors.diverging.Geyser,           # define color palette\n",
    "    labels={'sumValuePerPlz':'Stromverbrauch pro Smart Meter'},\n",
    "\n",
    "    hover_name='gemeinde.NAME',                                       # define mouse over infos\n",
    "    hover_data={'gemeinde.NAME':True, 'sumValuePerPlz':True},\n",
    "    opacity=0.5,\n",
    "    center=dict(lat=47.05048, lon=8.30635),                      # set lucerne as map center\n",
    "    zoom=8,\n",
    "    mapbox_style=\"carto-positron\"                                # other option \"open-street-map\"\n",
    ")\n",
    "\n",
    "fig.update_layout(margin=dict(l=0, r=0, t=0, b=0))\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "290027bff428a6f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "e229108dd05d48ec",
   "metadata": {},
   "source": [
    "# Get Data\n",
    "df = pd.read_sql_query(\"SELECT (a.anzMeter / p.value) AS smartmeterPerPopulation, a.bfsID FROM (SELECT MAX(anzMeter) AS anzMeter, bfsID FROM smartmeter s JOIN plzBfsMapping m ON s.plz = m.plz GROUP BY bfsID) a JOIN population p ON a.bfsID = p.bfsID;\", connection)\n",
    "\n",
    "# Merge Data with geo information\n",
    "geodf = pd.merge(raw_geodf, df, left_on=\"gemeinde.BFS_NUMMER\", right_on=\"bfsID\")\n",
    "\n",
    "# Create Choropleth GeoMap with Population Data (Feature \"zAnteil_Schweizer\")\n",
    "fig = px.choropleth_mapbox(\n",
    "    geodf,\n",
    "    geojson=geodf.geometry,\n",
    "    locations=geodf.index,\n",
    "    color='smartmeterPerPopulation',                                   # define feature variable\n",
    "    color_continuous_scale=px.colors.diverging.Geyser,           # define color palette\n",
    "    labels={'smartmeterPerPopulation':'Smartmeter pro Einwohner'},\n",
    "\n",
    "    hover_name='gemeinde.NAME',                                       # define mouse over infos\n",
    "    hover_data={'gemeinde.NAME':True, 'smartmeterPerPopulation':True},\n",
    "    opacity=0.5,\n",
    "    center=dict(lat=47.05048, lon=8.30635),                      # set lucerne as map center\n",
    "    zoom=8,\n",
    "    mapbox_style=\"carto-positron\"                                # other option \"open-street-map\"\n",
    ")\n",
    "\n",
    "fig.update_layout(margin=dict(l=0, r=0, t=0, b=0))\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8d7470a139c59007",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "c9d195c1edd99559",
   "metadata": {},
   "source": [
    "solarPower = pd.read_sql_query(\"SELECT a.sumKwh as sumKwhUsed, a.bfsID, a.lawCityName, o.sumTotalPower as sumKwhSolar FROM (SELECT SUM(valueKwh / anzMeter) AS sumKwh, bfsID, lawCityName FROM smartmeter s JOIN plzBfsMapping m ON s.plz = m.plz GROUP BY bfsID) a JOIN solarPlantsLUbfsId o ON a.bfsID = o.bfsID;\", connection)\n",
    "\n",
    "# Hochdorf aus Auswertung entfernen, da Daten fehlerhaft\n",
    "solarPower = solarPower[solarPower.bfsID != 1031]\n",
    "\n",
    "sns.scatterplot(x='sumKwhUsed', y='sumKwhSolar', data=solarPower).set(xlabel='Usage per Smartmeter (kW)', ylabel='Total Solar Power')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4435392283921ec4",
   "metadata": {},
   "source": [
    "Um mögliche Zusammenhänge zwischen Stromverbrauch pro Smartmeter und der Bevölkerungsanzahl zu finden, werden nachfolgend der Verbrauch pro Smartmeter und die Bevölkerungsanzahl gegenübergestellt. Farblich eingefärbt ist zusätzlich die Anzahl Unternehmen pro Gemeinde ersichtlich. Es zeigt sich, dass kein Zusammenhang zwischen Bevölkerungsgrösse und Stromverbrauch pro Smartmeter zu erkennen ist. Eine Aussage, dass kleinere Gemeinden mehr oder weniger Strom pro Smartmeter verbrauchen als grosse, ist also nicht möglich. Einzig ein Zusammenhang zwischen Bevölkerungsgrösse und Anzahl Unternehmen ist zu erkennen, was darauf schliessen lässt, dass grössere Gemeinden mit mehr Einwohner auch mehr Unternehmen beheimaten."
   ]
  },
  {
   "cell_type": "code",
   "id": "dd595440470336be",
   "metadata": {},
   "source": [
    "kwhPopulation = pd.read_sql_query(\"SELECT SUM(s.valueKwh / s.anzMeter) AS sumKwhUsed, m.bfsID, m.lawCityName, o.value AS population, b.value AS industry FROM smartmeter s JOIN plzBfsMapping m ON s.plz = m.plz JOIN demoValue o ON m.bfsID = o.bfsID AND o.indicator = 'Ind_01_01' JOIN demoValue b ON m.bfsID = b.bfsID AND b.indicator = 'Ind_06_07' GROUP BY m.bfsID, m.lawCityName, o.value, b.value;\", connection)\n",
    "\n",
    "# Hochdorf aus Auswertung entfernen, da Daten fehlerhaft\n",
    "kwhPopulation = kwhPopulation[kwhPopulation.bfsID != 1031]\n",
    "# Stadt Luzern aus Auswertung entfernen, da starke Abweichung bei Bewohner\n",
    "kwhPopulation = kwhPopulation[kwhPopulation.bfsID != 1061]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,5))\n",
    "fig.suptitle('Zusammenhang Verbrauch per Smartmeter & demografische Daten')\n",
    "sns.scatterplot(ax = axes[0], x='sumKwhUsed', y='population', hue='industry', data=kwhPopulation).set(xlabel='Usage per Smartmeter (kW)', ylabel='Population')\n",
    "sns.scatterplot(ax = axes[1], x='sumKwhUsed', y='industry', data=kwhPopulation).set(xlabel='Usage per Smartmeter (kW)', ylabel='Industry')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d38b1c45ace4f872",
   "metadata": {},
   "source": [
    "Eine reine Gegenüberstellung von Stromverbrauch pro Smartmeter und der Anzahl Unternehmen zeigt auch keine Zusammenhänge auf. Unternehmen scheinen also nicht primär für einen höheren Verbrauch pro Smartmeter verantwortlich zu sein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c255bc425d19d02",
   "metadata": {},
   "source": [
    "Weitere, tiefere Analysen können womöglich noch Zusammenhänge zwischen Stromverbrauch pro Smartmeter und demografischen Daten aufzeigen. Dazu scheint jedoch die Anzahl der Gemeinden zu klein, um aussagekräftig zu sein und die Daten der Smartmeter weisen zu viele Ungenauigkeiten und Fehler auf. Stünden verlässliche Smartmeter Daten schweizweit zur Verfügung, könnten womöglich Zusammenhänge hergestell werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b986f421f27b681",
   "metadata": {},
   "source": [
    "## Datenanalyse mit Meteodaten und Smartmeterdaten\n",
    "In diesem Notebook geht es darum kombinierte Analysen auszuführen. Also wie stehen die Smartmeter Daten im Verhältnis zu Meteodaten.\n",
    "\n",
    "### Datenanalyse Smartmeter und Sonnendaten\n",
    "Zuerst werden die Daten aus der Datenbank geladen und gleich im korrekten Zeitformat gesichert. Aus der ersten Analyse ist bekannt, dass es 4 Meteostationen gibt, welche die Sonnenminuten gemessen haben. Von diesen haben zwei (MOA und LUZ) den gesamten Zeitraum zu Verfügung. Dies wird nochmals in der Grafik ersichtlich. Es ist auch erkennbar, dass eine Saisonalität (Sommer/Winter) vorhanden ist. Im Winter gibt es erkennbar weniger Sonnenminuten wie im Sommer. Die geladenen Daten beinhalten die aufsummierten täglichen Sonnenminuten pro Tag und BFS-Nummer."
   ]
  },
  {
   "cell_type": "code",
   "id": "fa81ab5a0d8d543a",
   "metadata": {},
   "source": [
    "df_sun = pd.read_sql_query(\"SELECT SUM(meteoData.value) as 'sunMinDay', meteoData.dataTime, meteoData.meteoParameter, meteoStation FROM  meteoData WHERE meteoParameter == 'sre000h0' GROUP BY meteoStation, strftime('%Y-%m-%d', meteoData.dataTime)\", connection)\n",
    "df_sun['dataTime'] = pd.to_datetime(df_sun['dataTime'], format='%Y-%m-%d %H:%M')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "testPlot = sns.lineplot(x='dataTime', y='sunMinDay', hue='meteoStation', data=df_sun).set(title='Anz. Sonnenminuten pro Tag und Messstation', xlabel='Datum', ylabel='Anz. Sonnenminuten')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "160a3f477ca9d83a",
   "metadata": {},
   "source": [
    "Als nächstes werden die Sonnenminuten und Zählerdaten pro BFS-Nummer geladen. Bei den Zählerdaten handelt es sich immer um den Durchschnittsverbrauch pro Gemeinde pro Zähler. Damit sind die Gemeinden untereinander vergleichbar. Mit der BFS-Nummer und dem Datum lassen sich die Daten verknüpfen."
   ]
  },
  {
   "cell_type": "code",
   "id": "b98e953f112ed782",
   "metadata": {},
   "source": [
    "df_sun = pd.read_sql_query(\"SELECT * FROM sumSunMinutesPerDayBfsId\", connection)\n",
    "df_sun.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3edb8975fba1564d",
   "metadata": {},
   "source": [
    "df_power = pd.read_sql_query(\"SELECT * FROM dailySumSmartmeterBfsId\", connection)\n",
    "df_power.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "685e84ec2700da14",
   "metadata": {},
   "source": [
    "df_sunPower = pd.merge(df_sun, df_power, on=['time', 'bfsID'])\n",
    "df_sunPower['time'] = pd.to_datetime(df_sunPower['time'], format='%Y-%m-%d')\n",
    "df_sunPower.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4dcb7ce9d74df86f",
   "metadata": {},
   "source": [
    "### Erstanalyse am Beispiel der Gemeinde Meggen\n",
    "Bevor eine Analyse über sämtliche Daten durchgeführt wird, wird die Gemeinde Meggen als Beispiel genommen. Es wird sichtbar, dass im Fall von Meggen drei Sonnenwerte fehlen. Diese müssen noch aufgefüllt werden um eine komplette Zeitreihe zu erhalten."
   ]
  },
  {
   "cell_type": "code",
   "id": "922fc971841f7e8e",
   "metadata": {},
   "source": [
    "df_sunPowerMeggen = df_sunPower.query(\"bfsID == 1063\").copy()\n",
    "df_sunPowerMeggen.info()\n",
    "df_sunPowerMeggen.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "83231c5fc76571c5",
   "metadata": {},
   "source": [
    "Zuerst aber eine Grafik, welche auf der linken y-Achse wird der Verbrauch dargestellt und rechts die Sonnenminute. Bei der Betrachtung des Stromverbrauches erkennt man ebenfalls eine Saisonalität. Im Winter steigt der durchschnittliche Stromverbrauch und im Sommer nimmt dieser ab. Im Gegensatz zu der Sonne, welche zeitweise den Boden nicht erreicht (min = 0), wird permanent Strom verbraucht und ist nie 0."
   ]
  },
  {
   "cell_type": "code",
   "id": "7d3a0753a924465d",
   "metadata": {},
   "source": [
    "meggenPlot, ax1 = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(x='time', y='avgKwhConsum', data=df_sunPowerMeggen, ax=ax1).set(title='Vergleich des durchschnittlichen Stromverbrauches zu den Sonnenminute', xlabel='Datum', ylabel='Verbrauch in kWh')\n",
    "ax2 = ax1.twinx()\n",
    "sns.lineplot(data=df_sunPowerMeggen, x='time', y='sumSunDay', ax=ax2, color='red').set(ylabel='Anz. Sonnenminuten')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "15b9035c4df3a1b9",
   "metadata": {},
   "source": [
    "Für den Umgang mit den NA Werten, werden zunächst die unnötigen Spalten entfernt und kontrolliert, ob jedes Datum vorhanden ist."
   ]
  },
  {
   "cell_type": "code",
   "id": "33fc3b3dbede2632",
   "metadata": {},
   "source": [
    "df_meggen = df_sunPowerMeggen.copy()\n",
    "df_meggen.drop(columns=['meteoParameter', 'meteoStation', 'bfsID', 'lawCityName'], inplace=True)\n",
    "df_meggen['time'] = pd.to_datetime(df_meggen['time'])\n",
    "print('Fehlende Datum: ', pd.date_range(start = '2020-12-31', end='2024-03-05').difference(df_meggen['time']))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d5b269d6dc41a8a2",
   "metadata": {},
   "source": [
    "Für die spätere Kontrolle wie gut die Werte, zu den erzeugten Werten passen, wird eine Spalte erzeugt mit fehlenden Werten. Die fehlende Werte in der echten Spalten müssen entfernt werden, damit die spätere Kontrolle mit dem R-Squared funktioniert."
   ]
  },
  {
   "cell_type": "code",
   "id": "752af4cfb0f7cb09",
   "metadata": {},
   "source": [
    "df_meggen.set_index('time', inplace=True)\n",
    "df_meggen.dropna(inplace=True)\n",
    "df_meggen['sumSunDayRef'] = df_meggen['sumSunDay']\n",
    "df_meggen['sumSunDayRef'] = df_meggen['sumSunDayRef'].sample(frac=0.85)\n",
    "df_meggen.info()\n",
    "df_meggen.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a4581832ecd76f79",
   "metadata": {},
   "source": [
    "Nun werden verschiedene Methoden angewandt, die fehlenden Werte der Referenz-Spalte zu füllen. In der Übersicht erkennt man, dass jede Spalte, bis auf die Referenzspalte, eine vollständige Spalte besitzt."
   ]
  },
  {
   "cell_type": "code",
   "id": "b49e6e8f8a9ca3d2",
   "metadata": {},
   "source": [
    "df_meggen = df_meggen.assign(FillMean=df_meggen.sumSunDayRef.fillna(df_meggen.sumSunDayRef.mean()))\n",
    "df_meggen = df_meggen.assign(FillMedian=df_meggen.sumSunDayRef.fillna(df_meggen.sumSunDayRef.median()))\n",
    "df_meggen = df_meggen.assign(RollingMean=df_meggen.sumSunDayRef.fillna(df_meggen.sumSunDayRef.rolling(24, min_periods=1).mean()))\n",
    "df_meggen = df_meggen.assign(RollingMedian=df_meggen.sumSunDayRef.fillna(df_meggen.sumSunDayRef.rolling(24, min_periods=1).median()))\n",
    "df_meggen = df_meggen.assign(InterpolationLinear=df_meggen.sumSunDayRef.interpolate(method='linear'))\n",
    "df_meggen = df_meggen.assign(InterpolationQuadratic=df_meggen.sumSunDayRef.interpolate(method='quadratic'))\n",
    "df_meggen = df_meggen.assign(InterpolationCubic=df_meggen.sumSunDayRef.interpolate(method='cubic'))\n",
    "df_meggen = df_meggen.assign(InterpolationSLinear=df_meggen.sumSunDayRef.interpolate(method='slinear'))\n",
    "df_meggen = df_meggen.assign(InterpolationAkima=df_meggen.sumSunDayRef.interpolate(method='akima'))\n",
    "df_meggen = df_meggen.assign(InterpolationPoly5=df_meggen.sumSunDayRef.interpolate(method='polynomial', order=5))\n",
    "df_meggen = df_meggen.assign(InterpolationPoly7=df_meggen.sumSunDayRef.interpolate(method='polynomial', order=7))\n",
    "df_meggen = df_meggen.assign(InterpolationSpline3=df_meggen.sumSunDayRef.interpolate(method='spline', order=3))\n",
    "df_meggen = df_meggen.assign(InterpolationSpline4=df_meggen.sumSunDayRef.interpolate(method='spline', order=4))\n",
    "df_meggen = df_meggen.assign(InterpolationSpline5=df_meggen.sumSunDayRef.interpolate(method='spline', order=5))\n",
    "df_meggen.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "64f30b3016beae1c",
   "metadata": {},
   "source": [
    "Die Kontrolle mit der R-Squared Methode legt nahe, dass die Lineare-Methode am nächsten den realen Werten Nahe kommt. Aus diesem Grund wird mit dieser Methode die NA-Werte aufgefüllt. Bei lediglich 3 fehlenden Werten, stellt dies kein weiteres Problem dar."
   ]
  },
  {
   "cell_type": "code",
   "id": "60f0f567ef5423f5",
   "metadata": {},
   "source": [
    "results = [(method, r2_score(df_meggen.sumSunDay, df_meggen[method])) for method in list(df_meggen)[3:]]\n",
    "results_df = pd.DataFrame(np.array(results), columns=['Method', 'R_squared'])\n",
    "results_df.sort_values(by='R_squared', ascending=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2f4c807797a744e8",
   "metadata": {},
   "source": [
    "Beim Laden derselben Daten, werden die Daten nun mit der Linearen Interpolation aufgefüllt. Die Kontrolle zeigt, dass dies funktioniert hat. <br>\n",
    "Als nächstes wird die Korrelation in Meggen betrachtet. Die Zeit-Spalte wird als Index verwendet. Mit einer Korrelation von -0.51 wird ein schwacher negativer Zusammenhang zwischen den Sonnenminuten und des Stromverbrauches bestätigt. Das bedeutet, je mehr Sonnenschein, desto tiefer der Stromverbrauch. Mehr Sonnenschein bedeuetet normalerweise auch höhere Temperaturen. Diese Analyse folgt in einem späteren Kapitel.<br>\n",
    "Die Autocorrelation gibt anhand verschiedener Intervall an, wie stark die Werte von vorhergehenden Punkten in derselben Zeitreihe beeinflusst werden. Bei den Sonnenminuten gibt es keine regelmässigkeiten. Beim Strom sieht es anders aus. Mit jedem erweitern des Intervalls nimmt die Korrelation ab. Besonders bei 90-Tagen. Bei einem 1-Jahres Intervall ist die Korrelation wieder hoch. So kann zumindest angenommen werden, dass beim Strom eine wöchentliche und jährliche Korrelation besteht.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f024604a3ff11ea2",
   "metadata": {},
   "source": [
    "df_meggen = df_sunPowerMeggen.copy()\n",
    "df_meggen.drop(columns=['meteoParameter', 'meteoStation', 'bfsID', 'lawCityName'], inplace=True)\n",
    "df_meggen['time'] = pd.to_datetime(df_meggen['time'])\n",
    "df_meggen.sumSunDay.interpolate(method='linear', inplace=True)\n",
    "\n",
    "#df_test = df_test.astype({'time': str})\n",
    "df_meggen.index = df_meggen['time']\n",
    "#df_test = df_test.astype({'sumSunDay': str})\n",
    "df_meggen.drop(columns=['time'], inplace=True)\n",
    "df_meggen.info()\n",
    "df_meggen.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "43373cb944f41842",
   "metadata": {},
   "source": [
    "print('Korrelation zwischen den Parametern:\\n', df_meggen.corr())\n",
    "print('\\nAutocorrelation der täglichen Sonnenminuten und Stromverbrauch:')\n",
    "autocorrOneSun = df_meggen['sumSunDay'].autocorr(lag=1)\n",
    "print('Sonne 1-Tages-Intervall:\\t', autocorrOneSun)\n",
    "autocorrOneKwh = df_meggen['avgKwhConsum'].autocorr(lag=1)\n",
    "print('Strom 1-Tages-Intervall:\\t', autocorrOneKwh)\n",
    "autocorr7Sun = df_meggen['sumSunDay'].autocorr(lag=7)\n",
    "print('Sonne 7-Tages-Intervall:\\t', autocorr7Sun)\n",
    "autocorr7Kwh = df_meggen['avgKwhConsum'].autocorr(lag=7)\n",
    "print('Strom 7-Tages-Intervall:\\t', autocorr7Kwh)\n",
    "autocorr30Sun = df_meggen['sumSunDay'].autocorr(lag=30)\n",
    "print('Sonne 30-Tages-Intervall:\\t', autocorr30Sun)\n",
    "autocorr30Kwh = df_meggen['avgKwhConsum'].autocorr(lag=30)\n",
    "print('Strom 30-Tages-Intervall:\\t', autocorr30Kwh)\n",
    "\n",
    "autocorr90Sun = df_meggen['sumSunDay'].autocorr(lag=90)\n",
    "print('Sonne 90-Tages-Intervall:\\t', autocorr90Sun)\n",
    "autocorr90Kwh = df_meggen['avgKwhConsum'].autocorr(lag=90)\n",
    "print('Strom 90-Tages-Intervall:\\t', autocorr90Kwh)\n",
    "\n",
    "autocorr365Sun = df_meggen['sumSunDay'].autocorr(lag=365)\n",
    "print('Sonne 365-Tages-Intervall:\\t', autocorr365Sun)\n",
    "autocorr365Kwh = df_meggen['avgKwhConsum'].autocorr(lag=365)\n",
    "print('Strom 365-Tages-Intervall:\\t', autocorr365Kwh)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9c649ca6a1736fc9",
   "metadata": {},
   "source": [
    "### Ausweitung der Analyse auf alle Gemeinden\n",
    "Im nächsten Schritt wird die Korrelation-Analyse auf die weiteren Gemeinden ausgeweitet. Dazu wird die Analyse in West und Ost unterteilt, dies aufgrund der geografischen Standorte der Messstationen. Bei den westlichen Gemeinde werden die Daten bis zum 30.6.2024 verwendet."
   ]
  },
  {
   "cell_type": "code",
   "id": "19c65a4eb183f6a3",
   "metadata": {},
   "source": [
    "df_west = df_sunPower.query(\"meteoStation == 'SPF' | meteoStation == 'EGO'\")\n",
    "df_east = df_sunPower.query(\"meteoStation == 'LUZ' | meteoStation == 'MOA'\")\n",
    "df_west.info()\n",
    "df_east.info()\n",
    "df_west = df_west.copy()\n",
    "df_west.head()\n",
    "df_east = df_east.copy()\n",
    "df_east.head()\n",
    "df_west.drop(columns=['meteoParameter', 'meteoStation', 'lawCityName'], inplace=True)\n",
    "df_west['time'] = pd.to_datetime(df_west['time'])\n",
    "#df_west.dropna(inplace=True)\n",
    "df_westPivot = df_west.pivot(index='time', columns=['bfsID'], values=['avgKwhConsum', 'sumSunDay'])\n",
    "df_westPivot.info()\n",
    "\n",
    "df_east.drop(columns=['meteoParameter', 'meteoStation', 'lawCityName'], inplace=True)\n",
    "df_east['time'] = pd.to_datetime(df_east['time'])\n",
    "#df_east.dropna(inplace=True)\n",
    "df_eastPivot = df_east.pivot(index='time', columns='bfsID', values=['avgKwhConsum', 'sumSunDay'])\n",
    "df_eastPivot.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "91fb13d72ff5cb3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "462980f669ecfc0",
   "metadata": {},
   "source": [
    "df_eastPivot.interpolate(method='linear', inplace=True)\n",
    "df_eastPivot.info()\n",
    "df_westPivot.interpolate(method='linear', inplace=True)\n",
    "df_westPivot.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fefb6fe1a81b0579",
   "metadata": {},
   "source": [
    "Für eine bessere optische Ansicht wird mit den Korrelation-Werten eine Heatmap erstellt. Zuerst für die östliche Seite. Was sofort auffällt sind die beiden dunklen Vierecke. Unten rechts sind die Korrelationen zwischen den Sonnenminuten zwischen den Gemeinden. Diese Werte sind sehr hoch. Somit scheint die Sonne vielerorts gleichzeitig und unterscheidet sich im Schnitt pro Tag nicht sehr stark. Oben links befinden sich die Korrelationen zwischen den Gemeinden und des Stromverbrauchs. Vielfach verhaltet sich der Stromverbrauch ähnlich zu den Gemeinden. Es gibt aber einige Ausreisser. Dies kann mit den aussergewöhnlichen Anomalien Zusammenhängen, welche bei einigen Ortschaften in der ersten Analyse erkannt wurden. Dies ist z.B. bei der Gemeinde Kriens (plz=6010/BFS-Nummer=1059). Die verbleibenden Quadranten geben die Korrelation zwischen dem Stromverbrauch und den Sonnenminuten an. Was sich bei Meggen angedeutet hat lässt sich mit der Heatmap bestätigen. Die Korrelation liegt im Bereich von ca. -0.5. Ausser bei denen, welche bereits eine schwache Korrelation bei den Zählerdaten vorweisen. Dort geht die Korrelation noch weiter zurück bis gegen 0."
   ]
  },
  {
   "cell_type": "code",
   "id": "cbd74544abc315b8",
   "metadata": {},
   "source": [
    "print('Korrelation zwischen den Parametern:\\n', df_eastPivot.corr())\n",
    "\n",
    "fig = plt.figure(figsize=(40, 40))\n",
    "sns.heatmap(df_eastPivot.corr(), annot=True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b38f149695ab6600",
   "metadata": {},
   "source": [
    "Die westliche Seite präsentiert sich in einem ähnlichen Gewand."
   ]
  },
  {
   "cell_type": "code",
   "id": "d54d4fbc981bf3e8",
   "metadata": {},
   "source": [
    "print('Korrelation zwischen den Parametern:\\n', df_eastPivot.corr())\n",
    "\n",
    "fig = plt.figure(figsize=(40, 40))\n",
    "sns.heatmap(df_westPivot.corr(), annot=True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "de9871583da9a32e",
   "metadata": {},
   "source": [
    "Um die Korrelationen innerhalb der Zeitreihe noch besser einschätzen zu können, wird ein Boxplot erstellt."
   ]
  },
  {
   "cell_type": "code",
   "id": "c463f88c10e7a38b",
   "metadata": {},
   "source": [
    "columns = list(df_westPivot)\n",
    "columns = list(df_eastPivot)\n",
    "\n",
    "autocorrOneDay = []\n",
    "\n",
    "#1 Day Correlation\n",
    "for column in df_westPivot:\n",
    "    autocorrOneSun = df_westPivot[column].autocorr(lag=1)\n",
    "    col1 = column[0]+ 'OneDay'\n",
    "    autocorrOneDay.append([col1,column[1],autocorrOneSun])\n",
    "\n",
    "for column in df_eastPivot:\n",
    "    autocorrOneSun = df_eastPivot[column].autocorr(lag=1)\n",
    "    col1 = column[0]+ 'OneDay'\n",
    "    autocorrOneDay.append([col1,column[1],autocorrOneSun])\n",
    "#7 Day Correlation\n",
    "for column in df_westPivot:\n",
    "    autocorrOneSun = df_westPivot[column].autocorr(lag=7)\n",
    "    col7 = column[0]+ '7Day'\n",
    "    autocorrOneDay.append([col7,column[1],autocorrOneSun])\n",
    "\n",
    "for column in df_eastPivot:\n",
    "    autocorrOneSun = df_eastPivot[column].autocorr(lag=7)\n",
    "    col7 = column[0]+ '7Day'\n",
    "    autocorrOneDay.append([col7,column[1],autocorrOneSun])\n",
    "\n",
    "#30 Day Correlation\n",
    "for column in df_westPivot:\n",
    "    autocorrOneSun = df_westPivot[column].autocorr(lag=30)\n",
    "    col30 = column[0]+ '30Day'\n",
    "    autocorrOneDay.append([col30,column[1],autocorrOneSun])\n",
    "\n",
    "for column in df_eastPivot:\n",
    "    autocorrOneSun = df_eastPivot[column].autocorr(lag=30)\n",
    "    col30 = column[0]+ '30Day'\n",
    "    autocorrOneDay.append([col30,column[1],autocorrOneSun])\n",
    "\n",
    "for column in df_westPivot:\n",
    "    autocorrOneSun = df_westPivot[column].autocorr(lag=90)\n",
    "    col90 = column[0]+ '90Day'\n",
    "    autocorrOneDay.append([col90,column[1],autocorrOneSun])\n",
    "\n",
    "for column in df_eastPivot:\n",
    "    autocorrOneSun = df_eastPivot[column].autocorr(lag=90)\n",
    "    col90 = column[0]+ '90Day'\n",
    "    autocorrOneDay.append([col90,column[1],autocorrOneSun])\n",
    "\n",
    "for column in df_westPivot:\n",
    "    autocorrOneSun = df_westPivot[column].autocorr(lag=365)\n",
    "    col365 = column[0]+ '365Day'\n",
    "    autocorrOneDay.append([col365,column[1],autocorrOneSun])\n",
    "\n",
    "for column in df_eastPivot:\n",
    "    autocorrOneSun = df_eastPivot[column].autocorr(lag=365)\n",
    "    col365 = column[0]+ '365Day'\n",
    "    autocorrOneDay.append([col365,column[1],autocorrOneSun])\n",
    "\n",
    "df = pd.DataFrame(autocorrOneDay)\n",
    "df = df.pivot(index=1, columns=0, values=2)\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1f36c3d7d6321d46",
   "metadata": {},
   "source": [
    "Im Boxplot setzt sich die Erkenntnis von Meggen weiter. Das 90-Tag Intervall ist nicht relevant. Während die sonst gewählten Intervall eine höhere Korrelation vorweisen. So korreliert der Stromverbrauch bei 50% der Gemeinden mit dem Wert von 0.74 zum vor jährlichen Tagesschnitt. Im Bereich der Sonnenminuten gibt es keine bedeutende Korrelation."
   ]
  },
  {
   "cell_type": "code",
   "id": "33614e3a053cfe96",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "boxplot = sns.boxplot(df)\n",
    "boxplot.set(title='Korrelation innerhalb der Zeitreihen mit verschiedenen Intervallen')\n",
    "boxplot.tick_params(axis='x', labelrotation = 45)\n",
    "plt.show()\n",
    "df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "18c1fca4122e1fe9",
   "metadata": {},
   "source": [
    "Für den Boxplot der Korrelationen zwischen den Parametern werden normale Korrelationsmatrixen erstellt und die nicht notwendigen Index und Spalten entfernt."
   ]
  },
  {
   "cell_type": "code",
   "id": "6c9b5a7b62b96166",
   "metadata": {},
   "source": [
    "df_corrWest = df_westPivot[['avgKwhConsum', 'sumSunDay']].corr()\n",
    "df_corrWest.drop(columns=['sumSunDay'], index=['avgKwhConsum'],inplace=True)\n",
    "df_corrEast = df_eastPivot[['avgKwhConsum', 'sumSunDay']].corr()\n",
    "df_corrEast.drop(columns=['sumSunDay'], index=['avgKwhConsum'],inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "18378c0e5187145f",
   "metadata": {},
   "source": [
    "Der Boxplot für den westlichen Teil zeigt das 75% der Korrelationswerte tiefer als ca. -0.3 sind, also eine stärkere Korrelation aufweisen. Wobei nur 25% der Korrelation zwischen ca. -0.475 und ca. -0.55 liegen. Der östliche Teil hat weniger Outlier und das 75% Quantil ein wenig früher bei ca. -0.29 startet. Generll gibt somit keine starke Verbindung zwischen diesen zwei Parametern."
   ]
  },
  {
   "cell_type": "code",
   "id": "80a22217855e7257",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16,10))\n",
    "fig.suptitle('Vergleich der Korrelation zwischen Ost und West')\n",
    "sns.boxplot(ax = axes[0], data=df_corrWest).set(title='Boxplot West')\n",
    "sns.boxplot(ax = axes[1], data=df_corrEast).set(title='Boxplot Ost')\n",
    "plt.show()\n",
    "df_corrWest.describe()\n",
    "df_corrEast.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1c981cdf1e7e5acc",
   "metadata": {},
   "source": [
    "Abschliessend kann gesagt werden, dass die Sonne wohl keinen direkten Einfluss auf den Stromverbrauch hat.\n",
    "\n",
    "## Mögliche Analyse Solarpanels, Stromverbrauch während Sonnenzeit und während Sonne weg ist\n",
    "## Mögliche Analyse Zusammenhang des Zubaus von Solaranlagen und dem Trend des Rückgangs des Stromverbrauches über die restlichen drei Jahren.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4980189d4b386af",
   "metadata": {},
   "source": [
    "## Datenanalyse Smartmeter mit Regendaten\n",
    "Als nächster Schritt in der Analyse werden die Regendaten verwendet. In der Analyse wurde bereits festgestellt, dass die Daten nicht vollständig sind. In dieser Grafik ist gleich erkennbar, dass es da gewisse Ausschläge gibt, die nicht normal erscheinen. Für eine bessere Übersicht folgt später ein Facet Grid für jeden Standort. Die geladenen Daten beinhalten die aufsummierten Niederschläge in mm pro Tag und BFS-Nummer."
   ]
  },
  {
   "cell_type": "code",
   "id": "4e4ac332387ed759",
   "metadata": {},
   "source": [
    "df_rain = pd.read_sql_query(\"SELECT * FROM sumRainPerDayBfsId\", connection)\n",
    "df_rain[['dataTime', 'hour']] = df_rain['dataTime'].str.split(' ', expand=True)\n",
    "df_rain['dataTime'] = pd.to_datetime(df_rain['dataTime'], format='%Y-%m-%d')\n",
    "df_rain.drop(columns=['hour'], inplace=True)\n",
    "df_rain.rename(columns={'dataTime':'time'}, inplace=True)\n",
    "print(df_rain.count())\n",
    "df_rain.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a251ee3a9cb5bf4",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "testPlot = sns.lineplot(x='time', y='rainSumDay', hue='meteoStation', data=df_rain).set(title='Summe des Regens pro Tag und Messstation', xlabel='Datum', ylabel='mm Regen')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "706cbb49b299c18c",
   "metadata": {},
   "source": [
    "Damit die fehlenden Daten später besser analysiert werden können, wird eine Pivot Tabelle erstellt."
   ]
  },
  {
   "cell_type": "code",
   "id": "c516c0627dd63acf",
   "metadata": {},
   "source": [
    "df_rainPivot = df_rain.pivot(index='time', columns=['bfsID'], values=['rainSumDay'])\n",
    "df_rainPivot.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1ccbdbe072b1a90c",
   "metadata": {},
   "source": [
    "df_power = pd.read_sql_query(\"SELECT * FROM dailySumSmartmeterBfsId\", connection)\n",
    "df_power['time'] = pd.to_datetime(df_power['time'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a15823bffcdfecab",
   "metadata": {},
   "source": [
    "Um die Vollständigkeit zu prüfen, wird eine Pivot Tabelle erstellt und mit der Info-Ansicht werden diese erkennbar. Die meisten Werte sind vorhanden oder es fehlt einer. Eine Aussnahme ist die BFS-Nummer 1100 und 1129 welche 30 bzw. 32 fehlende Daten aufweist."
   ]
  },
  {
   "cell_type": "code",
   "id": "6a3ce4159e36b8",
   "metadata": {},
   "source": [
    "df_powerPivot = df_power.pivot(index='time', columns=['bfsID'], values=['avgKwhConsum'])\n",
    "df_powerPivot.info()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "716a9316844f89db",
   "metadata": {},
   "source": [
    "Mit der Betrachtung der leeren Daten fällt auf, dass die Daten zu Beginn der Zeitreihe fehlen. Aus der Forecast Analyse wissen wir, dass sich der Stromverbrauch Saisonal verhält. Mit der Erkenntnis, dass sich der Stromverbrauch innerhalb des Monats stabil bewegt, wird die lineare Interpolation angewendet. Die Interpolation folgt zu einem späteren Zeitpunkt. Nachfolgend werden die Daten vorbereitet für die weitere Analyse."
   ]
  },
  {
   "cell_type": "code",
   "id": "4cb9483f9bd07c31",
   "metadata": {},
   "source": [
    "df_powerPivotNa = df_powerPivot[df_powerPivot.isna().any(axis=1)]\n",
    "df_powerPivotNa.head(1000)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "172ab975dd7c5b12",
   "metadata": {},
   "source": [
    "df_rainPower = pd.merge(df_rain, df_power,on=['bfsID', 'time'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d9b741093dff647e",
   "metadata": {},
   "source": [
    "df_rainPower['time'] = pd.to_datetime(df_rainPower['time'])\n",
    "df_rainPower.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d6d358ffd7623c1",
   "metadata": {},
   "source": [
    "df_rainPower.drop(columns=['meteoParameter', 'lawCityName', 'meteoStation'], inplace=True)\n",
    "df_rainPowerPivot = df_rainPower.pivot(index='time', columns=['bfsID'], values=['avgKwhConsum', 'rainSumDay'])\n",
    "df_rainPowerPivot.head()\n",
    "df_rainPowerPivot.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eb8db011125ac883",
   "metadata": {},
   "source": [
    "Wie aus dem untenstehenden Facet Grid zu entnehmen ist, gibt es viele nicht vorhandene Werte und dies auch über längere Zeiträume. Eine Interpolation über längere Zeiträume wird als nicht sinnvoll erachtet. Als Alternative werden die fehlende Zeiträume mit Daten von anderen Messstationen zum gleichen Zeitpunkt kopiert. Dieser Ansatz basiert auf der Idee, dass durch die relativ nahen geografischen Standorten, die Unterschiede nicht signifikant sein werden. Diese Annahme wird auch gestützt aufgrund der Korrelationsmatrix. Aus optischer Perspektive bewegt sich die Korrelation oft zwischen 0.7-0.8."
   ]
  },
  {
   "cell_type": "code",
   "id": "a184930565b0ef12",
   "metadata": {},
   "source": [
    "# FacetGrid erstellen\n",
    "g = sns.FacetGrid(df_rain, col='meteoStation', col_wrap=3, height=4, sharex=True, sharey=False)\n",
    "g.map(sns.lineplot, 'time', 'rainSumDay')\n",
    "\n",
    "# Achsenbeschriftungen und Titel hinzufügen\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_xlabel('day')\n",
    "    ax.set_ylabel('mm rain')\n",
    "\n",
    "    # Intervall der x-Achsenbeschriftungen anpassen\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "    # Rotation der Beschriftungen\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_rotation(45)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c4304abc3129e82",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(60, 60))\n",
    "sns.heatmap(df_rainPowerPivot.corr(), annot=True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7a65de363bc09eb0",
   "metadata": {},
   "source": [
    "Das kopieren der Werte wird solange fortgesetzt, bis keine na Werte mehr vorhanden sind. Am Ende wird ein Zähler ausgegeben, wie viele Iterationen vorgenommen wurden. "
   ]
  },
  {
   "cell_type": "code",
   "id": "4fc38349a0bc3179",
   "metadata": {},
   "source": [
    "columns = df_rainPowerPivot['rainSumDay'].columns.tolist()\n",
    "counter = 1\n",
    "cycle = 0\n",
    "\n",
    "while df_rainPowerPivot.isna().rainSumDay.any().sum() != 0:\n",
    "    cycle += 1\n",
    "    for column in columns:\n",
    "        df_rainPowerPivot[('rainSumDay', column)].fillna(df_rainPowerPivot[('rainSumDay', columns[counter])], inplace=True)\n",
    "        if counter == len(columns)-1:\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "print(\"Anzahl durchgeführter Zyklen zum kopieren:\\t\", cycle)\n",
    "df_rainPowerPivot.info()\n",
    "df_rainPowerPivot.head()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6dae30a1b928a6b",
   "metadata": {},
   "source": [
    "Nun werden die Stromdaten mit einer linearen Interpolation ergänzt. Die Kontrolle ergibt, dass die Zeitreihe von 1129 nicht aufgefüllt wird. Dies liegt wohl daran, dass ein Anfangswert fehlt. Aus diesem Grund werden die restlichen Werte mit einem Durchschnittswert der entsprechenden Spalte aufgefüllt."
   ]
  },
  {
   "cell_type": "code",
   "id": "bd47ab3e4252d669",
   "metadata": {},
   "source": [
    "df_rainPowerPivot.avgKwhConsum.interpolate(method='linear', inplace=True)\n",
    "df_powerPivotNa = df_rainPowerPivot[df_rainPowerPivot.isna().any(axis=1)]\n",
    "df_powerPivotNa.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dd1649046e6cb796",
   "metadata": {},
   "source": [
    "df_rainPowerPivot[('avgKwhConsum', 1129)].fillna(df_rainPowerPivot[('avgKwhConsum', 1129)].mean(), inplace=True)\n",
    "df_powerPivotNa = df_rainPowerPivot[df_rainPowerPivot.isna().any(axis=1)]\n",
    "print('Keine fehlende Werte?:\\t', df_rainPowerPivot.isna().any().sum() == 0)\n",
    "df_powerPivotNa.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3a444fd4e1f89ae0",
   "metadata": {},
   "source": [
    "Nachdem die Daten kopiert wurden, wird die Tabelle wieder umgestellt, damit die Grafiken erstellt werden können."
   ]
  },
  {
   "cell_type": "code",
   "id": "be9a8dc5a57858e9",
   "metadata": {},
   "source": [
    "df_rainPowerNew = pd.DataFrame(columns=['time', 'rainSumDay', 'bfsID', 'avgKwhConsum'])\n",
    "df_rainNew = df_rainPowerPivot['rainSumDay']\n",
    "df_powerNew = df_rainPowerPivot['avgKwhConsum']\n",
    "df_rainNew = df_rainNew.unstack().reset_index()\n",
    "df_rainNew.rename(columns={0:'rainSumDay'}, inplace=True)\n",
    "df_powerNew = df_powerNew.unstack().reset_index()\n",
    "df_powerNew.rename(columns={0:'avgKwhConsum'}, inplace=True)\n",
    "\n",
    "df_rainNew.head()\n",
    "df_powerNew.head()\n",
    "df_rainPowerNew = pd.merge(df_rainNew, df_powerNew, on=['bfsID', 'time'])\n",
    "df_rainPowerNew.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9f55b4e13fad7882",
   "metadata": {},
   "source": [
    "df_rainPowerNew.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "92201d52125e5c1",
   "metadata": {},
   "source": [
    "Zur Kontrolle werden die Daten erneut in einem Facet Grid dargestellt. Die Daten sehen nun vollständig aus. Bei der BFS-Nummer 1024 gibt es noch einen langen Bereich welcher keine Daten anzeigt aber nicht als NAN gewertet wurden. Da dies nicht weiter verfiziert werden kann, wird dieser Datenstamm so belassen. Dasselbe gilt für die BFS-Nummern 1121 und 1143. Diese Daten sehen so aus, als gäbe es einen aussergewöhnlichen Zeitraum, doch es fehlen Anhaltspunkte diese weiter zu untersuchen. <br>\n",
    "Mit diesen Datenreihen können nun weitere Untersuchungen angestellt werden."
   ]
  },
  {
   "cell_type": "code",
   "id": "5e125a6c5c4a9b88",
   "metadata": {},
   "source": [
    "# FacetGrid erstellen\n",
    "g = sns.FacetGrid(df_rainPowerNew, col='bfsID', col_wrap=3, height=4, sharex=True, sharey=False)\n",
    "g.map(sns.lineplot, 'time', 'rainSumDay')\n",
    "\n",
    "# Achsenbeschriftungen und Titel hinzufügen\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_xlabel('day')\n",
    "    ax.set_ylabel('mm rain')\n",
    "\n",
    "    # Intervall der x-Achsenbeschriftungen anpassen\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "    # Rotation der Beschriftungen\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_rotation(45)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f91d206578af718a",
   "metadata": {},
   "source": [
    "### Erstanalyse am Beispiel der Gemeinde Meggen\n",
    "Wie bei der Analyse mit den Smartmeterdaten und Sonnenminuten wird zunächst mit einem reduzierten Dataset gearbeitet von der Gemeinde Meggen."
   ]
  },
  {
   "cell_type": "code",
   "id": "2604560b852239c1",
   "metadata": {},
   "source": [
    "df_1063 = df_rainPowerNew.query('bfsID == 1063')\n",
    "df_1063.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "75e5e22e0acfccac",
   "metadata": {},
   "source": [
    "Die Zeitreihe wird erneut kontrolliert und scheint vollständig zu sein."
   ]
  },
  {
   "cell_type": "code",
   "id": "373cc2f6b0ebbe46",
   "metadata": {},
   "source": [
    "df_1063.drop(columns=['bfsID'], inplace=True)\n",
    "df_1063.info()\n",
    "print(pd.date_range(start = '2020-12-31', end='2024-03-06').difference(df_1063['time']))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "43eeb4169ffddfde",
   "metadata": {},
   "source": [
    "Der Stromverbrauch wurde bereits analysiert. Der Niederschlag zeigt ebenfalls eine leichte Saisonalität. In den Bereichen Sommer und Herbst scheint es tendenziell mehr Niederschlag zu geben, während es im Winter nach weniger Niederschlag aussieht."
   ]
  },
  {
   "cell_type": "code",
   "id": "cf791abe36f87b9e",
   "metadata": {},
   "source": [
    "meggenPlot, ax1 = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(x='time', y='avgKwhConsum', data=df_1063, ax=ax1).set(title='Vergleich des durchschnittlichen Stromverbrauches zu dem Niederschlag', xlabel='Datum', ylabel='Verbrauch in kWh')\n",
    "ax2 = ax1.twinx()\n",
    "sns.lineplot(data=df_1063, x='time', y='rainSumDay', ax=ax2, color='red').set(ylabel='Niederschlag mm')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "34fd1192f64003db",
   "metadata": {},
   "source": [
    "Als nächstes wird die Korrelation in Meggen betrachtet. Die Zeit-Spalte wird als Index verwendet. Mit einer Korrelation von -0.017 besteht kein Zusammenhang zwischen dem Niederschlag und des Stromverbrauches.<br>\n",
    "Die Autocorrelation gibt anhand verschiedener Intervall an, wie stark die Werte von vorhergehenden Punkten in derselben Zeitreihe beeinflusst werden. Bei dem Niederschlag gibt es keine Regelmässigkeiten. Die Korrelationen bezüglich dem Strom wurden bereits in der vorhergehenden Analyse mit der Sonne beleuchtet."
   ]
  },
  {
   "cell_type": "code",
   "id": "c3d10720d4d1bc12",
   "metadata": {},
   "source": [
    "df_1063.set_index('time', inplace=True)\n",
    "print('Korrelation zwischen den Parametern:\\n', df_1063.corr())\n",
    "print('\\nAutocorrelation des täglichen Niederschlages und Stromverbrauch:')\n",
    "autocorrOne = df_1063['rainSumDay'].autocorr(lag=1)\n",
    "print('Niederschlag 1-Tages-Intervall:\\t', autocorrOne)\n",
    "autocorrOneKwh = df_1063['avgKwhConsum'].autocorr(lag=1)\n",
    "print('Strom 1-Tages-Intervall:\\t', autocorrOneKwh)\n",
    "autocorr7 = df_1063['rainSumDay'].autocorr(lag=7)\n",
    "print('Niederschlag 7-Tages-Intervall:\\t', autocorr7)\n",
    "autocorr7Kwh = df_1063['avgKwhConsum'].autocorr(lag=7)\n",
    "print('Strom 7-Tages-Intervall:\\t', autocorr7Kwh)\n",
    "autocorr30 = df_1063['rainSumDay'].autocorr(lag=30)\n",
    "print('Niederschlag 30-Tages-Intervall:\\t', autocorr30)\n",
    "autocorr30Kwh = df_1063['avgKwhConsum'].autocorr(lag=30)\n",
    "print('Strom 30-Tages-Intervall:\\t', autocorr30Kwh)\n",
    "\n",
    "autocorr90 = df_1063['rainSumDay'].autocorr(lag=90)\n",
    "print('Niederschlag 90-Tages-Intervall:\\t', autocorr90)\n",
    "autocorr90Kwh = df_1063['avgKwhConsum'].autocorr(lag=90)\n",
    "print('Strom 90-Tages-Intervall:\\t', autocorr90Kwh)\n",
    "\n",
    "autocorr365 = df_1063['rainSumDay'].autocorr(lag=365)\n",
    "print('Niederschlag 365-Tages-Intervall:\\t', autocorr365)\n",
    "autocorr365Kwh = df_1063['avgKwhConsum'].autocorr(lag=365)\n",
    "print('Strom 365-Tages-Intervall:\\t', autocorr365Kwh)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8cccaeb23058f995",
   "metadata": {},
   "source": [
    "### Ausweitung der Analyse auf alle Gemeinden\n",
    "Im nächsten Schritt wird die Korrelation-Analyse auf die weiteren Gemeinden ausgeweitet. Hier wird keine Auftrennung in Ost und West benötigt, da die fehlenden Werte aufgefüllt wurden."
   ]
  },
  {
   "cell_type": "code",
   "id": "22d6add00f9d31cc",
   "metadata": {},
   "source": [
    "df_rainPowerPivot.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eeb9f94916926a9f",
   "metadata": {},
   "source": [
    "Für eine bessere optische Ansicht wird mit den Korrelation-Werten eine Heatmap erstellt. Was sofort auffällt sind die beiden violetten Vierecke die herausstechen. Das sind die Korrelationswerte zwischen dem Niederschlag und des Stromverbrauches pro Gemeinde. Aufgrund der Farb-Skallierung erkennt man den erkannten Trend bei der Meggen-Analyse. Die Korrelationen sind sehr schwach, daher besteht wohl eher kein Zusammenhang zwischen dem Niederschlag und dem Stromverbrauch. Unten rechts sind die Korrelationen zwischen dem Niederschlag zwischen den Gemeinden. Diese Werte sind hoch und deuten somit an, dass sich der Niederschlag im Kanton Luzern ähnlich verhält. Oben links befinden sich die Korrelationen zwischen den Gemeinden und des Stromverbrauchs. Vielfach verhaltet sich der Stromverbrauch ähnlich zu den Gemeinden. Es gibt aber einige Ausreisser. Dies kann mit den aussergewöhnlichen Anomalien Zusammenhängen, welche bei einigen Ortschaften in der ersten Analyse erkannt wurden. Dies ist z.B. bei der Gemeinde Kriens (plz=6010/BFS-Nummer=1059)."
   ]
  },
  {
   "cell_type": "code",
   "id": "ce76c3d935ab5848",
   "metadata": {},
   "source": [
    "print('Korrelation zwischen den Parametern:\\n', df_rainPowerPivot.corr())\n",
    "\n",
    "fig = plt.figure(figsize=(60, 60))\n",
    "sns.heatmap(df_rainPowerPivot.corr(), annot=True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aa40e1e6f9b06f58",
   "metadata": {},
   "source": [
    "Um die Korrelationen der Zeitreihen noch besser zu verstehen folgt der Test, der Autokorrelation."
   ]
  },
  {
   "cell_type": "code",
   "id": "8d9fe2dec00c4cdc",
   "metadata": {},
   "source": [
    "columns = list(df_rainPowerPivot)\n",
    "\n",
    "autocorrOneDay = []\n",
    "\n",
    "#1 Day Correlation\n",
    "for column in df_rainPowerPivot:\n",
    "    autocorrOneSun = df_rainPowerPivot[column].autocorr(lag=1)\n",
    "    col1 = column[0]+ 'OneDay'\n",
    "    autocorrOneDay.append([col1,column[1],autocorrOneSun])\n",
    "\n",
    "#7 Day Correlation\n",
    "for column in df_rainPowerPivot:\n",
    "    autocorrOneSun = df_rainPowerPivot[column].autocorr(lag=7)\n",
    "    col7 = column[0]+ '7Day'\n",
    "    autocorrOneDay.append([col7,column[1],autocorrOneSun])\n",
    "\n",
    "#30 Day Correlation\n",
    "for column in df_rainPowerPivot:\n",
    "    autocorrOneSun = df_rainPowerPivot[column].autocorr(lag=30)\n",
    "    col30 = column[0]+ '30Day'\n",
    "    autocorrOneDay.append([col30,column[1],autocorrOneSun])\n",
    "\n",
    "for column in df_rainPowerPivot:\n",
    "    autocorrOneSun = df_rainPowerPivot[column].autocorr(lag=90)\n",
    "    col90 = column[0]+ '90Day'\n",
    "    autocorrOneDay.append([col90,column[1],autocorrOneSun])\n",
    "\n",
    "for column in df_rainPowerPivot:\n",
    "    autocorrOneSun = df_rainPowerPivot[column].autocorr(lag=365)\n",
    "    col365 = column[0]+ '365Day'\n",
    "    autocorrOneDay.append([col365,column[1],autocorrOneSun])\n",
    "\n",
    "df = pd.DataFrame(autocorrOneDay)\n",
    "df = df.pivot(index=1, columns=0, values=2)\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2d17e95aea557027",
   "metadata": {},
   "source": [
    "Im Boxplot setzt sich die Erkenntnis von Meggen weiter. Die Korrelationen innerhalb der Intervalle liegen praktisch bei 0 und zeigen somit keinen Zusammenhang. Dies bedeutet z.B., wenn es heute regnet, muss dies nicht zwingend bedeuten, dass es dies in einem Jahr ebenfalls tut. Das Wetter in einem Jahr kann nicht durch das heutige Wetter vorhergesagt werden. Beim Strom kann dies eher behauptet werden."
   ]
  },
  {
   "cell_type": "code",
   "id": "511fd58d42a11d44",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "sns.boxplot(df).set(title='Korrelation innerhalb der Zeitreihen mit verschiedenen Intervallen')\n",
    "plt.show()\n",
    "df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1b4c7dbfd0713063",
   "metadata": {},
   "source": [
    "Für den Boxplot der Korrelationen zwischen den Parametern werden normale Korrelationsmatrixen erstellt und die nicht notwendigen Index und Spalten entfernt."
   ]
  },
  {
   "cell_type": "code",
   "id": "7f5bcd7c8889d06b",
   "metadata": {},
   "source": [
    "df_corrRain = df_rainPowerPivot[['avgKwhConsum', 'rainSumDay']].corr()\n",
    "df_corrRain.drop(columns=['rainSumDay'], index=['avgKwhConsum'],inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "102815855604f020",
   "metadata": {},
   "source": [
    "Der Boxplot das 75% der Korrelationswerte zwischen ca. 0.08 und -0.15 sind, also keine Korrelation aufweisen. Die restlichen 25% verteilen sich als Outlier oben und unten, wobei der Höchstwert bei ca. 0.2 liegt und der tiefste Wert bei -0.2."
   ]
  },
  {
   "cell_type": "code",
   "id": "91f4a00262477484",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(16,10))\n",
    "sns.boxplot(data=df_corrRain).set(title='Boxplot über die Korrelationen zwischen dem Niederschlag und Stromverbrauch')\n",
    "plt.show()\n",
    "df_corrRain.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "14e0696c33f190e6",
   "metadata": {},
   "source": [
    "Abschliessend kann festgehalten werden, dass der Niederschlag an sich keine Auswirkung auf den Stromverbrauch hat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24eba4e7f3b3d4f",
   "metadata": {},
   "source": [
    "## Datenanalyse Smartmeter mit der Temperatur\n",
    "Zuerst werden die Daten aus der Datenbank geladen und gleich im korrekten Zeitformat gesichert. Aus der Analyse ist bekannt, dass gewisse Stationen fehlende Daten ausweisen. Aus bestätigt sich erneut mit den fehlenden Temperatur Daten. Für die Analyse werden werden die durchschnittlichen Temperaturwerte pro Tag und BFS-Nummer verwendet."
   ]
  },
  {
   "cell_type": "code",
   "id": "86d1e5464d21c8bb",
   "metadata": {},
   "source": [
    "df_temp = pd.read_sql_query(\"SELECT * FROM avgTempPerDayBfsId\", connection)\n",
    "df_temp[['dataTime', 'hour']] = df_temp['dataTime'].str.split(' ', expand=True)\n",
    "df_temp['dataTime'] = pd.to_datetime(df_temp['dataTime'], format='%Y-%m-%d')\n",
    "df_temp.drop(columns=['hour'], inplace=True)\n",
    "df_temp.rename(columns={'dataTime':'time'}, inplace=True)\n",
    "print(df_temp.count())\n",
    "df_temp.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ccf73ee16fa60fad",
   "metadata": {},
   "source": [
    "Um eine eine erste Übersicht zu erhalten, werden die Daten in einer Grafik dargestellt. Man erkennt sogleich die naheliegende starke Saisonalität. Im Winter ist es kälter und im Sommer wärmer."
   ]
  },
  {
   "cell_type": "code",
   "id": "20abb9257dde1730",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "testPlot = sns.lineplot(x='time', y='avgTempDay', hue='meteoStation', data=df_temp).set(title='Durchschnittliche Temperatur pro Tag', xlabel='Datum', ylabel='Temperatur Grad Celsius')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "78a87a70ee49eb01",
   "metadata": {},
   "source": [
    "Um festzustellen, wo sich die fehlenden Daten befinden, wird eine Pivot Tabelle erstellt. Die fehlenden Werte sind mehrfach verteilt und müssen zu einem späteren Zeitpunkt einer Interpollation oder einer anderen Methode aufgefüllt werden."
   ]
  },
  {
   "cell_type": "code",
   "id": "9c3d61470d320ed4",
   "metadata": {},
   "source": [
    "df_tempPivot = df_temp.pivot(index='time', columns=['bfsID'], values=['avgTempDay'])\n",
    "df_rainPivot.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "645ccadf36f83746",
   "metadata": {},
   "source": [
    "Für den Stromverbrauch, werden die täglich aufsummierten kWh pro BFS-Nummer geladen. Die Tabelle wird pivotiert um die NAN-Werte zu identifizieren. Da es sich um dieselben Stromverbrauch-Daten handelt, wie in den vorhergehenden Analysen, werden diese zu einem späteren Zeitpunkt gleich behandelt bezüglich den NAN-Werten."
   ]
  },
  {
   "cell_type": "code",
   "id": "bf169e26dc4e857b",
   "metadata": {},
   "source": [
    "df_power = pd.read_sql_query(\"SELECT * FROM dailySumSmartmeterBfsId\", connection)\n",
    "df_power['time'] = pd.to_datetime(df_power['time'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bbd1c4710bbc68b1",
   "metadata": {},
   "source": [
    "df_powerPivot = df_power.pivot(index='time', columns=['bfsID'], values=['avgKwhConsum'])\n",
    "df_powerPivot.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9762e6458b3ee03a",
   "metadata": {},
   "source": [
    "Für die spätere Behandlung der NAN-Werte wird eine kombinierte Pivot Tabelle mit den Stromverbrauchs- und Temperatur-Daten gebildet."
   ]
  },
  {
   "cell_type": "code",
   "id": "790e7626bac934dc",
   "metadata": {},
   "source": [
    "df_tempPower = pd.merge(df_temp, df_power,on=['bfsID', 'time'])\n",
    "df_tempPower['time'] = pd.to_datetime(df_tempPower['time'])\n",
    "df_tempPower.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c9ee12cb76189247",
   "metadata": {},
   "source": [
    "df_tempPower.drop(columns=['meteoParameter', 'lawCityName', 'meteoStation'], inplace=True)\n",
    "df_tempPowerPivot = df_tempPower.pivot(index='time', columns=['bfsID'], values=['avgKwhConsum', 'avgTempDay'])\n",
    "df_rainPowerPivot.head()\n",
    "df_rainPowerPivot.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "882d9c45ae57a30d",
   "metadata": {},
   "source": [
    "Anhand der Grafiken, lassen sich nicht lange Zeiträume feststellen, wo es fehlende Daten gibt. Aus diesem Grund wird eine lineare Interpolation angewendet. Als Alternative hätten die fehlende Zeiträume mit Daten von anderen Messstationen zum gleichen Zeitpunkt kopiert werden können. Dieser Ansatz basiert auf der Idee, dass durch die relativ nahen geografischen Standorten, die Unterschiede nicht signifikant sein werden. Diese Annahme wird auch gestützt aufgrund der Korrelationsmatrix. Aus optischer Perspektive bewegen sich die Korrelationen um den Wert von 0.9."
   ]
  },
  {
   "cell_type": "code",
   "id": "fb12dcaac548adba",
   "metadata": {},
   "source": [
    "# FacetGrid erstellen\n",
    "g = sns.FacetGrid(df_temp, col='meteoStation', col_wrap=3, height=4, sharex=True, sharey=False)\n",
    "g.map(sns.lineplot, 'time', 'avgTempDay')\n",
    "\n",
    "# Achsenbeschriftungen und Titel hinzufügen\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_xlabel('day')\n",
    "    ax.set_ylabel('temperature celsius')\n",
    "\n",
    "    # Intervall der x-Achsenbeschriftungen anpassen\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "    # Rotation der Beschriftungen\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_rotation(45)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8094dadd89c7a42a",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(60, 60))\n",
    "sns.heatmap(df_tempPowerPivot.corr(), annot=True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3195124ae685d35d",
   "metadata": {},
   "source": [
    "Zuerst wird die Interpolation der Temperaturen vorgenommen."
   ]
  },
  {
   "cell_type": "code",
   "id": "62b69580a5119917",
   "metadata": {},
   "source": [
    "df_tempPowerPivot.avgTempDay.interpolate(method='linear', inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5318d033b659c3f5",
   "metadata": {},
   "source": [
    "Nun folgen die Interpolationen der Stromverbrauchsdaten nach dem bereits bekannten Muster."
   ]
  },
  {
   "cell_type": "code",
   "id": "e434f0458ecfb41a",
   "metadata": {},
   "source": [
    "df_tempPowerPivot.avgKwhConsum.interpolate(method='linear', inplace=True)\n",
    "df_tempPivotNa = df_tempPowerPivot[df_tempPowerPivot.isna().any(axis=1)]\n",
    "df_tempPivotNa.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "127a3dac440ebd1c",
   "metadata": {},
   "source": [
    "df_tempPowerPivot[('avgKwhConsum', 1129)].fillna(df_tempPowerPivot[('avgKwhConsum', 1129)].mean(), inplace=True)\n",
    "df_powerPivotNa = df_tempPowerPivot[df_tempPowerPivot.isna().any(axis=1)]\n",
    "print('Keine fehlende Werte?:\\t', df_tempPowerPivot.isna().any().sum() == 0)\n",
    "df_tempPivotNa.head(1000)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e65f92225ab5d02a",
   "metadata": {},
   "source": [
    "Die Schlusskontrolle zeigt, dass bei der BFS-Nummer 1129 der Start der Temperatur Zeitreihe fehlen. Aus diesem Grund werden diese Daten von einer anderen Station kopiert und ergänzt."
   ]
  },
  {
   "cell_type": "code",
   "id": "cccfbe4a212e1ece",
   "metadata": {},
   "source": [
    "columns = df_tempPowerPivot['avgTempDay'].columns.tolist()\n",
    "counter = 1\n",
    "cycle = 0\n",
    "\n",
    "while df_tempPowerPivot.isna().avgTempDay.any().sum() != 0:\n",
    "    cycle += 1\n",
    "    for column in columns:\n",
    "        df_tempPowerPivot[('avgTempDay', column)].fillna(df_tempPowerPivot[('avgTempDay', columns[counter])], inplace=True)\n",
    "        if counter == len(columns)-1:\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "print(\"Anzahl durchgeführter Zyklen zum kopieren:\\t\", cycle)\n",
    "df_rainPowerPivot.info()\n",
    "df_rainPowerPivot.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c030b7919cf053b1",
   "metadata": {},
   "source": [
    "Ein Kopierzyklus wurde durchgeführt. Die Abschlusskontrolle findet keine weiteren NAN-Werte aus diesem Grund kann nun mit der weiteren Analyse fortgefahren werden."
   ]
  },
  {
   "cell_type": "code",
   "id": "9665d69a22d223ff",
   "metadata": {},
   "source": [
    "print('Keine fehlende Werte?:\\t', df_tempPowerPivot.isna().any().sum() == 0)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f7bc0e458cb93bd5",
   "metadata": {},
   "source": [
    "Die vollständigen Zeitreihen werden wieder entpivotiert für die weitere Verwendung."
   ]
  },
  {
   "cell_type": "code",
   "id": "3fe6dc2987e807f7",
   "metadata": {},
   "source": [
    "df_tempPowerNew = pd.DataFrame(columns=['time', 'avgTempDay', 'bfsID', 'avgKwhConsum'])\n",
    "df_tempNew = df_tempPowerPivot['avgTempDay']\n",
    "df_powerNew = df_tempPowerPivot['avgKwhConsum']\n",
    "df_tempNew = df_tempNew.unstack().reset_index()\n",
    "df_tempNew.rename(columns={0:'avgTempDay'}, inplace=True)\n",
    "df_powerNew = df_powerNew.unstack().reset_index()\n",
    "df_powerNew.rename(columns={0:'avgKwhConsum'}, inplace=True)\n",
    "\n",
    "df_tempNew.head()\n",
    "df_tempNew.head()\n",
    "df_tempPowerNew = pd.merge(df_tempNew, df_powerNew, on=['bfsID', 'time'])\n",
    "df_tempPowerNew.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "89b1aa423b1b2a76",
   "metadata": {},
   "source": [
    "Zur Kontrolle werden die Daten erneut in einem Facet Grid dargestellt. Es bestehen noch immer keine Auffälligkeiten. Aus diesem Grund werden die weiteren Analysen mit diesen Zeitreihen durchgeführt."
   ]
  },
  {
   "cell_type": "code",
   "id": "c7853b94e5de59e4",
   "metadata": {},
   "source": [
    "df_rainPowerNew.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9c40e467c798aefa",
   "metadata": {},
   "source": [
    "# FacetGrid erstellen\n",
    "g = sns.FacetGrid(df_tempPowerNew, col='bfsID', col_wrap=3, height=4, sharex=True, sharey=False)\n",
    "g.map(sns.lineplot, 'time', 'avgTempDay')\n",
    "\n",
    "# Achsenbeschriftungen und Titel hinzufügen\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_xlabel('day')\n",
    "    ax.set_ylabel('mm rain')\n",
    "\n",
    "    # Intervall der x-Achsenbeschriftungen anpassen\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "\n",
    "    # Rotation der Beschriftungen\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_rotation(45)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "38ddba42ed837a51",
   "metadata": {},
   "source": [
    "### Erstanalyse am Beispiel der Gemeinde Meggen\n",
    "Wie bei den vorhergehenden Analysen mit den wird zunächst mit einem reduzierten Dataset gearbeitet von der Gemeinde Meggen."
   ]
  },
  {
   "cell_type": "code",
   "id": "7a819db9f9cb17d5",
   "metadata": {},
   "source": [
    "df_1063 = df_tempPowerNew.query('bfsID == 1063')\n",
    "df_1063.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "92de71a44ef15343",
   "metadata": {},
   "source": [
    "Die Zeitreihe wird erneut kontrolliert und ist vollständig."
   ]
  },
  {
   "cell_type": "code",
   "id": "bde40091b9db3c4b",
   "metadata": {},
   "source": [
    "df_1063.drop(columns=['bfsID'], inplace=True)\n",
    "df_1063.info()\n",
    "print(pd.date_range(start = '2020-12-31', end='2024-03-06').difference(df_1063['time']))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "772378695ed01793",
   "metadata": {},
   "source": [
    "Wie der Stromverbrauch, zeigt die Temperatur ebenfalls eine starke Saisonalität. Zudem scheint diese, sehr gegengleich auszuschlagen. Es zeichnet sich eine gute Korrelation ab."
   ]
  },
  {
   "cell_type": "code",
   "id": "cb3ef96157867a2b",
   "metadata": {},
   "source": [
    "meggenPlot, ax1 = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(x='time', y='avgKwhConsum', data=df_1063, ax=ax1).set(title='Vergleich des durchschnittlichen Stromverbrauches zu der durchschnittlichen Temperatur', xlabel='Datum', ylabel='Verbrauch in kWh')\n",
    "ax2 = ax1.twinx()\n",
    "sns.lineplot(data=df_1063, x='time', y='avgTempDay', ax=ax2, color='red').set(ylabel='Temperatur Grad Celsius')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "46c9071a867b62d6",
   "metadata": {},
   "source": [
    "Als nächstes wird die Korrelation in Meggen betrachtet. Die Zeit-Spalte wird als Index verwendet. Mit einer Korrelation von -0.87 besteht ein Zusammenhang zwischen der Temperatur und des Stromverbrauches. Durch das negative Vorzeichen, bedeutet dies ein umgekehrter Zusammenhang. Je tiefer die Temperatur, desto höher ist der Stromverbrauch.<br>\n",
    "Die Autocorrelation gibt anhand verschiedener Intervall an, wie stark die Werte von vorhergehenden Punkten in derselben Zeitreihe beeinflusst werden. Hier gibt es in beiden Fällen eine starke Korrelation auf den entsprechenden Intervallen. Ausgenommen das vierteljährliche Intervall. Die Temperatur ist im Folgejahr in einem ähnlichen Bereich wie heute."
   ]
  },
  {
   "cell_type": "code",
   "id": "80231b9d61552b4c",
   "metadata": {},
   "source": [
    "df_1063.set_index('time', inplace=True)\n",
    "print('Korrelation zwischen den Parametern:\\n', df_1063.corr())\n",
    "print('\\nAutocorrelation der durchschnittlichen Temperatur und Stromverbrauch:')\n",
    "autocorrOne = df_1063['avgTempDay'].autocorr(lag=1)\n",
    "print('Temperatur 1-Tages-Intervall:\\t', autocorrOne)\n",
    "autocorrOneKwh = df_1063['avgKwhConsum'].autocorr(lag=1)\n",
    "print('Strom 1-Tages-Intervall:\\t', autocorrOneKwh)\n",
    "autocorr7 = df_1063['avgTempDay'].autocorr(lag=7)\n",
    "print('Temperatur 7-Tages-Intervall:\\t', autocorr7)\n",
    "autocorr7Kwh = df_1063['avgKwhConsum'].autocorr(lag=7)\n",
    "print('Strom 7-Tages-Intervall:\\t', autocorr7Kwh)\n",
    "autocorr30 = df_1063['avgTempDay'].autocorr(lag=30)\n",
    "print('Temperatur 30-Tages-Intervall:\\t', autocorr30)\n",
    "autocorr30Kwh = df_1063['avgKwhConsum'].autocorr(lag=30)\n",
    "print('Strom 30-Tages-Intervall:\\t', autocorr30Kwh)\n",
    "\n",
    "autocorr90 = df_1063['avgTempDay'].autocorr(lag=90)\n",
    "print('Temperatur 90-Tages-Intervall:\\t', autocorr90)\n",
    "autocorr90Kwh = df_1063['avgKwhConsum'].autocorr(lag=90)\n",
    "print('Strom 90-Tages-Intervall:\\t', autocorr90Kwh)\n",
    "\n",
    "autocorr365 = df_1063['avgTempDay'].autocorr(lag=365)\n",
    "print('Temperatur 365-Tages-Intervall:\\t', autocorr365)\n",
    "autocorr365Kwh = df_1063['avgKwhConsum'].autocorr(lag=365)\n",
    "print('Strom 365-Tages-Intervall:\\t', autocorr365Kwh)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "41ea7ed72f2de8",
   "metadata": {},
   "source": [
    "### Ausweitung der Analyse auf alle Gemeinden\n",
    "Im nächsten Schritt wird die Korrelation-Analyse auf die weiteren Gemeinden ausgeweitet. Hier wird keine Auftrennung in Ost und West benötigt, da die fehlenden Werte aufgefüllt wurden."
   ]
  },
  {
   "cell_type": "code",
   "id": "9c9d197e8f1d31ae",
   "metadata": {},
   "source": [
    "df_tempPowerPivot.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c95d25bfaf2dd7d1",
   "metadata": {},
   "source": [
    "Für eine bessere optische Ansicht wird mit den Korrelation-Werten eine Heatmap erstellt. Was sofort auffällt sind die beiden violetten Vierecke die herausstechen. Das sind die Korrelationswerte zwischen der Temperatur und des Stromverbrauches pro Gemeinde. Aufgrund der Farb-Skallierung erkennt man den erkannten Trend bei der Meggen-Analyse. Die Korrelationen sind eher auf der starken negativen Seite, daher besteht wohl Zusammenhang zwischen dem Niederschlag und dem Stromverbrauch. Unten rechts sind die Korrelationen zwischen den Temperaturen zwischen den Gemeinden. Diese Werte sind hoch und deuten somit an, dass sich die Temperaturen im Kanton Luzern sehr ähnlich verhalten. Oben links befinden sich die Korrelationen zwischen den Gemeinden und des Stromverbrauchs. Vielfach verhaltet sich der Stromverbrauch ähnlich zu den Gemeinden. Es gibt aber einige Ausreisser. Dies kann mit den aussergewöhnlichen Anomalien Zusammenhängen, welche bei einigen Ortschaften in der ersten Analyse erkannt wurden. Dies ist z.B. bei der Gemeinde Kriens (plz=6010/BFS-Nummer=1059)."
   ]
  },
  {
   "cell_type": "code",
   "id": "ac171cfcb684a7f4",
   "metadata": {},
   "source": [
    "print('Korrelation zwischen den Parametern:\\n', df_tempPowerPivot.corr())\n",
    "\n",
    "fig = plt.figure(figsize=(60, 60))\n",
    "sns.heatmap(df_tempPowerPivot.corr(), annot=True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1f4bd99ece396838",
   "metadata": {},
   "source": [
    "Die Korrelationen werden nun noch weiter betrachtet zunächst in der Autokorrelation."
   ]
  },
  {
   "cell_type": "code",
   "id": "a35ae155b48df782",
   "metadata": {},
   "source": [
    "columns = list(df_tempPowerPivot)\n",
    "\n",
    "autocorrOneDay = []\n",
    "\n",
    "#1 Day Correlation\n",
    "for column in df_tempPowerPivot:\n",
    "    autocorrOneSun = df_tempPowerPivot[column].autocorr(lag=1)\n",
    "    col1 = column[0]+ 'OneDay'\n",
    "    autocorrOneDay.append([col1,column[1],autocorrOneSun])\n",
    "\n",
    "#7 Day Correlation\n",
    "for column in df_tempPowerPivot:\n",
    "    autocorrOneSun = df_tempPowerPivot[column].autocorr(lag=7)\n",
    "    col7 = column[0]+ '7Day'\n",
    "    autocorrOneDay.append([col7,column[1],autocorrOneSun])\n",
    "\n",
    "#30 Day Correlation\n",
    "for column in df_tempPowerPivot:\n",
    "    autocorrOneSun = df_tempPowerPivot[column].autocorr(lag=30)\n",
    "    col30 = column[0]+ '30Day'\n",
    "    autocorrOneDay.append([col30,column[1],autocorrOneSun])\n",
    "\n",
    "for column in df_tempPowerPivot:\n",
    "    autocorrOneSun = df_tempPowerPivot[column].autocorr(lag=90)\n",
    "    col90 = column[0]+ '90Day'\n",
    "    autocorrOneDay.append([col90,column[1],autocorrOneSun])\n",
    "\n",
    "for column in df_tempPowerPivot:\n",
    "    autocorrOneSun = df_tempPowerPivot[column].autocorr(lag=365)\n",
    "    col365 = column[0]+ '365Day'\n",
    "    autocorrOneDay.append([col365,column[1],autocorrOneSun])\n",
    "\n",
    "df = pd.DataFrame(autocorrOneDay)\n",
    "df = df.pivot(index=1, columns=0, values=2)\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1d84ed4ea14d906e",
   "metadata": {},
   "source": [
    "Auf die Boxplots des Stromverbrauchs wird nicht weiter eingegangen. Die Betrachtung der Boxplots über die Temperatur zeigen einen sehr engen Zusammenhang und keine grosse Streuung der Werte. Das 90-Tag-Intervall ist wie dem Stromverbrauch irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "id": "a630fc4d15e1ef42",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "sns.boxplot(df).set(title='Korrelation innerhalb der Zeitreihen mit verschiedenen Intervallen')\n",
    "plt.show()\n",
    "df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "12f4d9b8771a20c2",
   "metadata": {},
   "source": [
    "Für die Boxplots der Korrelationen zwischen den Temperaturen und Stromverbrauch, werden die nicht benötigten Daten entfernt."
   ]
  },
  {
   "cell_type": "code",
   "id": "434d4b3a7b85b0e7",
   "metadata": {},
   "source": [
    "df_corrTemp = df_tempPowerPivot[['avgKwhConsum', 'avgTempDay']].corr()\n",
    "df_corrTemp.drop(columns=['avgTempDay'], index=['avgKwhConsum'],inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7230749aa3229a83",
   "metadata": {},
   "source": [
    "Mit einem Median bei ca. -0.85 kann von einem starken Zusammenhang ausgegangen werden zwischen der Temperatur und dem Stromverbrauch. Auch bei der Betrachtung des 75% Quantil liegen alle Werte unter ca. -0.65. Dies deutet weiterhin auf einen Zusammenhang hin. Da es wahrscheinlich fehlerbehaftete Smartmeterdaten gibt, könnte die Korrelation noch höher sein."
   ]
  },
  {
   "cell_type": "code",
   "id": "a8c6590431eb2bd0",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(16,10))\n",
    "sns.boxplot(data=df_corrTemp).set(title='Boxplot über die Korrelationen zwischen den Temperaturen und Stromverbrauch')\n",
    "plt.show()\n",
    "df_corrTemp.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "732e5d024c2d7ce1",
   "metadata": {},
   "source": [
    "Abschliessend kann gesagt werden, dass die Temperatur und der Stromverbrauch zusammenhängen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f8e156c29b6bef",
   "metadata": {},
   "source": [
    "# Forecasting\n",
    "In diesem Kapitel wird versucht ein Vorhersage-Modell zu erstellen basierend auf den vorliegenden Erkenntnissen. Zuerst wird versucht anhand der Stromverbrauchs-Zeitreihe von Meggen eine Vorhersage zu treffen. Danach folgt ein Versuch mittels eines Regressions-Modell den Stromverbrauch mit der Temperatur vorherzusagen.\n",
    "\n",
    "## Vorhersage Stromverbrauch\n",
    "Für die Vorhersage des Stromverbrauchs wird erneut die Zeitreihe von Meggen verwendet mit den täglichen durchschnittlichen Stromverbrauchsdaten."
   ]
  },
  {
   "cell_type": "code",
   "id": "c1e58733a1d7d431",
   "metadata": {},
   "source": [
    "df_powerMeggen = df_1063.copy()\n",
    "df_powerMeggen.drop(columns=['avgTempDay'], inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "90ded9c0fe0796e4",
   "metadata": {},
   "source": [
    "df_powerMeggen.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b43f82f56ed90012",
   "metadata": {},
   "source": [
    "Um die Daten zu glätten werden verschiedene Methoden versucht anzuwenden. Darunter gehören die:\n",
    "- Rolling Mean Intervall 7\n",
    "- Rolling Mean Intervall 365\n",
    "- Rolling Standard Deviation Intervall 7\n",
    "- Rolling Standard Deviation Intervall 365\n",
    "Die Intervalle wurden ausgewählt aufgrund der Autocorrelation Analyse in dem vorherigen Kapitel."
   ]
  },
  {
   "cell_type": "code",
   "id": "bccd31544af05157",
   "metadata": {},
   "source": [
    "rolmean7 = df_powerMeggen.rolling(window=7).mean()\n",
    "rolmean14 = df_powerMeggen.rolling(window=14).mean()\n",
    "rolmean30 = df_powerMeggen.rolling(window=30).mean()\n",
    "rolmean90 = df_powerMeggen.rolling(window=90).mean()\n",
    "rolmean365 = df_powerMeggen.rolling(window=365).mean()\n",
    "rolstd7 = df_powerMeggen.rolling(window=7).std()\n",
    "rolstd14 = df_powerMeggen.rolling(window=14).std()\n",
    "rolstd30 = df_powerMeggen.rolling(window=30).std()\n",
    "rolstd90 = df_powerMeggen.rolling(window=90).std()\n",
    "rolstd365 = df_powerMeggen.rolling(window=365).std()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "af9eea57efda8520",
   "metadata": {},
   "source": [
    "Rot wird die originale Zeitreihe dargestellt. Die anderen Farben repräsentieren die Versuche die Kurve zu glätten. Mit dem wöchigen Intervall werden die Daten durch den Rolling Mean gut dargestellt. Mit der Standardabweichung wird das Rauschen entlang des Durchschnittes dargestellt. Bei der Betrachtung des Intervalls von 365 wird die Saisonalität herausgefiltert und es zeichnet sich ein leichter negativer Trend ab. Die Saisonalität muss noch weiter untersucht werden. <br>\n",
    "Mit dem Rolling Mean können die Kurven geglättet werden, die Kurve mit dem einem Intervall von sieben, beschreibt die Daten sehr gut und behält die Spitzen. Das 30-Tage Intervall glättet die Kurven am Besten ohne die jährliche Saisonalität zu verlieren. Das 90-Tage Intervall glättet noch besser, ist aber bereits stark verschoben. <br>\n",
    "Die Standardabweichung wird immer glatter aber höher, je höher das Intervall gewählt wird."
   ]
  },
  {
   "cell_type": "code",
   "id": "54bd78aa4fadb1d9",
   "metadata": {},
   "source": [
    "fig = plt.figure()\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "sns.lineplot(data=df_powerMeggen, x='time', y='avgKwhConsum', label='Täglicher durchschnittler Stromverbrauch pro Smartmeter', color='red').set(title='Vergleich täglicher Stromverbrauch für Meggen', xlabel='Zeit', ylabel='Täglicher durchschnittler Verbrauch pro Smartmeter (kWh)')\n",
    "sns.lineplot(x='time', y='avgKwhConsum', data=rolmean7, label='7-Rolling Mean Strom kWh', color='blue').set()\n",
    "sns.lineplot(x='time', y='avgKwhConsum', data=rolstd7, label='7-Rolling Standard Deviation kWh', color='green').set()\n",
    "sns.lineplot(x='time', y='avgKwhConsum', data=rolmean14, label='14-Rolling Mean Strom kWh', color='brown').set()\n",
    "sns.lineplot(x='time', y='avgKwhConsum', data=rolstd14, label='14-Rolling Standard Deviation kWh', color='navy').set()\n",
    "sns.lineplot(x='time', y='avgKwhConsum', data=rolmean30, label='30-Rolling Mean Strom kWh', color='orange').set()\n",
    "sns.lineplot(x='time', y='avgKwhConsum', data=rolstd30, label='30-Rolling Standard Deviation kWh', color='grey').set()\n",
    "sns.lineplot(x='time', y='avgKwhConsum', data=rolmean90, label='90-Rolling Mean Strom kWh', color='yellow').set()\n",
    "sns.lineplot(x='time', y='avgKwhConsum', data=rolstd90, label='90-Rolling Standard Deviation kWh', color='purple').set()\n",
    "sns.lineplot(x='time', y='avgKwhConsum', data=rolmean365, label='365-Rolling Mean Strom kWh', color='black').set()\n",
    "sns.lineplot(x='time', y='avgKwhConsum', data=rolstd365, label='365-Rolling Standard Deviation kWh', color='grey').set()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "629d8c7f9d0a916",
   "metadata": {},
   "source": [
    "### Decomposition\n",
    "Die Zeitreihe wird nun zerlegt in verschiedene Perioden um verschiedene Saisonalitäten festzustellen.<br>\n",
    "Anhand des Trends ist erkennbar, dass der Stromverbrauch über die letzten drei Jahre zurückgegangen ist. Innerhalb der jeder Periode sind Saisonalitäten erkennbar."
   ]
  },
  {
   "cell_type": "code",
   "id": "df3d0efb0262f2c2",
   "metadata": {},
   "source": [
    "ax = plt.figure(figsize = (30,80))\n",
    "mstl = MSTL(df_powerMeggen, periods=[7, 14, 30, 365])\n",
    "res = mstl.fit()\n",
    "ax = res.plot()\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "89188d6d51fb04a2",
   "metadata": {},
   "source": [
    "Die gleiche Analyse mit dem Rolling Mean über 30 Tage zeigt noch immer die Saisonalität zu den gegebenen Perioden an."
   ]
  },
  {
   "cell_type": "code",
   "id": "6527b3213bded1a",
   "metadata": {},
   "source": [
    "rolmean30.dropna(inplace=True)\n",
    "mstlrol30 = MSTL(rolmean30['avgKwhConsum'], periods=[7, 14, 30, 365])\n",
    "res30 = mstlrol30.fit()\n",
    "res30.seasonal.head()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "449cc229add39272",
   "metadata": {},
   "source": [
    "ax = res30.plot()\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9352218716878a06",
   "metadata": {},
   "source": [
    "In einer näheren Betrachtung der Saisonalitäten werden die tiefen sowie Spitzen erkennbar. Bei der wöchentlichen Ansicht, werden die ersten zwei Wochen ausgeblendet, da es sich dort um eine Ferienzeit handelt. Zur Eindordnung, der 14.1.2021 ist ein Donnerstag. Demzufolge ist der 16.1/17.1 das Wochenende. Die wöchentliche Saisonalität zeigt, dass es jeweils am Donnerstag einen Einbruch des Stromverbrauches gibt. Dieser steigt bis zum Freitag wieder, auf den Samstag ebenfalls bevor er auf den Sonntag jeweils sinkt. Am Montag scheint sich jeweils der Peak des Stromverbrauches zu zeigen.<br>\n",
    "Bei der Betrachtung des 14-Tages Zyklus sieht man, dass dieser im zwei Wochen Rhythms sinkt und steigt. Dasselbe gilt für den 30-Tages Zyklus. Jeweils gegen Ende des Monats sinkt der Verbrauch und Mitte des Monats wird am meisten Strom benötigt."
   ]
  },
  {
   "cell_type": "code",
   "id": "ea7a804b347b95e2",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(nrows=4, figsize=[10,10])\n",
    "res.seasonal[\"seasonal_7\"].iloc[14:7*6].plot(ax=ax[0])\n",
    "ax[0].set_ylabel(\"seasonal_7\")\n",
    "ax[0].set_title(\"Weekly seasonality\")\n",
    "\n",
    "res.seasonal[\"seasonal_14\"].iloc[14:14*4].plot(ax=ax[1])\n",
    "ax[1].set_ylabel(\"seasonal_14\")\n",
    "ax[1].set_title(\"2-Weekly seasonality\")\n",
    "\n",
    "res.seasonal[\"seasonal_30\"].iloc[:30*3].plot(ax=ax[2])\n",
    "ax[2].set_ylabel(\"seasonal_30\")\n",
    "ax[2].set_title(\"Monthly seasonality\")\n",
    "\n",
    "res.seasonal[\"seasonal_365\"].iloc[:365*3].plot(ax=ax[3])\n",
    "ax[3].set_ylabel(\"seasonal_365\")\n",
    "ax[3].set_title(\"Yearly seasonality\")\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c661a64c6d510d06",
   "metadata": {},
   "source": [
    "Nachstehend noch der Vergleich in den Sommermonaten 2021. Die Wöchentliche Saisonalität ist nun deutlich ausgeprägter. Zur Einordnung der 19.6/20.6 sind Samstag und Sonntag. Im Gegensatz zu den Wintermonaten, bricht der Stromverbrauch am Mittwoch ein und nicht mehr am Donnerstag. Klar zu erkennen ist, dass am Wochenende am wenigsten Strom verbraucht wird. Das 14-Tage Intervall zeigt kaum mehr eine Saisonalität. Wobei das 30-Tage Intervall noch immer ausgeprägt ist."
   ]
  },
  {
   "cell_type": "code",
   "id": "7268caed4012d8b4",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(nrows=3, figsize=[10,10])\n",
    "res.seasonal[\"seasonal_7\"].iloc[7*24:7*28].plot(ax=ax[0])\n",
    "ax[0].set_ylabel(\"seasonal_7\")\n",
    "ax[0].set_title(\"Weekly seasonality\")\n",
    "\n",
    "res.seasonal[\"seasonal_14\"].iloc[7*24:7*32].plot(ax=ax[1])\n",
    "ax[1].set_ylabel(\"seasonal_14\")\n",
    "ax[1].set_title(\"2-Weekly seasonality\")\n",
    "\n",
    "res.seasonal[\"seasonal_30\"].iloc[7*24:7*36].plot(ax=ax[2])\n",
    "ax[2].set_ylabel(\"seasonal_30\")\n",
    "ax[2].set_title(\"Monthly seasonality\")\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e94965875b1205ac",
   "metadata": {},
   "source": [
    "Für die Vorhersage ist es wichtig zu Wissen ob es sich bei der Zeitreihe um eine stationäre oder nicht-stationäre Zeitreihe handelt. Dies aus dem Grund, weil stationäre Daten besser vorhergesagt werden können, da dort keine Brüche in Trends, Saisonalität oder Zyklen aufweisen. Also die Variance, Durchschnitt oder Autokorrelation sind konstant über die Zeit.<br>\n",
    "Aus den vorhergehenden Analyse wissen wir bereits, dass es verschiedene Saisonalitäten gibt und sich die Autokorrelation über die Zeit ändert, je nach gewähltem Intervall. Der Augmented Dickey-Fuller Test hilft dabei festzustellen, ob es um stationäre oder nicht-stationäre Daten handelt. Die untstehende Funktion stammt von Daniel Benninger ([GitHub](https://github.com/sawubona-repo/BINA-FS24-WORK/blob/main/LB06-Regression%2BTimeSeries/Python/Python_JUPYTER_TIMESERIES_AirPassengers.ipynb), 2024)"
   ]
  },
  {
   "cell_type": "code",
   "id": "3383a1e8bdf9766f",
   "metadata": {},
   "source": [
    "# define ADF stationarity test function for a time series\n",
    "def stationarity_test(timeseries):\n",
    "    # Augmented Dickey-Fuller (ADF) test\n",
    "    print('Results of Augmented-Dickey-Fuller (ADF) Test\\n')\n",
    "    df_test = adfuller(timeseries)\n",
    "\n",
    "    df_output = pd.Series(df_test[0:4], index = ['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
    "    for key, value in df_test[4].items():\n",
    "        df_output['Critical Value (%s)' %key] = value\n",
    "\n",
    "    print(df_output)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "923c24f897ac4a90",
   "metadata": {},
   "source": [
    "Der Test hat ergeben mit einem p-Value von 0.11, dass es sich um eine nicht-stationäre Zeitreihe handelt und die Variance nicht konstant über die Zeit ist. Auch die Teststatistik ist nicht kleiner wie die kritischen 1%, 5% oder 10% Intervalle. Damit werden die vorhergehenden Untersuchungen bestätigt und es handelt sich nicht um stationäre Daten."
   ]
  },
  {
   "cell_type": "code",
   "id": "acb9f94f76ffbf51",
   "metadata": {},
   "source": [
    "series = df_powerMeggen['avgKwhConsum'].values\n",
    "\n",
    "stationarity_test(series)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "419926fe15fe064d",
   "metadata": {},
   "source": [
    "Mit den First-Differences wird nun versucht aus den nicht stationären Daten, stationäre Daten zu produzieren. Der ADF Test scheint zu bestätigen, dass es sich nun um stationäre Daten handelt. Mit diesen wird nun versucht ein ARIMA-Model zu füllen."
   ]
  },
  {
   "cell_type": "code",
   "id": "81102f52d34572ab",
   "metadata": {},
   "source": [
    "df_diff = df_powerMeggen\n",
    "df_diff = df_diff.diff(periods = 7)\n",
    "df_diff.dropna(inplace=True)\n",
    "series = df_diff['avgKwhConsum'].values\n",
    "\n",
    "stationarity_test(series)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3cf6f3a5261c9442",
   "metadata": {},
   "source": [
    "### AutoARIMA Model\n",
    "Für die Modellierung wird zunächst ein Training-Set und ein Test-Set erstellt. Es wird ein Set für die First-Differences und die echten Daten erstellt."
   ]
  },
  {
   "cell_type": "code",
   "id": "768dab5ad1eb6883",
   "metadata": {},
   "source": [
    "df_trainPower = df_powerMeggen[df_powerMeggen.index < pd.to_datetime(\"2023-06-01\", format='%Y-%m-%d')].copy()\n",
    "df_trainPower.rename(columns={'avgKwhConsum': 'train'}, inplace=True)\n",
    "df_trainPower.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b0ecb7ae74ab35e2",
   "metadata": {},
   "source": [
    "df_trainPowerDiff = df_diff[df_diff.index < pd.to_datetime(\"2023-06-01\", format='%Y-%m-%d')].copy()\n",
    "df_trainPowerDiff.rename(columns={'avgKwhConsum': 'train'}, inplace=True)\n",
    "df_trainPowerDiff.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c564250fff3a0096",
   "metadata": {},
   "source": [
    "df_testPower = df_powerMeggen[df_powerMeggen.index >= pd.to_datetime(\"2023-06-01\", format='%Y-%m-%d')].copy()\n",
    "df_testPower.rename(columns={'avgKwhConsum': 'test'}, inplace=True)\n",
    "df_testPower.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2d4317edf224a204",
   "metadata": {},
   "source": [
    "df_testPowerDiff = df_diff[df_diff.index >= pd.to_datetime(\"2023-06-01\", format='%Y-%m-%d')].copy()\n",
    "df_testPowerDiff.rename(columns={'avgKwhConsum': 'test'}, inplace=True)\n",
    "df_testPowerDiff.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "753ef652c9cd9e69",
   "metadata": {},
   "source": [
    "In der Grafik sind Trainingsdaten und Testdaten ersichtlich."
   ]
  },
  {
   "cell_type": "code",
   "id": "ac9030c5d77ad96b",
   "metadata": {},
   "source": [
    "plt.plot(df_trainPower, color = \"black\")\n",
    "plt.plot(df_testPower, color = \"red\")\n",
    "plt.title(\"Train/Test Trennung des Stromverbrauchs (echte Daten)\")\n",
    "plt.ylabel(\"Stromverbrauch kWh\")\n",
    "plt.xlabel('Tag')\n",
    "plt.xticks(rotation=90)\n",
    "sns.set()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ad0a6e41c426684d",
   "metadata": {},
   "source": [
    "plt.plot(df_trainPowerDiff, color = \"black\")\n",
    "plt.plot(df_testPowerDiff, color = \"red\")\n",
    "plt.title(\"Train/Test Trennung des Stromverbrauchs (First-Differences)\")\n",
    "plt.ylabel(\"Stromverbrauch kWh\")\n",
    "plt.xlabel('Tag')\n",
    "plt.xticks(rotation=90)\n",
    "sns.set()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d850c299be1ead3b",
   "metadata": {},
   "source": [
    "Nun wird das AutoARIMA Modell mit den Trainingsdaten bespielt. Zuerst mit einer Saisonalität von 7-Tagen."
   ]
  },
  {
   "cell_type": "code",
   "id": "ba210c8363ce1e54",
   "metadata": {},
   "source": [
    "model = pm.auto_arima(df_trainPower,\n",
    "                      m=7, seasonal=True,\n",
    "                      error_action='ignore',\n",
    "                      suppress_warnings=True,\n",
    "                      stepwise=True, trace=True)\n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70d67cfe52baf500",
   "metadata": {},
   "source": [
    "modelDiff = pm.auto_arima(df_trainPowerDiff,\n",
    "                      m=7, seasonal=True,\n",
    "                      error_action='ignore',\n",
    "                      suppress_warnings=True,\n",
    "                      stepwise=True, trace=True)\n",
    "modelDiff.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b646fd58c307ea9d",
   "metadata": {},
   "source": [
    "Mit beiden Modellen werden nun die Vorhersagen getroffen und mit den Test Daten verglichen."
   ]
  },
  {
   "cell_type": "code",
   "id": "4201ae99af94471c",
   "metadata": {},
   "source": [
    "pred = model.predict(n_periods=len(df_testPower), index=df_testPower)\n",
    "predDiff = modelDiff.predict(n_periods=len(df_testPowerDiff), index=df_testPowerDiff)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c492b7f75690355b",
   "metadata": {},
   "source": [
    "Bei den echten Daten erkennt ARIMA den abwärts Trend aber nicht mehr die Saisonalität mit dem zunehmenden Stromverbrauch. Der 7-Tages Intervall ist zu kurz um den weiteren aufwärts Trend zu erkennen. Die Vorhersage passt nicht zu den echten Daten."
   ]
  },
  {
   "cell_type": "code",
   "id": "abffd21ef52e1048",
   "metadata": {},
   "source": [
    "plt.plot(df_trainPower, color = \"black\")\n",
    "plt.plot(df_testPower, color = \"red\")\n",
    "plt.plot(pred, color = \"blue\")\n",
    "plt.title(\"Vergleich der Vorhersage mit den Testdaten (echte Daten)\")\n",
    "plt.ylabel(\"Stromverbrauch kWh\")\n",
    "plt.xlabel('Tag')\n",
    "plt.xticks(rotation=90)\n",
    "sns.set()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "346a3686714cee5f",
   "metadata": {},
   "source": [
    "Mit den First Differences sieht es ähnlich aus. Zu Beginn wird erkannt, dass die Daten gering schwanken. Der Trend in der Vorhersage geht dann gegen 0 obwohl in der Realität die Schwankungen wieder zunehmen. Daher ist auch dieses Modell für die Vorhersage geeignet."
   ]
  },
  {
   "cell_type": "code",
   "id": "5631334c2f6a34d2",
   "metadata": {},
   "source": [
    "plt.plot(df_trainPowerDiff, color = \"black\")\n",
    "plt.plot(df_testPowerDiff, color = \"red\")\n",
    "plt.plot(predDiff, color = \"blue\")\n",
    "plt.title(\"Vergleich der Vorhersage mit den Testdaten (First-Differences)\")\n",
    "plt.ylabel(\"Stromverbrauch kWh\")\n",
    "plt.xlabel('Tag')\n",
    "plt.xticks(rotation=90)\n",
    "sns.set()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "777118c44043ed1c",
   "metadata": {},
   "source": [
    "Der nächste Schritt wäre mit den echten Daten ein AutoARIMA Modell zu erstellen mit einem jährlichen Intervall. Doch mehrere Versuche sind gescheitert, da nach 40min (MacBook Pro mit M3 Pro) jeweils ein Memory Leak entstanden ist und zum Abbruch führte. Bis zu diesem Zeitpunkt konnten zwischen 6-7 Schritte von ARIMA durchgeführt werden für das passende Modell. Auf Goggle Colab brach der Prozess mehrfach nach ca. 2h ab mit demselben Fehler und der ungefähr gleichen Anzahl an Schritte. Recherchen haben gezeigt, dass es wohl an der Multi-Saisonalität liegt, die bereits in der vorhergehenden Analysen gefunden wurde. Damit kann ARIMA schlecht umgehen. <br>\n",
    "Aus diesem Grund wurde TBATS als Alternative gefunden. Bei diesem Algorithmus können die Saisonalitäten mitgegeben werden. Nachfolgend folgt ein Versuch mit den echten Daten. Es werden die bekannten Saisonalitäten mitgegeben und der Trend auf True gesetzt, da sich über die drei Jahre ein negativer Trend angedeutet hat."
   ]
  },
  {
   "cell_type": "code",
   "id": "9c5cef2649aaf18a",
   "metadata": {},
   "source": [
    "#model = pm.auto_arima(df_trainPower,\n",
    "#                      m=365, seasonal=True,\n",
    " #                     error_action='ignore',\n",
    "  #                    suppress_warnings=True,\n",
    "   #                   stepwise=True, trace=True)\n",
    "#model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "911076b99b3307f8",
   "metadata": {},
   "source": [
    "estimator = TBATS(seasonal_periods=(7, 14, 30, 365), use_trend=True)\n",
    "model_tbats = estimator.fit(df_trainPower)\n",
    "forecast = model_tbats.forecast(steps=len(df_testPower))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "99946a4655fd2c0a",
   "metadata": {},
   "source": [
    "Die Vorhersage sieht nun passender aus, da die Saisonalität erkannt wurde. Doch auch diese Kurve ist nicht passend und zu wenig gut um diese zu verwenden."
   ]
  },
  {
   "cell_type": "code",
   "id": "c71eda6859322154",
   "metadata": {},
   "source": [
    "df_forecast = pd.DataFrame(forecast, index=df_testPower.index)\n",
    "plt.plot(df_trainPower, color = \"black\")\n",
    "plt.plot(df_testPower, color = \"red\")\n",
    "plt.plot(df_forecast, color = \"blue\")\n",
    "plt.title(\"Vergleich der Vorhersage mit den Testdaten (TBATS)\")\n",
    "plt.ylabel(\"Stromverbrauch kWh\")\n",
    "plt.xlabel('Tag')\n",
    "plt.xticks(rotation=90)\n",
    "sns.set()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8871683858c99200",
   "metadata": {},
   "source": [
    "### Zusammenfassung\n",
    "Es wurde eine mehrfache Saisonalität erkannt und das es sich um nicht stationäre Daten handelt. Dies macht die Vorhersage schwierig mit nur dieser Zeitreihe. Aus den vorhergehenden Anaylsen konnte zudem erkannt werden das externe Faktoren (hauptsächlich Temperatur) einen Einfluss auf den Stromverbrauch haben. Die hier verwendeten Algorithmen unterstützen keine Multivariate Modelle. AutoARIMA hat sich als nicht geeignet herausgestellt aufgrund der Multisaisonalität. TBATS kommt der echten Welt am nächsten aber ebenfalls nicht genügend. Zumindest wird dort die jährliche Saisonalität erkannt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b510c3c79e8d7cab",
   "metadata": {},
   "source": [
    "## Regression Model Stromverbrauch und Temperatur\n",
    "Da ein Zusammenhang zwischen dem Stromverbrauch und der Temperatur erkannt wurde, wird versucht ein Regression Model zu erstellen. Dazu werden wieder die Daten von Meggen verwendet.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2c6d57b22b164547",
   "metadata": {},
   "source": [
    "df_meggen = df_1063.copy()\n",
    "df_meggen.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f0cce589eee6bc1",
   "metadata": {},
   "source": [
    "Die Daten werden nun in einem Scatterplot dargestellt um eine Tendenz zu finden. Es scheint einen negativen liniearen Zusammenhang zugeben. Dies haben die Korrelationen aus der früheren Analysen bereits angedeutet. Ein Outlier ist erkennbar gegen Unten Links."
   ]
  },
  {
   "cell_type": "code",
   "id": "1113d0beba3076c0",
   "metadata": {},
   "source": [
    "sns.scatterplot(df_meggen, x='avgTempDay', y='avgKwhConsum').set(title='Scatterplot zischen Temperatur und dem Stromverbrauch', xlabel='Temperatur Grad Celsius', ylabel='Stromverbrauch kWh')\n",
    "plt.figsize = (10,5)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "12fbd418410a80bd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "38fb7d7aa13f1507",
   "metadata": {},
   "source": [
    "power_train, power_test, temp_train, temp_test = train_test_split(df_meggen['avgKwhConsum'], df_meggen['avgTempDay'], train_size = 0.8, test_size = 0.2, random_state = 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eb0b8686f4080e40",
   "metadata": {},
   "source": [
    "power_train.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5eea2cbe7da418a",
   "metadata": {},
   "source": [
    "power_test.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aba507d4186cf118",
   "metadata": {},
   "source": [
    "temp_train.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5dcf61ae6e222619",
   "metadata": {},
   "source": [
    "temp_test.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a46f6ca0594e7609",
   "metadata": {},
   "source": [
    "Das Regression-Model wird nach der Vorlage von Daniel Benninger erstellt ([GitHub](https://github.com/sawubona-repo/BINA-FS24-WORK/blob/main/LB06-Regression%2BTimeSeries/Python/Python_JUPYTER_Linear_REGRESSION_Advertising.ipynb), 2024). Das Modell gibt eine negative Steigung an und einen Intercept von 21.31."
   ]
  },
  {
   "cell_type": "code",
   "id": "c039c2761be8722d",
   "metadata": {},
   "source": [
    "# Add a constant to get an intercept\n",
    "temp_train_sm = sm.add_constant(temp_train)\n",
    "\n",
    "# Fit the Regression Line using 'OLS' (ordinary least square)\n",
    "lr = sm.OLS(power_train, temp_train_sm).fit()\n",
    "lr.params"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1db061639fc584d7",
   "metadata": {},
   "source": [
    "Anhand der Zusammenfassung wird bestätigt, dass mit einem tiefen p-Value die Koeffizienten einen signifikanten Einfluss auf den Stromverbrauch haben. Mit einem R-squared Wert von 0.753 werden die Daten gut beschrieben."
   ]
  },
  {
   "cell_type": "code",
   "id": "6d537b78e33ad2d0",
   "metadata": {},
   "source": [
    "print(lr.summary())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "37d67acc72f0a649",
   "metadata": {},
   "source": [
    "In der Grafik erkennt man, dass die lineare Linie gut zu den Punkten passt."
   ]
  },
  {
   "cell_type": "code",
   "id": "a4f064d76058ea51",
   "metadata": {},
   "source": [
    "plt.scatter(temp_train, power_train)\n",
    "plt.plot(temp_train, 21.3065 + -0.5574*temp_train, 'r')\n",
    "\n",
    "plt.title('Originale Daten und das lineare Model')\n",
    "plt.figsize = (10,5)\n",
    "\n",
    "# Set x-axis label\n",
    "plt.xlabel('Temperatur Grad Celsius')\n",
    "# Set y-axis label\n",
    "plt.ylabel('Stromverbrauch kWh')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "684c916fc9cbcbf9",
   "metadata": {},
   "source": [
    "### Modell Evaluation\n",
    "Um das Modell zu bestätigen, werden die Residiuale analysiert um die Zuverlässigkeit zu prüfen. Dazu wird die Verteilung der Abweichungen von der linearen Linie zu den realen Punkten analysiert. Die Verteilung ist normalverteilt mit einem Durschnitt von 0. Es gibt eine Aussnahme links aussen, diese stammt wohl von dem erkannten Outlier und kann ignoriert werden."
   ]
  },
  {
   "cell_type": "code",
   "id": "4df0e654611bd7a8",
   "metadata": {},
   "source": [
    "power_train_pred = lr.predict(temp_train_sm)\n",
    "res = (power_train - power_train_pred)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ad96e913b7b98c6f",
   "metadata": {},
   "source": [
    "plt.figure()\n",
    "sns.displot(res, bins = 15, kde=True)\n",
    "\n",
    "plt.title('Model Evaluation: Verteilung der Error Terms', fontsize = 15)\n",
    "plt.xlabel('power_train - power_train_pred', fontsize = 15)         # X-label\n",
    "\n",
    "plt.figsize = (10,5)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "68b3596f8dadec64",
   "metadata": {},
   "source": [
    "Die Residuale zeigen, dass die Daten gut beschrieben werden durch das lineare Modell. Im tieferen Temperaturen Bereich gibt es noch eine grössere Streuung auf als im höheren Bereich. Da gibt es noch Faktoren, die nicht durch dieses Model beschrieben werden können."
   ]
  },
  {
   "cell_type": "code",
   "id": "34cfa05a45dc4ee1",
   "metadata": {},
   "source": [
    "plt.scatter(temp_train,res)\n",
    "\n",
    "plt.title('Model Evaluation: Residual Patterns', fontsize = 15)\n",
    "plt.ylabel('power_train - power_train_pred', fontsize = 15)         # Y-label\n",
    "\n",
    "plt.figsize = (10,5)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e4e9b0fbdf296ef1",
   "metadata": {},
   "source": [
    "### Vorhersagen basierend auf dem Test Set\n",
    "Mit dem evaluierten Model können nun die Vorhersagen getestet werden. Der RMSE Wert sowie der R-squared Wert deuten auf ein gut passendes Modell hin."
   ]
  },
  {
   "cell_type": "code",
   "id": "cd941bef3573304a",
   "metadata": {},
   "source": [
    "# Add a constant to X_test\n",
    "temp_test_sm = sm.add_constant(temp_test)\n",
    "\n",
    "# Predict the y values corresponding to X_test_sm\n",
    "power_pred = lr.predict(temp_test_sm)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "57a0b94fd1550769",
   "metadata": {},
   "source": [
    "#Returns the mean squared error (RMSE); we'll take a square root\n",
    "RMSE = np.sqrt(mean_squared_error(power_test, power_pred))\n",
    "print('Root Mean Squared Error (RMSE): ', RMSE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "594fefcd85939859",
   "metadata": {},
   "source": [
    "r_squared = r2_score(power_test, power_pred)\n",
    "print('R-squared: ',r_squared)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "148a5bb6b8e4fa1a",
   "metadata": {},
   "source": [
    "Bei dieser Evaluation deutet sich an, dass ein lineares Model wohl nicht am besten die Realität widerspiegelt und lineare Linie underfitted ist. Es könnte in die Richtung einer polynomiale Regression gehen."
   ]
  },
  {
   "cell_type": "code",
   "id": "bfc7e69cf59d5e55",
   "metadata": {},
   "source": [
    "plt.scatter(temp_test, power_test)\n",
    "plt.plot(temp_test, 21.3065 + -0.5574* temp_test, 'r')\n",
    "\n",
    "plt.title('Model Evaluation: Visualisierung der Passform des Modells auf die Testdaten', fontsize = 15)\n",
    "\n",
    "plt.ylabel('Stromverbrauch kWh')         # Y-label\n",
    "\n",
    "plt.xlabel('Temperatur Grad Celsius')            # X-label\n",
    "\n",
    "plt.figsize = (10,5)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f3917f70ab89c0e2",
   "metadata": {},
   "source": [
    "### Modell anwenden\n",
    "Mit der Definition einer Funktion, können nun Vorhersagen basierend auf einem Input getroffen werden."
   ]
  },
  {
   "cell_type": "code",
   "id": "411ea7a33d2f855a",
   "metadata": {},
   "source": [
    "def lr_model_prediction (Xarg):\n",
    "    intercept = 21.3065\n",
    "    coeff_X = -0.5574\n",
    "\n",
    "    result = intercept + coeff_X * Xarg\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8eb19d9935955d90",
   "metadata": {},
   "source": [
    "tmp = -2\n",
    "print('Stromverbrauch Vorhersage:\\t',lr_model_prediction(tmp),'kWh\\nbei Temperatur: \\t\\t\\t', tmp, 'Grad Celsius')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9b4927ad31ce85c6",
   "metadata": {},
   "source": [
    "### Zusammenfassung\n",
    "Generell kann die Aussage getroffen werden, dass für jedes Grad wärmer der Stromverbrauch um ca. 0.5 kWh abnimmt, in dieser linearen Betrachtung. Aufgrund der Residuale und der letzten Test Grafik scheint es noch weitere Faktoren zu geben, die den Stromverbrauch beeinflussen. Ebenfalls scheint es grafisch nach einem Underfitting auszusehen.\n",
    "## Zusammenfassung Forecasting\n",
    "Eine Vorhersage alleine basierend auf der Zeitreihe des Stromverbrauches ist nicht sinnvoll mit den angewandten Algorithmen. Ein lineares Modell scheint gut zu passen. Die tiefere Betrachtung zeigt aber eine Tendenz des Underfitting. Als nächster Schritt würde sich ein Long Short-Term Memory LSTM Modell anbieten, welches auf dem recurrent neural network RNN basiert. In diesem können verschiedene Inputs geliefert werden um einen Output zu liefern. Dies wird nicht weiter in dieser Arbeit behandelt.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fazit\n",
    "## Datenqualität & Auswertungen\n",
    "Die gesammelten Daten lassen eine Auswertung in die angestrebte Richtung zu. Besonders die Meteo-Daten sind zwar kompliziert in der Handhabung, lassen aber viele Rückschlüsse und Auswertungen zu. Auch die demografischen Daten des Bundes sind sehr ausführlich, wenn auch teilweise nicht top aktuell. Die Smartmeter Daten stellen jedoch die Schwachstelle dar. Die Daten weisen Ungenauigkeiten und offensichtliche Fehler auf. Diese fehlerhaften Datensätze ziehen sich in einigen Fällen über mehrere Monate hinweg, was das Herausfiltern und Auffüllen der Daten sinnlos macht. \n",
    "\n",
    "Da die Daten nur für Gemeinden im Kanton Luzern zur Verfügung stehen, ist das Datenset betreffend der Ortschaften stark begrenzt und fehlerhafte Daten engen es noch weiter ein. Um aussagekräftige Zusammenhänge zwischen Stromverbrauch, demografischen Daten und Meteo-Daten ziehen zu können, ist das Datenset zu klein und geografisch zu stark begrenzt. Weiter wäre es interessant, wenn die Smart Meter auch Angaben über den eingespeisten Strom machen würden. Damit wären in Verbindung mit den installierten Solaranlagen weitere Auswertungen möglich, ob das Potenzial ausgeschöpft wird. Leider fehlen aktuell Informationen, über den tatsächlich mit den installierten Solaranlagen produzierten Storm. \n",
    "\n",
    "Weiter wäre eine Kategorisierung der Smartmeter Daten nach privat und gewerblich sinnvoll. Zwar werden Grossverbraucher herausgefiltert, der Vergleich von Anzahl Smartmeter mit Anzahl Haushalten zeigt jedoch, dass je nach Gemeinde auch zahlreiche Messungen aus dem Gewerbe vorhanden sind. Dadurch sind keine separaten Auswertungen und Trendanalysen möglich.\n",
    "\n",
    "## Persönliches Fazit\n",
    "Wir haben uns für das Projekt eine zu breite Datenbasis vorgenommen. Dies machte einerseits das Aufbereiten und Analysieren der Daten sehr aufwendig, andererseits brachte es auch unsere IDEs teilweise ans Limit und brauchte jeweils lange für eine Durchführung. Besonders die Meteo-Daten waren sehr zeitintensiv und die Smartmeter Daten haben etwas enttäuscht. Einerseits durch die schlechte Datenqualität, andererseits dadurch, dass nur die PLZ zur Verfügung stand. Das eindeutige Mapping von PLZ auf die BFS-ID war aufwendig und musste von Hand vorgenommen werden. Da das Datenset auf den Kanton Luzern beschränkt ist, war dies möglich, jedoch wäre es bei einer Ausweitung auf die ganze Schweiz sehr unpraktisch. Hier empfiehlt es sich für die CKW AG, die Datensätze in Zukunft mit BFS-ID zur Verfügung zu stellen, da auch sämtliche anderen Datensätze damit arbeiten.\n",
    "\n",
    "Insofern waren die Ergebnisse der Auswertungen im Hinblick auf die Fragestellung und die breite Datenbasis eher ernüchternd und aussagekräftige Zusammenhänge konnten keine festgestellt werden und für weitere, tiefere Auswertungen fehlte aufgrund der aufwendigen Aufbereitung der breiten Datenbasis die Zeit. Die ersten Versuche mit ML haben aber gezeigt, dass hier potenzial besteht, anhand der verschiedenen Parametern der Meteo-Daten den Stromverbrauch vorherzusagen.\n"
   ],
   "id": "6076fe78793f477b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
